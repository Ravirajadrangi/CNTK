CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 264106564 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining OutputDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu DeviceId=0 timestamping=true
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:10) on eee0b25ee9ec at 2017/08/21 14:28:00

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining  OutputDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu  DeviceId=0  timestamping=true
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/21/2017 14:28:00: -------------------------------------------------------------------
08/21/2017 14:28:00: Build info: 

08/21/2017 14:28:00: 		Built time: Aug 21 2017 08:19:23
08/21/2017 14:28:00: 		Last modified date: Fri Aug 18 16:43:56 2017
08/21/2017 14:28:00: 		Build type: debug
08/21/2017 14:28:00: 		Build target: GPU
08/21/2017 14:28:00: 		With 1bit-SGD: no
08/21/2017 14:28:00: 		With ASGD: yes
08/21/2017 14:28:00: 		Math lib: mkl
08/21/2017 14:28:00: 		CUDA_PATH: /usr/local/cuda-8.0
08/21/2017 14:28:00: 		CUB_PATH: /usr/local/cub-1.4.1
08/21/2017 14:28:00: 		CUDNN_PATH: /usr/local/cudnn-6.0
08/21/2017 14:28:00: 		Build Branch: HEAD
08/21/2017 14:28:00: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
08/21/2017 14:28:00: 		Built by Source/CNTK/buildinfo.h$$0 on 978ed30056f7
08/21/2017 14:28:00: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/21/2017 14:28:00: 		MPI distribution: Open MPI
08/21/2017 14:28:00: 		MPI version: 1.10.7
08/21/2017 14:28:00: -------------------------------------------------------------------
08/21/2017 14:28:00: -------------------------------------------------------------------
08/21/2017 14:28:00: GPU info:

08/21/2017 14:28:00: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 3018 MB
08/21/2017 14:28:00: -------------------------------------------------------------------

Configuration, Raw:

08/21/2017 14:28:00: precision = "float"
deviceId = $DeviceId$
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
ndlMacros = "$ConfigDir$/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "$RunDir$/models/Pre1/cntkSpeech"
    newModel  = "$RunDir$/models/Pre2/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
addLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "$RunDir$/models/Pre2/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech"
    deviceId = $DeviceId$
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "$DataDir$/glob_0000.scp"
    ]
    labels = [
        mlfFile = "$DataDir$/glob_0000.mlf"
        labelMappingFile = "$DataDir$/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining
OutputDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu
DeviceId=0
timestamping=true


Configuration After Variable Resolution:

08/21/2017 14:28:00: precision = "float"
deviceId = 0
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
ndlMacros = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]
addLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
        labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining
OutputDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu
DeviceId=0
timestamping=true


Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
        labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
08/21/2017 14:28:00: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
08/21/2017 14:28:00: precision = "float"

08/21/2017 14:28:00: ##############################################################################
08/21/2017 14:28:00: #                                                                            #
08/21/2017 14:28:00: # dptPre1 command (train action)                                             #
08/21/2017 14:28:00: #                                                                            #
08/21/2017 14:28:00: ##############################################################################

08/21/2017 14:28:00: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
08/21/2017 14:28:01: 
Model has 19 nodes. Using GPU 0.

08/21/2017 14:28:01: Training criterion:   ce = CrossEntropyWithSoftmax
08/21/2017 14:28:01: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 2 are aliased.
	OL.t (gradient) reuses OL.z (gradient)

Memory Sharing: Out of 29 matrices, 12 are shared as 3, and 17 are not shared.

Here are the ones that share memory:
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.t : [512 x *]
	  HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *]
	  HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *]
	  OL.t : [132 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }

Here are the ones that don't share memory:
	{scaledLogLikelihood : [132 x 1 x *]}
	{OL.b : [132 x 1] (gradient)}
	{ce : [1] (gradient)}
	{err : [1]}
	{ce : [1]}
	{OL.W : [132 x 512] (gradient)}
	{featNorm : [363 x *]}
	{globalMean : [363 x 1]}
	{globalInvStd : [363 x 1]}
	{globalPrior : [132 x 1]}
	{HL1.W : [512 x 363]}
	{HL1.b : [512 x 1]}
	{OL.W : [132 x 512]}
	{OL.b : [132 x 1]}
	{labels : [132 x *]}
	{features : [363 x *]}
	{logPrior : [132 x 1]}


08/21/2017 14:28:01: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

08/21/2017 14:28:01: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
08/21/2017 14:28:01: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
08/21/2017 14:28:01: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
08/21/2017 14:28:01: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

08/21/2017 14:28:01: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/21/2017 14:28:01: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

08/21/2017 14:28:02: Starting minibatch loop.
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.77545433 * 2560; err = 0.83984375 * 2560; time = 0.1985s; samplesPerSecond = 12899.4
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129173 * 2560; err = 0.69921875 * 2560; time = 0.0623s; samplesPerSecond = 41118.6
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0619s; samplesPerSecond = 41343.7
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0616s; samplesPerSecond = 41546.9
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.98474121 * 2560; err = 0.55273438 * 2560; time = 0.0616s; samplesPerSecond = 41559.6
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0618s; samplesPerSecond = 41400.6
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0628s; samplesPerSecond = 40771.8
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646271 * 2560; err = 0.49335937 * 2560; time = 0.0662s; samplesPerSecond = 38671.7
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.66541901 * 2560; err = 0.46328125 * 2560; time = 0.0638s; samplesPerSecond = 40115.4
08/21/2017 14:28:02:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725983 * 2560; err = 0.46054688 * 2560; time = 0.0653s; samplesPerSecond = 39233.6
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61621094 * 2560; err = 0.45390625 * 2560; time = 0.0651s; samplesPerSecond = 39310.9
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56063995 * 2560; err = 0.44140625 * 2560; time = 0.0650s; samplesPerSecond = 39363.5
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0651s; samplesPerSecond = 39347.4
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53460999 * 2560; err = 0.46210937 * 2560; time = 0.0649s; samplesPerSecond = 39450.5
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46377869 * 2560; err = 0.44140625 * 2560; time = 0.0651s; samplesPerSecond = 39330.4
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43344116 * 2560; err = 0.42617187 * 2560; time = 0.0650s; samplesPerSecond = 39354.7
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.43215027 * 2560; err = 0.42148438 * 2560; time = 0.0652s; samplesPerSecond = 39248.6
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.37987366 * 2560; err = 0.41250000 * 2560; time = 0.0650s; samplesPerSecond = 39364.6
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35841980 * 2560; err = 0.40039062 * 2560; time = 0.0659s; samplesPerSecond = 38865.8
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44842224 * 2560; err = 0.42656250 * 2560; time = 0.0649s; samplesPerSecond = 39448.8
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.43927917 * 2560; err = 0.42539063 * 2560; time = 0.0655s; samplesPerSecond = 39103.8
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41734009 * 2560; err = 0.42539063 * 2560; time = 0.0659s; samplesPerSecond = 38869.3
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33211670 * 2560; err = 0.40468750 * 2560; time = 0.0659s; samplesPerSecond = 38833.1
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36109009 * 2560; err = 0.40429688 * 2560; time = 0.0651s; samplesPerSecond = 39297.0
08/21/2017 14:28:03:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.30958252 * 2560; err = 0.39804688 * 2560; time = 0.0648s; samplesPerSecond = 39492.3
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25348511 * 2560; err = 0.36992188 * 2560; time = 0.0647s; samplesPerSecond = 39545.0
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30338745 * 2560; err = 0.39570312 * 2560; time = 0.0648s; samplesPerSecond = 39477.5
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36117859 * 2560; err = 0.40859375 * 2560; time = 0.0649s; samplesPerSecond = 39475.0
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.29568787 * 2560; err = 0.39531250 * 2560; time = 0.0648s; samplesPerSecond = 39509.2
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35455017 * 2560; err = 0.40859375 * 2560; time = 0.0648s; samplesPerSecond = 39500.5
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32246399 * 2560; err = 0.39921875 * 2560; time = 0.0649s; samplesPerSecond = 39459.3
08/21/2017 14:28:04:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27023926 * 2560; err = 0.38242188 * 2560; time = 0.0594s; samplesPerSecond = 43069.4
08/21/2017 14:28:04: Finished Epoch[ 1 of 2]: [Training] ce = 1.65206318 * 81920; err = 0.46723633 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.11148s
08/21/2017 14:28:04: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre1/cntkSpeech.1'

08/21/2017 14:28:04: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

08/21/2017 14:28:04: Starting minibatch loop.
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.24553871 * 2560; err = 0.38984375 * 2560; time = 0.0663s; samplesPerSecond = 38620.9
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23801517 * 2560; err = 0.36718750 * 2560; time = 0.0645s; samplesPerSecond = 39709.0
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26358624 * 2560; err = 0.39218750 * 2560; time = 0.0648s; samplesPerSecond = 39530.2
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26325531 * 2560; err = 0.38203125 * 2560; time = 0.0647s; samplesPerSecond = 39554.5
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.27975998 * 2560; err = 0.36562500 * 2560; time = 0.0649s; samplesPerSecond = 39419.1
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18315849 * 2560; err = 0.35195312 * 2560; time = 0.0633s; samplesPerSecond = 40432.2
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19740906 * 2560; err = 0.37070313 * 2560; time = 0.0625s; samplesPerSecond = 40965.8
08/21/2017 14:28:04:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23275757 * 2560; err = 0.36835937 * 2560; time = 0.0648s; samplesPerSecond = 39530.0
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.27090912 * 2560; err = 0.38945313 * 2560; time = 0.0655s; samplesPerSecond = 39056.0
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25143051 * 2560; err = 0.37500000 * 2560; time = 0.0654s; samplesPerSecond = 39155.3
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.21462936 * 2560; err = 0.37187500 * 2560; time = 0.0648s; samplesPerSecond = 39514.0
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19433441 * 2560; err = 0.36796875 * 2560; time = 0.0647s; samplesPerSecond = 39597.5
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16462097 * 2560; err = 0.36171875 * 2560; time = 0.0664s; samplesPerSecond = 38548.2
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16609802 * 2560; err = 0.36484375 * 2560; time = 0.0652s; samplesPerSecond = 39248.8
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.14834595 * 2560; err = 0.34492187 * 2560; time = 0.0653s; samplesPerSecond = 39187.2
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11703033 * 2560; err = 0.34804687 * 2560; time = 0.0651s; samplesPerSecond = 39311.7
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.17735901 * 2560; err = 0.35703125 * 2560; time = 0.0659s; samplesPerSecond = 38843.9
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13435669 * 2560; err = 0.35664062 * 2560; time = 0.0649s; samplesPerSecond = 39457.5
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14561310 * 2560; err = 0.35039063 * 2560; time = 0.0648s; samplesPerSecond = 39488.1
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11020966 * 2560; err = 0.33281250 * 2560; time = 0.0649s; samplesPerSecond = 39473.4
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.16456146 * 2560; err = 0.35078125 * 2560; time = 0.0649s; samplesPerSecond = 39471.8
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14552612 * 2560; err = 0.35742188 * 2560; time = 0.0647s; samplesPerSecond = 39555.6
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09541931 * 2560; err = 0.34492187 * 2560; time = 0.0648s; samplesPerSecond = 39532.7
08/21/2017 14:28:05:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12883606 * 2560; err = 0.34218750 * 2560; time = 0.0651s; samplesPerSecond = 39310.1
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.08879089 * 2560; err = 0.33867188 * 2560; time = 0.0647s; samplesPerSecond = 39560.8
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08555603 * 2560; err = 0.32695313 * 2560; time = 0.0649s; samplesPerSecond = 39472.7
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.12885132 * 2560; err = 0.34492187 * 2560; time = 0.0647s; samplesPerSecond = 39572.6
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.12917175 * 2560; err = 0.34921875 * 2560; time = 0.0647s; samplesPerSecond = 39547.3
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.12189331 * 2560; err = 0.34570312 * 2560; time = 0.0651s; samplesPerSecond = 39297.9
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08549500 * 2560; err = 0.32773438 * 2560; time = 0.0649s; samplesPerSecond = 39436.1
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08267212 * 2560; err = 0.34023437 * 2560; time = 0.0653s; samplesPerSecond = 39201.4
08/21/2017 14:28:06:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07620239 * 2560; err = 0.32578125 * 2560; time = 0.0600s; samplesPerSecond = 42646.6
08/21/2017 14:28:06: Finished Epoch[ 2 of 2]: [Training] ce = 1.16660604 * 81920; err = 0.35634766 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.08399s
08/21/2017 14:28:06: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre1/cntkSpeech'

08/21/2017 14:28:06: Action "train" complete.


08/21/2017 14:28:06: ##############################################################################
08/21/2017 14:28:06: #                                                                            #
08/21/2017 14:28:06: # addLayer2 command (edit action)                                            #
08/21/2017 14:28:06: #                                                                            #
08/21/2017 14:28:06: ##############################################################################


08/21/2017 14:28:06: Action "edit" complete.


08/21/2017 14:28:06: ##############################################################################
08/21/2017 14:28:06: #                                                                            #
08/21/2017 14:28:06: # dptPre2 command (train action)                                             #
08/21/2017 14:28:06: #                                                                            #
08/21/2017 14:28:06: ##############################################################################

08/21/2017 14:28:06: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
08/21/2017 14:28:06: 
Model has 24 nodes. Using GPU 0.

08/21/2017 14:28:06: Training criterion:   ce = CrossEntropyWithSoftmax
08/21/2017 14:28:06: Evaluation criterion: err = ClassificationError

08/21/2017 14:28:06: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/21/2017 14:28:06: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
08/21/2017 14:28:06: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
08/21/2017 14:28:06: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
08/21/2017 14:28:06: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
08/21/2017 14:28:06: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
08/21/2017 14:28:06: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

08/21/2017 14:28:06: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/21/2017 14:28:06: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

08/21/2017 14:28:07: Starting minibatch loop.
08/21/2017 14:28:07:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.95234604 * 2560; err = 0.81796875 * 2560; time = 0.0868s; samplesPerSecond = 29506.5
08/21/2017 14:28:07:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.60234833 * 2560; err = 0.63789063 * 2560; time = 0.0835s; samplesPerSecond = 30667.4
08/21/2017 14:28:07:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.15345840 * 2560; err = 0.57734375 * 2560; time = 0.0834s; samplesPerSecond = 30683.7
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.80804749 * 2560; err = 0.50703125 * 2560; time = 0.0834s; samplesPerSecond = 30699.3
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.62714386 * 2560; err = 0.47343750 * 2560; time = 0.0835s; samplesPerSecond = 30648.9
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.58302765 * 2560; err = 0.45625000 * 2560; time = 0.0834s; samplesPerSecond = 30693.1
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57416840 * 2560; err = 0.46406250 * 2560; time = 0.0835s; samplesPerSecond = 30649.9
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.49049683 * 2560; err = 0.44609375 * 2560; time = 0.0833s; samplesPerSecond = 30717.1
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.43992004 * 2560; err = 0.41835937 * 2560; time = 0.0834s; samplesPerSecond = 30707.1
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.39899445 * 2560; err = 0.41093750 * 2560; time = 0.0836s; samplesPerSecond = 30609.3
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41018677 * 2560; err = 0.40273437 * 2560; time = 0.0836s; samplesPerSecond = 30632.1
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.35843353 * 2560; err = 0.39804688 * 2560; time = 0.0838s; samplesPerSecond = 30564.2
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.32144775 * 2560; err = 0.39375000 * 2560; time = 0.0839s; samplesPerSecond = 30504.0
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33142242 * 2560; err = 0.40546875 * 2560; time = 0.0847s; samplesPerSecond = 30229.1
08/21/2017 14:28:08:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27800751 * 2560; err = 0.37812500 * 2560; time = 0.0840s; samplesPerSecond = 30460.3
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28858032 * 2560; err = 0.39453125 * 2560; time = 0.0835s; samplesPerSecond = 30644.2
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.29140320 * 2560; err = 0.37968750 * 2560; time = 0.0834s; samplesPerSecond = 30686.5
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.27164612 * 2560; err = 0.39023438 * 2560; time = 0.0834s; samplesPerSecond = 30712.1
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29244080 * 2560; err = 0.38710937 * 2560; time = 0.0835s; samplesPerSecond = 30646.1
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32063599 * 2560; err = 0.39843750 * 2560; time = 0.0825s; samplesPerSecond = 31012.1
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.30206909 * 2560; err = 0.38476562 * 2560; time = 0.0833s; samplesPerSecond = 30737.1
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.31644287 * 2560; err = 0.39726563 * 2560; time = 0.0845s; samplesPerSecond = 30279.6
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.23897095 * 2560; err = 0.37187500 * 2560; time = 0.0833s; samplesPerSecond = 30748.0
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.26500854 * 2560; err = 0.38203125 * 2560; time = 0.0835s; samplesPerSecond = 30650.3
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22773132 * 2560; err = 0.37265625 * 2560; time = 0.0834s; samplesPerSecond = 30682.9
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19237976 * 2560; err = 0.35507813 * 2560; time = 0.0834s; samplesPerSecond = 30678.9
08/21/2017 14:28:09:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20592957 * 2560; err = 0.36640625 * 2560; time = 0.0834s; samplesPerSecond = 30683.0
08/21/2017 14:28:10:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.24901123 * 2560; err = 0.37304688 * 2560; time = 0.0833s; samplesPerSecond = 30720.1
08/21/2017 14:28:10:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.17727051 * 2560; err = 0.34882812 * 2560; time = 0.0835s; samplesPerSecond = 30665.9
08/21/2017 14:28:10:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.17915344 * 2560; err = 0.35585937 * 2560; time = 0.0851s; samplesPerSecond = 30099.5
08/21/2017 14:28:10:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19775085 * 2560; err = 0.35703125 * 2560; time = 0.0841s; samplesPerSecond = 30435.5
08/21/2017 14:28:10:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.15687256 * 2560; err = 0.34179688 * 2560; time = 0.0782s; samplesPerSecond = 32737.4
08/21/2017 14:28:10: Finished Epoch[ 1 of 2]: [Training] ce = 1.48446083 * 81920; err = 0.42325439 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.61611s
08/21/2017 14:28:10: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech.1'

08/21/2017 14:28:10: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

08/21/2017 14:28:10: Starting minibatch loop.
08/21/2017 14:28:10:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.16664762 * 2560; err = 0.36015625 * 2560; time = 0.0853s; samplesPerSecond = 30028.0
08/21/2017 14:28:10:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18870573 * 2560; err = 0.35781250 * 2560; time = 0.0837s; samplesPerSecond = 30576.6
08/21/2017 14:28:10:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.16170979 * 2560; err = 0.35625000 * 2560; time = 0.0835s; samplesPerSecond = 30648.7
08/21/2017 14:28:10:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.15019836 * 2560; err = 0.35468750 * 2560; time = 0.0836s; samplesPerSecond = 30632.5
08/21/2017 14:28:10:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.19214973 * 2560; err = 0.34375000 * 2560; time = 0.0834s; samplesPerSecond = 30698.5
08/21/2017 14:28:10:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.13505058 * 2560; err = 0.35156250 * 2560; time = 0.0834s; samplesPerSecond = 30677.3
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14320984 * 2560; err = 0.35351562 * 2560; time = 0.0829s; samplesPerSecond = 30894.4
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17766495 * 2560; err = 0.36562500 * 2560; time = 0.0833s; samplesPerSecond = 30740.9
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.17257233 * 2560; err = 0.35937500 * 2560; time = 0.0833s; samplesPerSecond = 30715.7
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18593369 * 2560; err = 0.36210938 * 2560; time = 0.0835s; samplesPerSecond = 30658.1
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14418716 * 2560; err = 0.34921875 * 2560; time = 0.0834s; samplesPerSecond = 30708.7
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13939972 * 2560; err = 0.34453125 * 2560; time = 0.0836s; samplesPerSecond = 30639.4
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.10048523 * 2560; err = 0.34375000 * 2560; time = 0.0849s; samplesPerSecond = 30146.8
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12730865 * 2560; err = 0.34648438 * 2560; time = 0.0834s; samplesPerSecond = 30677.5
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09852142 * 2560; err = 0.33828125 * 2560; time = 0.0833s; samplesPerSecond = 30739.3
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07665100 * 2560; err = 0.33906250 * 2560; time = 0.0836s; samplesPerSecond = 30636.9
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.12044373 * 2560; err = 0.33828125 * 2560; time = 0.0835s; samplesPerSecond = 30665.6
08/21/2017 14:28:11:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.07696075 * 2560; err = 0.33203125 * 2560; time = 0.0833s; samplesPerSecond = 30742.0
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11485443 * 2560; err = 0.34687500 * 2560; time = 0.0842s; samplesPerSecond = 30407.9
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08271027 * 2560; err = 0.32343750 * 2560; time = 0.0834s; samplesPerSecond = 30697.3
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.12734528 * 2560; err = 0.33164063 * 2560; time = 0.0834s; samplesPerSecond = 30707.6
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09645691 * 2560; err = 0.33906250 * 2560; time = 0.0833s; samplesPerSecond = 30747.4
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04905548 * 2560; err = 0.32695313 * 2560; time = 0.0836s; samplesPerSecond = 30629.3
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.09844055 * 2560; err = 0.33906250 * 2560; time = 0.0836s; samplesPerSecond = 30616.2
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09992371 * 2560; err = 0.34218750 * 2560; time = 0.0835s; samplesPerSecond = 30654.2
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07493591 * 2560; err = 0.33007812 * 2560; time = 0.0833s; samplesPerSecond = 30740.5
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10963440 * 2560; err = 0.34218750 * 2560; time = 0.0833s; samplesPerSecond = 30736.2
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.08672485 * 2560; err = 0.33515625 * 2560; time = 0.0838s; samplesPerSecond = 30536.8
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.09848633 * 2560; err = 0.33789062 * 2560; time = 0.0834s; samplesPerSecond = 30691.0
08/21/2017 14:28:12:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08891296 * 2560; err = 0.32343750 * 2560; time = 0.0837s; samplesPerSecond = 30575.4
08/21/2017 14:28:13:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07447510 * 2560; err = 0.33007812 * 2560; time = 0.0840s; samplesPerSecond = 30472.8
08/21/2017 14:28:13:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07217102 * 2560; err = 0.33632812 * 2560; time = 0.0779s; samplesPerSecond = 32872.1
08/21/2017 14:28:13: Finished Epoch[ 2 of 2]: [Training] ce = 1.11974773 * 81920; err = 0.34315186 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.68078s
08/21/2017 14:28:13: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/Pre2/cntkSpeech'

08/21/2017 14:28:13: Action "train" complete.


08/21/2017 14:28:13: ##############################################################################
08/21/2017 14:28:13: #                                                                            #
08/21/2017 14:28:13: # addLayer3 command (edit action)                                            #
08/21/2017 14:28:13: #                                                                            #
08/21/2017 14:28:13: ##############################################################################


08/21/2017 14:28:13: Action "edit" complete.


08/21/2017 14:28:13: ##############################################################################
08/21/2017 14:28:13: #                                                                            #
08/21/2017 14:28:13: # speechTrain command (train action)                                         #
08/21/2017 14:28:13: #                                                                            #
08/21/2017 14:28:13: ##############################################################################

08/21/2017 14:28:13: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
08/21/2017 14:28:13: 
Model has 29 nodes. Using GPU 0.

08/21/2017 14:28:13: Training criterion:   ce = CrossEntropyWithSoftmax
08/21/2017 14:28:13: Evaluation criterion: err = ClassificationError

08/21/2017 14:28:13: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

08/21/2017 14:28:13: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
08/21/2017 14:28:13: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
08/21/2017 14:28:13: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
08/21/2017 14:28:13: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
08/21/2017 14:28:13: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
08/21/2017 14:28:13: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
08/21/2017 14:28:13: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
08/21/2017 14:28:13: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

08/21/2017 14:28:13: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/21/2017 14:28:13: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

08/21/2017 14:28:14: Starting minibatch loop.
08/21/2017 14:28:14:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 4.04495506 * 2560; err = 0.84531250 * 2560; time = 0.1063s; samplesPerSecond = 24090.1
08/21/2017 14:28:14:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57063713 * 2560; err = 0.61523438 * 2560; time = 0.1022s; samplesPerSecond = 25060.6
08/21/2017 14:28:14:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.05942078 * 2560; err = 0.56093750 * 2560; time = 0.1029s; samplesPerSecond = 24885.3
08/21/2017 14:28:14:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.69141846 * 2560; err = 0.47031250 * 2560; time = 0.1035s; samplesPerSecond = 24743.2
08/21/2017 14:28:14:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.51787796 * 2560; err = 0.44218750 * 2560; time = 0.1026s; samplesPerSecond = 24940.5
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.45984192 * 2560; err = 0.42070313 * 2560; time = 0.1024s; samplesPerSecond = 25001.9
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.46016541 * 2560; err = 0.42578125 * 2560; time = 0.1026s; samplesPerSecond = 24950.0
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37518768 * 2560; err = 0.40390625 * 2560; time = 0.1025s; samplesPerSecond = 24984.6
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.33064575 * 2560; err = 0.38476562 * 2560; time = 0.1024s; samplesPerSecond = 24998.0
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28854523 * 2560; err = 0.37734375 * 2560; time = 0.1024s; samplesPerSecond = 25000.0
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31856384 * 2560; err = 0.38203125 * 2560; time = 0.1037s; samplesPerSecond = 24686.9
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27931366 * 2560; err = 0.37148437 * 2560; time = 0.1024s; samplesPerSecond = 24998.7
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24598083 * 2560; err = 0.37382813 * 2560; time = 0.1025s; samplesPerSecond = 24972.3
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.26057587 * 2560; err = 0.38203125 * 2560; time = 0.1024s; samplesPerSecond = 24994.3
08/21/2017 14:28:15:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.20037689 * 2560; err = 0.35742188 * 2560; time = 0.1024s; samplesPerSecond = 25011.1
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.22235413 * 2560; err = 0.37031250 * 2560; time = 0.1022s; samplesPerSecond = 25052.5
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.21270752 * 2560; err = 0.36328125 * 2560; time = 0.1023s; samplesPerSecond = 25020.8
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20062256 * 2560; err = 0.36640625 * 2560; time = 0.1023s; samplesPerSecond = 25019.9
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21882324 * 2560; err = 0.37226562 * 2560; time = 0.1025s; samplesPerSecond = 24985.0
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.25444336 * 2560; err = 0.37890625 * 2560; time = 0.1065s; samplesPerSecond = 24029.3
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.24527588 * 2560; err = 0.36523438 * 2560; time = 0.1025s; samplesPerSecond = 24976.9
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.24994202 * 2560; err = 0.38867188 * 2560; time = 0.1022s; samplesPerSecond = 25043.6
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18169861 * 2560; err = 0.35117188 * 2560; time = 0.1022s; samplesPerSecond = 25037.6
08/21/2017 14:28:16:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21201477 * 2560; err = 0.37265625 * 2560; time = 0.1023s; samplesPerSecond = 25034.9
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17803345 * 2560; err = 0.35585937 * 2560; time = 0.1030s; samplesPerSecond = 24858.6
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14755859 * 2560; err = 0.34570312 * 2560; time = 0.1029s; samplesPerSecond = 24872.0
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13581848 * 2560; err = 0.35585937 * 2560; time = 0.1031s; samplesPerSecond = 24836.0
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19696655 * 2560; err = 0.36093750 * 2560; time = 0.1029s; samplesPerSecond = 24876.8
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.12962036 * 2560; err = 0.33710937 * 2560; time = 0.1026s; samplesPerSecond = 24954.0
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14494934 * 2560; err = 0.35195312 * 2560; time = 0.1035s; samplesPerSecond = 24739.9
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15758972 * 2560; err = 0.34687500 * 2560; time = 0.1028s; samplesPerSecond = 24897.7
08/21/2017 14:28:17:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.11477661 * 2560; err = 0.34257813 * 2560; time = 0.0968s; samplesPerSecond = 26443.7
08/21/2017 14:28:17: Finished Epoch[ 1 of 4]: [Training] ce = 1.41583443 * 81920; err = 0.40434570 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=4.21453s
08/21/2017 14:28:17: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech.1'

08/21/2017 14:28:17: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

08/21/2017 14:28:17: Starting minibatch loop.
08/21/2017 14:28:17:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.23277740 * 5120; err = 0.37402344 * 5120; time = 0.1484s; samplesPerSecond = 34491.3
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.34094334 * 5120; err = 0.39355469 * 5120; time = 0.1454s; samplesPerSecond = 35218.5
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.32344379 * 5120; err = 0.39804688 * 5120; time = 0.1450s; samplesPerSecond = 35318.8
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.16154022 * 5120; err = 0.35371094 * 5120; time = 0.1441s; samplesPerSecond = 35531.4
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16383133 * 5120; err = 0.34960938 * 5120; time = 0.1439s; samplesPerSecond = 35575.3
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.12472038 * 5120; err = 0.33984375 * 5120; time = 0.1438s; samplesPerSecond = 35611.5
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.09685593 * 5120; err = 0.33789062 * 5120; time = 0.1457s; samplesPerSecond = 35131.6
08/21/2017 14:28:18:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06717148 * 5120; err = 0.32890625 * 5120; time = 0.1466s; samplesPerSecond = 34934.1
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.09009476 * 5120; err = 0.33046875 * 5120; time = 0.1451s; samplesPerSecond = 35277.6
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10942917 * 5120; err = 0.34824219 * 5120; time = 0.1444s; samplesPerSecond = 35465.5
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09149475 * 5120; err = 0.32949219 * 5120; time = 0.1456s; samplesPerSecond = 35172.0
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07471619 * 5120; err = 0.33496094 * 5120; time = 0.1451s; samplesPerSecond = 35294.6
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.08045197 * 5120; err = 0.33378906 * 5120; time = 0.1434s; samplesPerSecond = 35703.5
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.18746948 * 5120; err = 0.36054687 * 5120; time = 0.1438s; samplesPerSecond = 35608.9
08/21/2017 14:28:19:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08097229 * 5120; err = 0.33203125 * 5120; time = 0.1439s; samplesPerSecond = 35587.8
08/21/2017 14:28:20:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05254364 * 5120; err = 0.32460937 * 5120; time = 0.1325s; samplesPerSecond = 38641.6
08/21/2017 14:28:20: Finished Epoch[ 2 of 4]: [Training] ce = 1.14240351 * 81920; err = 0.34810791 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.32383s
08/21/2017 14:28:20: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech.2'

08/21/2017 14:28:20: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

08/21/2017 14:28:20: Starting minibatch loop.
08/21/2017 14:28:20:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.07480564 * 5120; err = 0.33242187 * 5120; time = 0.1450s; samplesPerSecond = 35318.5
08/21/2017 14:28:20:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.09418888 * 5120; err = 0.33535156 * 5120; time = 0.1440s; samplesPerSecond = 35567.5
08/21/2017 14:28:20:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08832016 * 5120; err = 0.33691406 * 5120; time = 0.1441s; samplesPerSecond = 35530.6
08/21/2017 14:28:20:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.04801941 * 5120; err = 0.32382813 * 5120; time = 0.1439s; samplesPerSecond = 35577.2
08/21/2017 14:28:20:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07341309 * 5120; err = 0.32714844 * 5120; time = 0.1440s; samplesPerSecond = 35554.4
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.08500938 * 5120; err = 0.33398438 * 5120; time = 0.1438s; samplesPerSecond = 35595.5
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06951523 * 5120; err = 0.33125000 * 5120; time = 0.1437s; samplesPerSecond = 35631.8
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.08042984 * 5120; err = 0.34062500 * 5120; time = 0.1494s; samplesPerSecond = 34276.9
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10114899 * 5120; err = 0.35390625 * 5120; time = 0.1451s; samplesPerSecond = 35287.9
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.01768875 * 5120; err = 0.31328125 * 5120; time = 0.1441s; samplesPerSecond = 35541.3
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03360672 * 5120; err = 0.32324219 * 5120; time = 0.1441s; samplesPerSecond = 35523.2
08/21/2017 14:28:21:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06860886 * 5120; err = 0.33789062 * 5120; time = 0.1444s; samplesPerSecond = 35468.5
08/21/2017 14:28:22:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.06691895 * 5120; err = 0.33613281 * 5120; time = 0.1450s; samplesPerSecond = 35302.6
08/21/2017 14:28:22:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08316956 * 5120; err = 0.34160156 * 5120; time = 0.1438s; samplesPerSecond = 35609.4
08/21/2017 14:28:22:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.01882782 * 5120; err = 0.31210938 * 5120; time = 0.1437s; samplesPerSecond = 35619.7
08/21/2017 14:28:22:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03026886 * 5120; err = 0.32714844 * 5120; time = 0.1330s; samplesPerSecond = 38507.6
08/21/2017 14:28:22: Finished Epoch[ 3 of 4]: [Training] ce = 1.06462126 * 81920; err = 0.33167725 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=2.31797s
08/21/2017 14:28:22: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech.3'

08/21/2017 14:28:22: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

08/21/2017 14:28:22: Starting minibatch loop.
08/21/2017 14:28:22:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02498760 * 5120; err = 0.32812500 * 5120; time = 0.1448s; samplesPerSecond = 35349.6
08/21/2017 14:28:23:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.00653004 * 4926; err = 0.31892002 * 4926; time = 0.4697s; samplesPerSecond = 10487.2
08/21/2017 14:28:23:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.01978836 * 5120; err = 0.31718750 * 5120; time = 0.1450s; samplesPerSecond = 35307.5
08/21/2017 14:28:23:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03124619 * 5120; err = 0.32324219 * 5120; time = 0.1458s; samplesPerSecond = 35115.5
08/21/2017 14:28:23:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.02960358 * 5120; err = 0.31738281 * 5120; time = 0.1474s; samplesPerSecond = 34746.3
08/21/2017 14:28:23:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00228767 * 5120; err = 0.31523438 * 5120; time = 0.1440s; samplesPerSecond = 35563.8
08/21/2017 14:28:23:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01488953 * 5120; err = 0.32167969 * 5120; time = 0.1442s; samplesPerSecond = 35505.6
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00438156 * 5120; err = 0.30585937 * 5120; time = 0.1455s; samplesPerSecond = 35187.6
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.98022079 * 5120; err = 0.32109375 * 5120; time = 0.1435s; samplesPerSecond = 35680.8
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98383560 * 5120; err = 0.30644531 * 5120; time = 0.1437s; samplesPerSecond = 35618.0
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03895187 * 5120; err = 0.32109375 * 5120; time = 0.1441s; samplesPerSecond = 35537.2
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98408051 * 5120; err = 0.30019531 * 5120; time = 0.1436s; samplesPerSecond = 35652.3
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00010757 * 5120; err = 0.31171875 * 5120; time = 0.1440s; samplesPerSecond = 35560.1
08/21/2017 14:28:24:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96877747 * 5120; err = 0.30097656 * 5120; time = 0.1445s; samplesPerSecond = 35437.5
08/21/2017 14:28:25:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97649994 * 5120; err = 0.30332031 * 5120; time = 0.1437s; samplesPerSecond = 35621.1
08/21/2017 14:28:25:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96828461 * 5120; err = 0.30625000 * 5120; time = 0.1362s; samplesPerSecond = 37589.8
08/21/2017 14:28:25: Finished Epoch[ 4 of 4]: [Training] ce = 1.00239983 * 81920; err = 0.31373291 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=2.65411s
08/21/2017 14:28:25: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142800.187761/Speech/DNN_DiscriminativePreTraining@debug_gpu/models/cntkSpeech'

08/21/2017 14:28:25: Action "train" complete.

08/21/2017 14:28:25: __COMPLETED__