CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 264106564 kB
-------------------------------------------------------------------
=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet-parallel.cntk currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu DeviceId=0 timestamping=true numCPUThreads=1 precision=float parallelTrain=true minibatch=256 epochsize=12 asyncBuffer="false" parallelizationMethod=DataParallelASGD stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:10) on dfcf9f489d2c at 2017/08/21 14:27:04

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet-parallel.cntk  currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu  DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD  OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  precision=float  parallelTrain=true  minibatch=256  epochsize=12  asyncBuffer="false"  parallelizationMethod=DataParallelASGD  stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:10) on dfcf9f489d2c at 2017/08/21 14:27:04

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet-parallel.cntk  currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu  DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD  OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  precision=float  parallelTrain=true  minibatch=256  epochsize=12  asyncBuffer="false"  parallelizationMethod=DataParallelASGD  stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
Changed current directory to /tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
Changed current directory to /tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 2 out of 2 MPI nodes on a single host (2 requested); we (1) are in (participating)
ping [mpihelper]: 2 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 2 out of 2 MPI nodes on a single host (2 requested); we (0) are in (participating)
ping [mpihelper]: 2 nodes pinging each other
08/21/2017 14:27:04: Redirecting stderr to file /tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU_Train.logrank0
08/21/2017 14:27:05: Redirecting stderr to file /tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU_Train.logrank1
MPI Rank 0: 08/21/2017 14:27:04: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 14:27:04: Build info: 
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: 		Built time: Aug 21 2017 08:19:23
MPI Rank 0: 08/21/2017 14:27:04: 		Last modified date: Fri Aug 18 16:43:56 2017
MPI Rank 0: 08/21/2017 14:27:04: 		Build type: debug
MPI Rank 0: 08/21/2017 14:27:04: 		Build target: GPU
MPI Rank 0: 08/21/2017 14:27:04: 		With 1bit-SGD: no
MPI Rank 0: 08/21/2017 14:27:04: 		With ASGD: yes
MPI Rank 0: 08/21/2017 14:27:04: 		Math lib: mkl
MPI Rank 0: 08/21/2017 14:27:04: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 0: 08/21/2017 14:27:04: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 08/21/2017 14:27:04: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 0: 08/21/2017 14:27:04: 		Build Branch: HEAD
MPI Rank 0: 08/21/2017 14:27:04: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 0: 08/21/2017 14:27:04: 		Built by Source/CNTK/buildinfo.h$$0 on 978ed30056f7
MPI Rank 0: 08/21/2017 14:27:04: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 08/21/2017 14:27:04: 		MPI distribution: Open MPI
MPI Rank 0: 08/21/2017 14:27:04: 		MPI version: 1.10.7
MPI Rank 0: 08/21/2017 14:27:04: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 14:27:04: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 14:27:04: GPU info:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 3018 MB
MPI Rank 0: 08/21/2017 14:27:04: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: Configuration, Raw:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: makeMode = true
MPI Rank 0: RootDir = "."
MPI Rank 0: configName = "asgd"
MPI Rank 0: minibatch = 128
MPI Rank 0: epochSize = 5
MPI Rank 0: parallelizationMethod = "DataParallelASGD"
MPI Rank 0: asyncBuffer = "true"
MPI Rank 0: ConfigDir = "$RootDir$"
MPI Rank 0: DataDir = "$RootDir$"
MPI Rank 0: OutputDir = "$RootDir$/Output-$configName$"
MPI Rank 0: ModelDir = "$OutputDir$/Models"
MPI Rank 0: ndlMacros = "$ConfigDir$/Macros.ndl"
MPI Rank 0: precision = "float"
MPI Rank 0: DeviceId = 0
MPI Rank 0: imageLayout = "cudnn"
MPI Rank 0: initOnCPUOnly=true
MPI Rank 0: prefetch = "true"
MPI Rank 0: parallelTrain = "false"
MPI Rank 0: command = Train
MPI Rank 0: stderr = "$OutputDir$/Asgd_ResNet"
MPI Rank 0: traceLevel = 1
MPI Rank 0: Proj16to32Filename = "$ConfigDir$/16to32.txt"
MPI Rank 0: Proj32to64Filename = "$ConfigDir$/32to64.txt"
MPI Rank 0: Train = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$ModelDir$/ASGD_Resnet.model"
MPI Rank 0:      NDLNetworkBuilder = [
MPI Rank 0:         networkDescription = "$ConfigDir$/03_ResNet.ndl"
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 0
MPI Rank 0:         minibatchSize = $minibatch$
MPI Rank 0:         learningRatesPerSample = 0.004*80:0.0004*40:0.00004
MPI Rank 0:         momentumPerMB = 0
MPI Rank 0:         maxEpochs = $epochsize$
MPI Rank 0:         L2RegWeight = 0.0001
MPI Rank 0:         dropoutRate = 0
MPI Rank 0:         perfTraceLevel = 0
MPI Rank 0:         firstMBsToShowResult = 1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = $parallelizationMethod$
MPI Rank 0:             distributedMBReading = "true"
MPI Rank 0:             parallelizationStartEpoch = 1
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:                 useBufferedAsyncGradientAggregation = $asyncBuffer$
MPI Rank 0:             ]
MPI Rank 0:             ModelAveragingSGD = [
MPI Rank 0:                 blockSizePerWorker = 128
MPI Rank 0:             ]
MPI Rank 0:             DataParallelASGD = [
MPI Rank 0:                 syncPeriod = 128
MPI Rank 0:                 usePipeline = $asyncBuffer$
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "$DataDir$/train_map.txt"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "RandomSide"
MPI Rank 0:             sideRatio = 0.8
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "$DataDir$/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     cvReader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "$DataDir$/test_map.txt"
MPI Rank 0:         randomize = "none"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "Center"
MPI Rank 0:             sideRatio = 1
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "$DataDir$/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]    
MPI Rank 0: ]
MPI Rank 0: Test = [
MPI Rank 0:     action = "test"
MPI Rank 0:     modelPath = "$ModelDir$/03_ResNet"
MPI Rank 0:     minibatchSize = 256
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "$DataDir$/cifar-10-batches-py/test_map.txt"
MPI Rank 0:         randomize = "none"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "Center"
MPI Rank 0:             sideRatio = 1
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "$DataDir$/cifar-10-batches-py/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]    
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 0: RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 0: DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD
MPI Rank 0: OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: precision=float
MPI Rank 0: parallelTrain=true
MPI Rank 0: minibatch=256
MPI Rank 0: epochsize=12
MPI Rank 0: asyncBuffer="false"
MPI Rank 0: parallelizationMethod=DataParallelASGD
MPI Rank 0: stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Configuration After Variable Resolution:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: makeMode = true
MPI Rank 0: RootDir = "."
MPI Rank 0: configName = "asgd"
MPI Rank 0: minibatch = 128
MPI Rank 0: epochSize = 5
MPI Rank 0: parallelizationMethod = "DataParallelASGD"
MPI Rank 0: asyncBuffer = "true"
MPI Rank 0: ConfigDir = "."
MPI Rank 0: DataDir = "."
MPI Rank 0: OutputDir = "./Output-asgd"
MPI Rank 0: ModelDir = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models"
MPI Rank 0: ndlMacros = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/Macros.ndl"
MPI Rank 0: precision = "float"
MPI Rank 0: DeviceId = 0
MPI Rank 0: imageLayout = "cudnn"
MPI Rank 0: initOnCPUOnly=true
MPI Rank 0: prefetch = "true"
MPI Rank 0: parallelTrain = "false"
MPI Rank 0: command = Train
MPI Rank 0: stderr = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Asgd_ResNet"
MPI Rank 0: traceLevel = 1
MPI Rank 0: Proj16to32Filename = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/16to32.txt"
MPI Rank 0: Proj32to64Filename = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/32to64.txt"
MPI Rank 0: Train = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model"
MPI Rank 0:      NDLNetworkBuilder = [
MPI Rank 0:         networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet.ndl"
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 0
MPI Rank 0:         minibatchSize = 256
MPI Rank 0:         learningRatesPerSample = 0.004*80:0.0004*40:0.00004
MPI Rank 0:         momentumPerMB = 0
MPI Rank 0:         maxEpochs = 12
MPI Rank 0:         L2RegWeight = 0.0001
MPI Rank 0:         dropoutRate = 0
MPI Rank 0:         perfTraceLevel = 0
MPI Rank 0:         firstMBsToShowResult = 1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = DataParallelASGD
MPI Rank 0:             distributedMBReading = "true"
MPI Rank 0:             parallelizationStartEpoch = 1
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:                 useBufferedAsyncGradientAggregation = false
MPI Rank 0:             ]
MPI Rank 0:             ModelAveragingSGD = [
MPI Rank 0:                 blockSizePerWorker = 128
MPI Rank 0:             ]
MPI Rank 0:             DataParallelASGD = [
MPI Rank 0:                 syncPeriod = 128
MPI Rank 0:                 usePipeline = false
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/train_map.txt"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "RandomSide"
MPI Rank 0:             sideRatio = 0.8
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     cvReader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/test_map.txt"
MPI Rank 0:         randomize = "none"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "Center"
MPI Rank 0:             sideRatio = 1
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]    
MPI Rank 0: ]
MPI Rank 0: Test = [
MPI Rank 0:     action = "test"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/03_ResNet"
MPI Rank 0:     minibatchSize = 256
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/test_map.txt"
MPI Rank 0:         randomize = "none"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "Center"
MPI Rank 0:             sideRatio = 1
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]    
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 0: RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 0: DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD
MPI Rank 0: OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: precision=float
MPI Rank 0: parallelTrain=true
MPI Rank 0: minibatch=256
MPI Rank 0: epochsize=12
MPI Rank 0: asyncBuffer="false"
MPI Rank 0: parallelizationMethod=DataParallelASGD
MPI Rank 0: stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Configuration After Processing and Variable Resolution:
MPI Rank 0: 
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:asyncBuffer=false
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:command=Train
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:configName=asgd
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:DeviceId=0
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:epochSize=12
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:imageLayout=cudnn
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:initOnCPUOnly=true
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:makeMode=true
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:minibatch=256
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:ModelDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/Macros.ndl
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:numCPUThreads=1
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:parallelizationMethod=DataParallelASGD
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:parallelTrain=true
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:precision=float
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:prefetch=true
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:Proj16to32Filename=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/16to32.txt
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:Proj32to64Filename=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/32to64.txt
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:RootDir=.
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:Test=[
MPI Rank 0:     action = "test"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/03_ResNet"
MPI Rank 0:     minibatchSize = 256
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/test_map.txt"
MPI Rank 0:         randomize = "none"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "Center"
MPI Rank 0:             sideRatio = 1
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]    
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:timestamping=true
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:traceLevel=1
MPI Rank 0: configparameters: 03_ResNet-parallel.cntk:Train=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model"
MPI Rank 0:      NDLNetworkBuilder = [
MPI Rank 0:         networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet.ndl"
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 0
MPI Rank 0:         minibatchSize = 256
MPI Rank 0:         learningRatesPerSample = 0.004*80:0.0004*40:0.00004
MPI Rank 0:         momentumPerMB = 0
MPI Rank 0:         maxEpochs = 12
MPI Rank 0:         L2RegWeight = 0.0001
MPI Rank 0:         dropoutRate = 0
MPI Rank 0:         perfTraceLevel = 0
MPI Rank 0:         firstMBsToShowResult = 1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = DataParallelASGD
MPI Rank 0:             distributedMBReading = "true"
MPI Rank 0:             parallelizationStartEpoch = 1
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:                 useBufferedAsyncGradientAggregation = false
MPI Rank 0:             ]
MPI Rank 0:             ModelAveragingSGD = [
MPI Rank 0:                 blockSizePerWorker = 128
MPI Rank 0:             ]
MPI Rank 0:             DataParallelASGD = [
MPI Rank 0:                 syncPeriod = 128
MPI Rank 0:                 usePipeline = false
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/train_map.txt"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "RandomSide"
MPI Rank 0:             sideRatio = 0.8
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     cvReader = [
MPI Rank 0:         readerType = "ImageReader"
MPI Rank 0:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/test_map.txt"
MPI Rank 0:         randomize = "none"
MPI Rank 0:         features = [
MPI Rank 0:             width = 32
MPI Rank 0:             height = 32
MPI Rank 0:             channels = 3
MPI Rank 0:             cropType = "Center"
MPI Rank 0:             sideRatio = 1
MPI Rank 0:             jitterType = "UniRatio"
MPI Rank 0:             interpolations = "linear"
MPI Rank 0:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             labelDim = 10
MPI Rank 0:         ]
MPI Rank 0:     ]    
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: Commands: Train
MPI Rank 0: 08/21/2017 14:27:04: precision = "float"
MPI Rank 0: 08/21/2017 14:27:04: Using 1 CPU threads.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: ##############################################################################
MPI Rank 0: 08/21/2017 14:27:04: #                                                                            #
MPI Rank 0: 08/21/2017 14:27:04: # Train command (train action)                                               #
MPI Rank 0: 08/21/2017 14:27:04: #                                                                            #
MPI Rank 0: 08/21/2017 14:27:04: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:04: 
MPI Rank 0: Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.1'.
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: conv1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 16, Kernel: 3 x 3 x 3, Map: 1 x 1 x 16, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn1_1.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn1_1.c2.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn1_2.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn1_2.c2.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn1_3.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn1_3.c2.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_1.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 16 x 16 x 32, Kernel: 3 x 3 x 16, Map: 1 x 1 x 32, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_1.c2.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_1.c_proj.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 16 x 16 x 32, Kernel: 1 x 1 x 16, Map: 1 x 1 x 32, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_2.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_2.c2.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_3.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn2_3.c2.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_1.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 8 x 8 x 64, Kernel: 3 x 3 x 32, Map: 1 x 1 x 64, Stride: 2 x 2 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_1.c2.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_1.c_proj.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 8 x 8 x 64, Kernel: 1 x 1 x 32, Map: 1 x 1 x 64, Stride: 2 x 2 x 32, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_2.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_2.c2.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_3.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: rn3_3.c2.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 0: Using CNTK batch normalization engine.
MPI Rank 0: pool: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 1 x 1 x 64, Kernel: 8 x 8 x 1, Map: 1, Stride: 1 x 1 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
MPI Rank 0: 08/21/2017 14:27:06: 
MPI Rank 0: Model has 205 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:06: Training criterion:   CE = CrossEntropyWithSoftmax
MPI Rank 0: 08/21/2017 14:27:06: Evaluation criterion: Err = ClassificationError
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:06: Training 269914 parameters in 63 out of 63 parameter tensors and 137 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'OutputNodes.W' (LearnableParameter operation) : [10 x 1 x 1 x 64]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'OutputNodes.b' (LearnableParameter operation) : [10]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'conv1.c.W' (LearnableParameter operation) : [16 x 27]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'conv1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'conv1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_1.c1.c.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_1.c1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_1.c1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_1.c2.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_1.c2.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_1.c2.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_2.c1.c.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_2.c1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_2.c1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_2.c2.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_2.c2.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_2.c2.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_3.c1.c.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_3.c1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_3.c1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_3.c2.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_3.c2.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn1_3.c2.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c1.c.W' (LearnableParameter operation) : [32 x 144]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c1.c.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c1.c.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c2.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c2.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c2.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c_proj.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_1.c_proj.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_2.c1.c.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_2.c1.c.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_2.c1.c.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_2.c2.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_2.c2.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_2.c2.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_3.c1.c.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_3.c1.c.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_3.c1.c.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_3.c2.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_3.c2.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn2_3.c2.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c1.c.W' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c1.c.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c1.c.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c2.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c2.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c2.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c_proj.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_1.c_proj.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_2.c1.c.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_2.c1.c.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_2.c1.c.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_2.c2.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_2.c2.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_2.c2.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_3.c1.c.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_3.c1.c.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_3.c1.c.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_3.c2.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_3.c2.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 08/21/2017 14:27:06: 	Node 'rn3_3.c2.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:06: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 08/21/2017 14:27:06: Warning: Checkpoint file is missing. Parameter-learning state (such as momentum) will be reset.
MPI Rank 0: [INFO] [2017-08-21 14:27:06] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
MPI Rank 0: [INFO] [2017-08-21 14:27:07] All nodes registered. System contains 2 nodes. num_worker = 2, num_server = 2
MPI Rank 0: [INFO] [2017-08-21 14:27:07] Create a async server
MPI Rank 0: [INFO] [2017-08-21 14:27:07] Rank 0: Multiverso start successfully
MPI Rank 0: multiverso initial model loaded.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:07: Starting Epoch 2: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:07: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:27:08:  Epoch[ 2 of 12]-Minibatch[   1-   1]: CE = 1.75266480 * 128; Err = 0.73437500 * 128; time = 0.5689s; samplesPerSecond = 225.0
MPI Rank 0: 08/21/2017 14:27:10:  Epoch[ 2 of 12]-Minibatch[   2-  10]: CE = 1.79176646 * 1152; Err = 0.69618056 * 1152; time = 2.4720s; samplesPerSecond = 466.0
MPI Rank 0: 08/21/2017 14:27:12:  Epoch[ 2 of 12]-Minibatch[  11-  20]: CE = 1.81580353 * 1280; Err = 0.67578125 * 1280; time = 1.8605s; samplesPerSecond = 688.0
MPI Rank 0: 08/21/2017 14:27:14:  Epoch[ 2 of 12]-Minibatch[  21-  30]: CE = 1.76559830 * 1280; Err = 0.66093750 * 1280; time = 1.8880s; samplesPerSecond = 678.0
MPI Rank 0: 08/21/2017 14:27:16:  Epoch[ 2 of 12]-Minibatch[  31-  40]: CE = 1.72169724 * 1280; Err = 0.64843750 * 1280; time = 1.9413s; samplesPerSecond = 659.4
MPI Rank 0: 08/21/2017 14:27:18:  Epoch[ 2 of 12]-Minibatch[  41-  50]: CE = 1.66450958 * 1280; Err = 0.62343750 * 1280; time = 1.8679s; samplesPerSecond = 685.3
MPI Rank 0: 08/21/2017 14:27:19:  Epoch[ 2 of 12]-Minibatch[  51-  60]: CE = 1.68855438 * 1280; Err = 0.66250000 * 1280; time = 1.7576s; samplesPerSecond = 728.2
MPI Rank 0: 08/21/2017 14:27:21:  Epoch[ 2 of 12]-Minibatch[  61-  70]: CE = 1.70248413 * 1280; Err = 0.63359375 * 1280; time = 1.9813s; samplesPerSecond = 646.0
MPI Rank 0: 08/21/2017 14:27:23:  Epoch[ 2 of 12]-Minibatch[  71-  80]: CE = 1.67400284 * 1280; Err = 0.63359375 * 1280; time = 1.8837s; samplesPerSecond = 679.5
MPI Rank 0: 08/21/2017 14:27:25:  Epoch[ 2 of 12]-Minibatch[  81-  90]: CE = 1.59696655 * 1280; Err = 0.61171875 * 1280; time = 1.8877s; samplesPerSecond = 678.1
MPI Rank 0: 08/21/2017 14:27:27:  Epoch[ 2 of 12]-Minibatch[  91- 100]: CE = 1.61097107 * 1280; Err = 0.60937500 * 1280; time = 1.8381s; samplesPerSecond = 696.4
MPI Rank 0: 08/21/2017 14:27:29:  Epoch[ 2 of 12]-Minibatch[ 101- 110]: CE = 1.64262543 * 1280; Err = 0.61171875 * 1280; time = 1.8479s; samplesPerSecond = 692.7
MPI Rank 0: 08/21/2017 14:27:31:  Epoch[ 2 of 12]-Minibatch[ 111- 120]: CE = 1.66050415 * 1280; Err = 0.63046875 * 1280; time = 1.8481s; samplesPerSecond = 692.6
MPI Rank 0: 08/21/2017 14:27:33:  Epoch[ 2 of 12]-Minibatch[ 121- 130]: CE = 1.60585175 * 1280; Err = 0.60781250 * 1280; time = 1.9289s; samplesPerSecond = 663.6
MPI Rank 0: 08/21/2017 14:27:35:  Epoch[ 2 of 12]-Minibatch[ 131- 140]: CE = 1.59301300 * 1280; Err = 0.60468750 * 1280; time = 1.9107s; samplesPerSecond = 669.9
MPI Rank 0: 08/21/2017 14:27:36:  Epoch[ 2 of 12]-Minibatch[ 141- 150]: CE = 1.62123566 * 1280; Err = 0.59921875 * 1280; time = 1.7796s; samplesPerSecond = 719.3
MPI Rank 0: 08/21/2017 14:27:38:  Epoch[ 2 of 12]-Minibatch[ 151- 160]: CE = 1.57940216 * 1280; Err = 0.56875000 * 1280; time = 1.9306s; samplesPerSecond = 663.0
MPI Rank 0: 08/21/2017 14:27:40:  Epoch[ 2 of 12]-Minibatch[ 161- 170]: CE = 1.50358887 * 1280; Err = 0.56093750 * 1280; time = 1.7922s; samplesPerSecond = 714.2
MPI Rank 0: 08/21/2017 14:27:42:  Epoch[ 2 of 12]-Minibatch[ 171- 180]: CE = 1.58321838 * 1280; Err = 0.58281250 * 1280; time = 1.8097s; samplesPerSecond = 707.3
MPI Rank 0: 08/21/2017 14:27:44:  Epoch[ 2 of 12]-Minibatch[ 181- 190]: CE = 1.54472351 * 1280; Err = 0.58671875 * 1280; time = 1.9203s; samplesPerSecond = 666.6
MPI Rank 0: 08/21/2017 14:27:45: Finished Epoch[ 2 of 12]: [Training] CE = 1.64679375 * 25000; Err = 0.62064000 * 25000; totalSamplesSeen = 25000; learningRatePerSample = 0.0040000002; epochTime=37.7589s
MPI Rank 0: 08/21/2017 14:27:50: Final Results: Minibatch[1-79]: CE = 1.54902424 * 10000; perplexity = 4.70687514; Err = 0.58110000 * 10000
MPI Rank 0: 08/21/2017 14:27:50: Finished Epoch[ 2 of 12]: [Validate] CE = 1.54902424 * 10000; Err = 0.58110000 * 10000
MPI Rank 0: 08/21/2017 14:27:50: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.2'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:50: Starting Epoch 3: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:27:50: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:27:51:  Epoch[ 3 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.43296838 * 128; Err = 0.52343750 * 128; time = 0.3235s; samplesPerSecond = 395.7
MPI Rank 0: 08/21/2017 14:27:52:  Epoch[ 3 of 12]-Minibatch[   2-  10, 10.53%]: CE = 1.45388050 * 1152; Err = 0.53125000 * 1152; time = 1.6069s; samplesPerSecond = 716.9
MPI Rank 0: 08/21/2017 14:27:54:  Epoch[ 3 of 12]-Minibatch[  11-  20, 21.05%]: CE = 1.49322872 * 1280; Err = 0.57421875 * 1280; time = 1.7850s; samplesPerSecond = 717.1
MPI Rank 0: 08/21/2017 14:27:56:  Epoch[ 3 of 12]-Minibatch[  21-  30, 31.58%]: CE = 1.50451546 * 1280; Err = 0.57109375 * 1280; time = 1.8139s; samplesPerSecond = 705.7
MPI Rank 0: 08/21/2017 14:27:58:  Epoch[ 3 of 12]-Minibatch[  31-  40, 42.11%]: CE = 1.41673584 * 1280; Err = 0.52421875 * 1280; time = 1.7675s; samplesPerSecond = 724.2
MPI Rank 0: 08/21/2017 14:28:00:  Epoch[ 3 of 12]-Minibatch[  41-  50, 52.63%]: CE = 1.44027977 * 1280; Err = 0.51562500 * 1280; time = 1.9455s; samplesPerSecond = 657.9
MPI Rank 0: 08/21/2017 14:28:01:  Epoch[ 3 of 12]-Minibatch[  51-  60, 63.16%]: CE = 1.46631775 * 1280; Err = 0.54453125 * 1280; time = 1.7960s; samplesPerSecond = 712.7
MPI Rank 0: 08/21/2017 14:28:03:  Epoch[ 3 of 12]-Minibatch[  61-  70, 73.68%]: CE = 1.44390717 * 1280; Err = 0.52031250 * 1280; time = 2.0352s; samplesPerSecond = 628.9
MPI Rank 0: 08/21/2017 14:28:05:  Epoch[ 3 of 12]-Minibatch[  71-  80, 84.21%]: CE = 1.39712982 * 1280; Err = 0.51406250 * 1280; time = 1.7878s; samplesPerSecond = 716.0
MPI Rank 0: 08/21/2017 14:28:07:  Epoch[ 3 of 12]-Minibatch[  81-  90, 94.74%]: CE = 1.43191071 * 1280; Err = 0.49843750 * 1280; time = 1.8502s; samplesPerSecond = 691.8
MPI Rank 0: 08/21/2017 14:28:09:  Epoch[ 3 of 12]-Minibatch[  91- 100, 105.26%]: CE = 1.46269684 * 1280; Err = 0.52968750 * 1280; time = 1.6731s; samplesPerSecond = 765.1
MPI Rank 0: 08/21/2017 14:28:10:  Epoch[ 3 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 1.39177856 * 1280; Err = 0.52656250 * 1280; time = 1.7733s; samplesPerSecond = 721.8
MPI Rank 0: 08/21/2017 14:28:12:  Epoch[ 3 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 1.36581421 * 1280; Err = 0.51796875 * 1280; time = 1.7977s; samplesPerSecond = 712.0
MPI Rank 0: 08/21/2017 14:28:14:  Epoch[ 3 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 1.37913666 * 1280; Err = 0.49687500 * 1280; time = 1.7176s; samplesPerSecond = 745.2
MPI Rank 0: 08/21/2017 14:28:16:  Epoch[ 3 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 1.35779114 * 1280; Err = 0.51484375 * 1280; time = 1.7603s; samplesPerSecond = 727.1
MPI Rank 0: 08/21/2017 14:28:18:  Epoch[ 3 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 1.33753662 * 1280; Err = 0.48671875 * 1280; time = 1.8448s; samplesPerSecond = 693.9
MPI Rank 0: 08/21/2017 14:28:19:  Epoch[ 3 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 1.28441925 * 1280; Err = 0.47734375 * 1280; time = 1.7910s; samplesPerSecond = 714.7
MPI Rank 0: 08/21/2017 14:28:21:  Epoch[ 3 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 1.31036072 * 1280; Err = 0.46015625 * 1280; time = 1.8629s; samplesPerSecond = 687.1
MPI Rank 0: 08/21/2017 14:28:23:  Epoch[ 3 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 1.24981689 * 1280; Err = 0.46875000 * 1280; time = 1.9377s; samplesPerSecond = 660.6
MPI Rank 0: 08/21/2017 14:28:25:  Epoch[ 3 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 1.30120544 * 1280; Err = 0.47968750 * 1280; time = 1.8415s; samplesPerSecond = 695.1
MPI Rank 0: 08/21/2017 14:28:26: Finished Epoch[ 3 of 12]: [Training] CE = 1.39023094 * 25000; Err = 0.51148000 * 25000; totalSamplesSeen = 50000; learningRatePerSample = 0.0040000002; epochTime=35.8878s
MPI Rank 0: 08/21/2017 14:28:31: Final Results: Minibatch[1-79]: CE = 1.52877449 * 10000; perplexity = 4.61252066; Err = 0.51780000 * 10000
MPI Rank 0: 08/21/2017 14:28:31: Finished Epoch[ 3 of 12]: [Validate] CE = 1.52877449 * 10000; Err = 0.51780000 * 10000
MPI Rank 0: 08/21/2017 14:28:32: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.3'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:28:32: Starting Epoch 4: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:28:32: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:28:33:  Epoch[ 4 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.31189489 * 128; Err = 0.46875000 * 128; time = 0.2692s; samplesPerSecond = 475.4
MPI Rank 0: 08/21/2017 14:28:34:  Epoch[ 4 of 12]-Minibatch[   2-  10, 10.53%]: CE = 1.22954851 * 1152; Err = 0.44444444 * 1152; time = 1.6258s; samplesPerSecond = 708.6
MPI Rank 0: 08/21/2017 14:28:36:  Epoch[ 4 of 12]-Minibatch[  11-  20, 21.05%]: CE = 1.26088934 * 1280; Err = 0.44921875 * 1280; time = 1.9653s; samplesPerSecond = 651.3
MPI Rank 0: 08/21/2017 14:28:38:  Epoch[ 4 of 12]-Minibatch[  21-  30, 31.58%]: CE = 1.24845657 * 1280; Err = 0.43750000 * 1280; time = 1.8046s; samplesPerSecond = 709.3
MPI Rank 0: 08/21/2017 14:28:40:  Epoch[ 4 of 12]-Minibatch[  31-  40, 42.11%]: CE = 1.23276291 * 1280; Err = 0.46171875 * 1280; time = 1.7459s; samplesPerSecond = 733.1
MPI Rank 0: 08/21/2017 14:28:41:  Epoch[ 4 of 12]-Minibatch[  41-  50, 52.63%]: CE = 1.22121811 * 1280; Err = 0.44296875 * 1280; time = 1.8037s; samplesPerSecond = 709.6
MPI Rank 0: 08/21/2017 14:28:43:  Epoch[ 4 of 12]-Minibatch[  51-  60, 63.16%]: CE = 1.20099792 * 1280; Err = 0.42734375 * 1280; time = 1.7942s; samplesPerSecond = 713.4
MPI Rank 0: 08/21/2017 14:28:45:  Epoch[ 4 of 12]-Minibatch[  61-  70, 73.68%]: CE = 1.14807968 * 1280; Err = 0.41875000 * 1280; time = 1.9428s; samplesPerSecond = 658.8
MPI Rank 0: 08/21/2017 14:28:47:  Epoch[ 4 of 12]-Minibatch[  71-  80, 84.21%]: CE = 1.15436630 * 1280; Err = 0.42812500 * 1280; time = 1.8249s; samplesPerSecond = 701.4
MPI Rank 0: 08/21/2017 14:28:49:  Epoch[ 4 of 12]-Minibatch[  81-  90, 94.74%]: CE = 1.19830093 * 1280; Err = 0.45703125 * 1280; time = 1.7301s; samplesPerSecond = 739.9
MPI Rank 0: 08/21/2017 14:28:51:  Epoch[ 4 of 12]-Minibatch[  91- 100, 105.26%]: CE = 1.21202621 * 1280; Err = 0.42109375 * 1280; time = 1.8886s; samplesPerSecond = 677.7
MPI Rank 0: 08/21/2017 14:28:53:  Epoch[ 4 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 1.14015274 * 1280; Err = 0.41562500 * 1280; time = 1.9406s; samplesPerSecond = 659.6
MPI Rank 0: 08/21/2017 14:28:55:  Epoch[ 4 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 1.12425995 * 1280; Err = 0.40468750 * 1280; time = 1.9437s; samplesPerSecond = 658.5
MPI Rank 0: 08/21/2017 14:28:56:  Epoch[ 4 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 1.10669556 * 1280; Err = 0.40625000 * 1280; time = 1.8648s; samplesPerSecond = 686.4
MPI Rank 0: 08/21/2017 14:28:58:  Epoch[ 4 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 1.08291779 * 1280; Err = 0.39296875 * 1280; time = 1.8679s; samplesPerSecond = 685.3
MPI Rank 0: 08/21/2017 14:29:00:  Epoch[ 4 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 1.18403625 * 1280; Err = 0.44062500 * 1280; time = 1.8491s; samplesPerSecond = 692.2
MPI Rank 0: 08/21/2017 14:29:02:  Epoch[ 4 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 1.08225861 * 1280; Err = 0.39062500 * 1280; time = 1.8929s; samplesPerSecond = 676.2
MPI Rank 0: 08/21/2017 14:29:04:  Epoch[ 4 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 1.12737122 * 1280; Err = 0.42343750 * 1280; time = 1.8179s; samplesPerSecond = 704.1
MPI Rank 0: 08/21/2017 14:29:06:  Epoch[ 4 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 1.02829742 * 1280; Err = 0.38046875 * 1280; time = 1.8422s; samplesPerSecond = 694.8
MPI Rank 0: 08/21/2017 14:29:08:  Epoch[ 4 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 1.12045746 * 1280; Err = 0.39375000 * 1280; time = 1.8521s; samplesPerSecond = 691.1
MPI Rank 0: 08/21/2017 14:29:09: Finished Epoch[ 4 of 12]: [Training] CE = 1.16154359 * 25000; Err = 0.42148000 * 25000; totalSamplesSeen = 75000; learningRatePerSample = 0.0040000002; epochTime=36.3233s
MPI Rank 0: 08/21/2017 14:29:14: Final Results: Minibatch[1-79]: CE = 1.47953015 * 10000; perplexity = 4.39088213; Err = 0.49100000 * 10000
MPI Rank 0: 08/21/2017 14:29:14: Finished Epoch[ 4 of 12]: [Validate] CE = 1.47953015 * 10000; Err = 0.49100000 * 10000
MPI Rank 0: 08/21/2017 14:29:14: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.4'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:29:14: Starting Epoch 5: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:29:14: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:29:14:  Epoch[ 5 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.06338370 * 128; Err = 0.34375000 * 128; time = 0.2385s; samplesPerSecond = 536.7
MPI Rank 0: 08/21/2017 14:29:16:  Epoch[ 5 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.98811185 * 1152; Err = 0.36111111 * 1152; time = 1.5920s; samplesPerSecond = 723.6
MPI Rank 0: 08/21/2017 14:29:18:  Epoch[ 5 of 12]-Minibatch[  11-  20, 21.05%]: CE = 1.01755981 * 1280; Err = 0.36484375 * 1280; time = 1.9082s; samplesPerSecond = 670.8
MPI Rank 0: 08/21/2017 14:29:20:  Epoch[ 5 of 12]-Minibatch[  21-  30, 31.58%]: CE = 1.06132698 * 1280; Err = 0.38281250 * 1280; time = 1.7289s; samplesPerSecond = 740.3
MPI Rank 0: 08/21/2017 14:29:21:  Epoch[ 5 of 12]-Minibatch[  31-  40, 42.11%]: CE = 1.00064468 * 1280; Err = 0.36093750 * 1280; time = 1.8156s; samplesPerSecond = 705.0
MPI Rank 0: 08/21/2017 14:29:23:  Epoch[ 5 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.97594414 * 1280; Err = 0.34921875 * 1280; time = 1.8856s; samplesPerSecond = 678.8
MPI Rank 0: 08/21/2017 14:29:25:  Epoch[ 5 of 12]-Minibatch[  51-  60, 63.16%]: CE = 1.01656685 * 1280; Err = 0.36171875 * 1280; time = 1.7088s; samplesPerSecond = 749.1
MPI Rank 0: 08/21/2017 14:29:27:  Epoch[ 5 of 12]-Minibatch[  61-  70, 73.68%]: CE = 1.02010078 * 1280; Err = 0.37656250 * 1280; time = 1.8952s; samplesPerSecond = 675.4
MPI Rank 0: 08/21/2017 14:29:29:  Epoch[ 5 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.90821838 * 1280; Err = 0.31093750 * 1280; time = 1.8461s; samplesPerSecond = 693.4
MPI Rank 0: 08/21/2017 14:29:31:  Epoch[ 5 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.97280045 * 1280; Err = 0.33906250 * 1280; time = 1.8070s; samplesPerSecond = 708.4
MPI Rank 0: 08/21/2017 14:29:32:  Epoch[ 5 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.95595627 * 1280; Err = 0.33906250 * 1280; time = 1.8592s; samplesPerSecond = 688.5
MPI Rank 0: 08/21/2017 14:29:34:  Epoch[ 5 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.99815598 * 1280; Err = 0.36640625 * 1280; time = 1.7861s; samplesPerSecond = 716.6
MPI Rank 0: 08/21/2017 14:29:36:  Epoch[ 5 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.98750763 * 1280; Err = 0.34140625 * 1280; time = 1.8762s; samplesPerSecond = 682.2
MPI Rank 0: 08/21/2017 14:29:38:  Epoch[ 5 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.93508224 * 1280; Err = 0.32890625 * 1280; time = 1.7840s; samplesPerSecond = 717.5
MPI Rank 0: 08/21/2017 14:29:40:  Epoch[ 5 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.92209473 * 1280; Err = 0.31953125 * 1280; time = 1.7568s; samplesPerSecond = 728.6
MPI Rank 0: 08/21/2017 14:29:41:  Epoch[ 5 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.97970581 * 1280; Err = 0.35546875 * 1280; time = 1.8337s; samplesPerSecond = 698.0
MPI Rank 0: 08/21/2017 14:29:43:  Epoch[ 5 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.94369965 * 1280; Err = 0.33281250 * 1280; time = 1.8508s; samplesPerSecond = 691.6
MPI Rank 0: 08/21/2017 14:29:45:  Epoch[ 5 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.85486603 * 1280; Err = 0.30781250 * 1280; time = 1.8592s; samplesPerSecond = 688.5
MPI Rank 0: 08/21/2017 14:29:47:  Epoch[ 5 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.93342896 * 1280; Err = 0.32421875 * 1280; time = 1.9150s; samplesPerSecond = 668.4
MPI Rank 0: 08/21/2017 14:29:49:  Epoch[ 5 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.90465088 * 1280; Err = 0.32265625 * 1280; time = 1.8446s; samplesPerSecond = 693.9
MPI Rank 0: 08/21/2017 14:29:50: Finished Epoch[ 5 of 12]: [Training] CE = 0.96649000 * 25000; Err = 0.34440000 * 25000; totalSamplesSeen = 100000; learningRatePerSample = 0.0040000002; epochTime=35.8696s
MPI Rank 0: 08/21/2017 14:29:55: Final Results: Minibatch[1-79]: CE = 1.51460792 * 10000; perplexity = 4.54763773; Err = 0.45230000 * 10000
MPI Rank 0: 08/21/2017 14:29:55: Finished Epoch[ 5 of 12]: [Validate] CE = 1.51460792 * 10000; Err = 0.45230000 * 10000
MPI Rank 0: 08/21/2017 14:29:56: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.5'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:29:56: Starting Epoch 6: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:29:56: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:29:56:  Epoch[ 6 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.02566671 * 128; Err = 0.38281250 * 128; time = 0.2590s; samplesPerSecond = 494.2
MPI Rank 0: 08/21/2017 14:29:58:  Epoch[ 6 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.89924426 * 1152; Err = 0.31250000 * 1152; time = 1.6543s; samplesPerSecond = 696.4
MPI Rank 0: 08/21/2017 14:30:00:  Epoch[ 6 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.83188295 * 1280; Err = 0.29296875 * 1280; time = 1.8221s; samplesPerSecond = 702.5
MPI Rank 0: 08/21/2017 14:30:01:  Epoch[ 6 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.88224983 * 1280; Err = 0.31406250 * 1280; time = 1.8797s; samplesPerSecond = 681.0
MPI Rank 0: 08/21/2017 14:30:03:  Epoch[ 6 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.86690903 * 1280; Err = 0.29296875 * 1280; time = 1.9360s; samplesPerSecond = 661.2
MPI Rank 0: 08/21/2017 14:30:05:  Epoch[ 6 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.90117378 * 1280; Err = 0.31328125 * 1280; time = 1.9306s; samplesPerSecond = 663.0
MPI Rank 0: 08/21/2017 14:30:07:  Epoch[ 6 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.88564682 * 1280; Err = 0.31562500 * 1280; time = 1.7860s; samplesPerSecond = 716.7
MPI Rank 0: 08/21/2017 14:30:09:  Epoch[ 6 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.84121361 * 1280; Err = 0.29531250 * 1280; time = 1.9186s; samplesPerSecond = 667.1
MPI Rank 0: 08/21/2017 14:30:11:  Epoch[ 6 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.86103897 * 1280; Err = 0.31953125 * 1280; time = 1.8493s; samplesPerSecond = 692.2
MPI Rank 0: 08/21/2017 14:30:13:  Epoch[ 6 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.89255142 * 1280; Err = 0.31015625 * 1280; time = 1.9407s; samplesPerSecond = 659.5
MPI Rank 0: 08/21/2017 14:30:15:  Epoch[ 6 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.79427719 * 1280; Err = 0.28203125 * 1280; time = 1.8242s; samplesPerSecond = 701.7
MPI Rank 0: 08/21/2017 14:30:16:  Epoch[ 6 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.84332657 * 1280; Err = 0.30234375 * 1280; time = 1.7922s; samplesPerSecond = 714.2
MPI Rank 0: 08/21/2017 14:30:18:  Epoch[ 6 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.83116531 * 1280; Err = 0.29921875 * 1280; time = 1.8043s; samplesPerSecond = 709.4
MPI Rank 0: 08/21/2017 14:30:20:  Epoch[ 6 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.82459030 * 1280; Err = 0.28906250 * 1280; time = 1.8391s; samplesPerSecond = 696.0
MPI Rank 0: 08/21/2017 14:30:22:  Epoch[ 6 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.79201431 * 1280; Err = 0.26562500 * 1280; time = 1.8851s; samplesPerSecond = 679.0
MPI Rank 0: 08/21/2017 14:30:24:  Epoch[ 6 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.80140381 * 1280; Err = 0.27031250 * 1280; time = 1.7941s; samplesPerSecond = 713.4
MPI Rank 0: 08/21/2017 14:30:26:  Epoch[ 6 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.86621628 * 1280; Err = 0.30703125 * 1280; time = 1.9482s; samplesPerSecond = 657.0
MPI Rank 0: 08/21/2017 14:30:27:  Epoch[ 6 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.79977722 * 1280; Err = 0.27578125 * 1280; time = 1.7595s; samplesPerSecond = 727.5
MPI Rank 0: 08/21/2017 14:30:29:  Epoch[ 6 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.80727081 * 1280; Err = 0.28593750 * 1280; time = 1.8874s; samplesPerSecond = 678.2
MPI Rank 0: 08/21/2017 14:30:31:  Epoch[ 6 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.78590240 * 1280; Err = 0.27500000 * 1280; time = 1.9018s; samplesPerSecond = 673.1
MPI Rank 0: 08/21/2017 14:30:32: Finished Epoch[ 6 of 12]: [Training] CE = 0.84221828 * 25000; Err = 0.29560000 * 25000; totalSamplesSeen = 125000; learningRatePerSample = 0.0040000002; epochTime=36.4234s
MPI Rank 0: 08/21/2017 14:30:38: Final Results: Minibatch[1-79]: CE = 0.88149213 * 10000; perplexity = 2.41449977; Err = 0.30630000 * 10000
MPI Rank 0: 08/21/2017 14:30:38: Finished Epoch[ 6 of 12]: [Validate] CE = 0.88149213 * 10000; Err = 0.30630000 * 10000
MPI Rank 0: 08/21/2017 14:30:38: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.6'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:30:38: Starting Epoch 7: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:30:38: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:30:38:  Epoch[ 7 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.80974782 * 128; Err = 0.25781250 * 128; time = 0.2869s; samplesPerSecond = 446.2
MPI Rank 0: 08/21/2017 14:30:40:  Epoch[ 7 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.76886865 * 1152; Err = 0.27430556 * 1152; time = 1.6182s; samplesPerSecond = 711.9
MPI Rank 0: 08/21/2017 14:30:41:  Epoch[ 7 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.75889864 * 1280; Err = 0.26718750 * 1280; time = 1.8572s; samplesPerSecond = 689.2
MPI Rank 0: 08/21/2017 14:30:43:  Epoch[ 7 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.83523369 * 1280; Err = 0.28593750 * 1280; time = 1.8424s; samplesPerSecond = 694.7
MPI Rank 0: 08/21/2017 14:30:45:  Epoch[ 7 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.71934891 * 1280; Err = 0.25156250 * 1280; time = 1.8566s; samplesPerSecond = 689.4
MPI Rank 0: 08/21/2017 14:30:47:  Epoch[ 7 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.73547611 * 1280; Err = 0.26250000 * 1280; time = 1.9109s; samplesPerSecond = 669.8
MPI Rank 0: 08/21/2017 14:30:49:  Epoch[ 7 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.78139839 * 1280; Err = 0.27656250 * 1280; time = 1.8617s; samplesPerSecond = 687.5
MPI Rank 0: 08/21/2017 14:30:51:  Epoch[ 7 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.70809593 * 1280; Err = 0.24609375 * 1280; time = 1.8114s; samplesPerSecond = 706.6
MPI Rank 0: 08/21/2017 14:30:53:  Epoch[ 7 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.75486755 * 1280; Err = 0.27187500 * 1280; time = 1.9684s; samplesPerSecond = 650.3
MPI Rank 0: 08/21/2017 14:30:55:  Epoch[ 7 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.76614532 * 1280; Err = 0.25312500 * 1280; time = 1.9279s; samplesPerSecond = 663.9
MPI Rank 0: 08/21/2017 14:30:56:  Epoch[ 7 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.76981277 * 1280; Err = 0.26562500 * 1280; time = 1.8061s; samplesPerSecond = 708.7
MPI Rank 0: 08/21/2017 14:30:58:  Epoch[ 7 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.72138062 * 1280; Err = 0.24921875 * 1280; time = 1.8808s; samplesPerSecond = 680.6
MPI Rank 0: 08/21/2017 14:31:00:  Epoch[ 7 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.71218491 * 1280; Err = 0.23437500 * 1280; time = 1.8884s; samplesPerSecond = 677.8
MPI Rank 0: 08/21/2017 14:31:02:  Epoch[ 7 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.77159576 * 1280; Err = 0.26015625 * 1280; time = 1.8082s; samplesPerSecond = 707.9
MPI Rank 0: 08/21/2017 14:31:04:  Epoch[ 7 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.80443192 * 1280; Err = 0.26484375 * 1280; time = 1.7272s; samplesPerSecond = 741.1
MPI Rank 0: 08/21/2017 14:31:06:  Epoch[ 7 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.73367081 * 1280; Err = 0.25312500 * 1280; time = 1.8769s; samplesPerSecond = 682.0
MPI Rank 0: 08/21/2017 14:31:07:  Epoch[ 7 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.74574432 * 1280; Err = 0.25546875 * 1280; time = 1.8557s; samplesPerSecond = 689.8
MPI Rank 0: 08/21/2017 14:31:09:  Epoch[ 7 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.75207443 * 1280; Err = 0.26875000 * 1280; time = 1.7107s; samplesPerSecond = 748.2
MPI Rank 0: 08/21/2017 14:31:11:  Epoch[ 7 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.73280487 * 1280; Err = 0.26640625 * 1280; time = 1.8785s; samplesPerSecond = 681.4
MPI Rank 0: 08/21/2017 14:31:13:  Epoch[ 7 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.76750336 * 1280; Err = 0.26406250 * 1280; time = 1.7839s; samplesPerSecond = 717.5
MPI Rank 0: 08/21/2017 14:31:14: Finished Epoch[ 7 of 12]: [Training] CE = 0.75455484 * 25000; Err = 0.26160000 * 25000; totalSamplesSeen = 150000; learningRatePerSample = 0.0040000002; epochTime=36.2264s
MPI Rank 0: 08/21/2017 14:31:19: Final Results: Minibatch[1-79]: CE = 0.82051735 * 10000; perplexity = 2.27167478; Err = 0.28640000 * 10000
MPI Rank 0: 08/21/2017 14:31:19: Finished Epoch[ 7 of 12]: [Validate] CE = 0.82051735 * 10000; Err = 0.28640000 * 10000
MPI Rank 0: 08/21/2017 14:31:20: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.7'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:31:20: Starting Epoch 8: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:31:20: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:31:20:  Epoch[ 8 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.64811420 * 128; Err = 0.25000000 * 128; time = 0.2667s; samplesPerSecond = 480.0
MPI Rank 0: 08/21/2017 14:31:22:  Epoch[ 8 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.68294011 * 1152; Err = 0.23003472 * 1152; time = 1.7163s; samplesPerSecond = 671.2
MPI Rank 0: 08/21/2017 14:31:24:  Epoch[ 8 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.71090093 * 1280; Err = 0.25625000 * 1280; time = 1.8412s; samplesPerSecond = 695.2
MPI Rank 0: 08/21/2017 14:31:26:  Epoch[ 8 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.70045309 * 1280; Err = 0.24531250 * 1280; time = 1.9211s; samplesPerSecond = 666.3
MPI Rank 0: 08/21/2017 14:31:27:  Epoch[ 8 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.70881176 * 1280; Err = 0.25703125 * 1280; time = 1.9258s; samplesPerSecond = 664.6
MPI Rank 0: 08/21/2017 14:31:29:  Epoch[ 8 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.74600315 * 1280; Err = 0.26562500 * 1280; time = 1.7853s; samplesPerSecond = 717.0
MPI Rank 0: 08/21/2017 14:31:31:  Epoch[ 8 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.73598862 * 1280; Err = 0.26093750 * 1280; time = 1.9206s; samplesPerSecond = 666.4
MPI Rank 0: 08/21/2017 14:31:33:  Epoch[ 8 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.75178299 * 1280; Err = 0.25859375 * 1280; time = 1.6849s; samplesPerSecond = 759.7
MPI Rank 0: 08/21/2017 14:31:35:  Epoch[ 8 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.65243340 * 1280; Err = 0.21875000 * 1280; time = 1.8387s; samplesPerSecond = 696.2
MPI Rank 0: 08/21/2017 14:31:36:  Epoch[ 8 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.66990395 * 1280; Err = 0.23281250 * 1280; time = 1.7629s; samplesPerSecond = 726.1
MPI Rank 0: 08/21/2017 14:31:38:  Epoch[ 8 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.67571220 * 1280; Err = 0.23906250 * 1280; time = 1.9534s; samplesPerSecond = 655.3
MPI Rank 0: 08/21/2017 14:31:40:  Epoch[ 8 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.65987320 * 1280; Err = 0.23046875 * 1280; time = 1.9074s; samplesPerSecond = 671.1
MPI Rank 0: 08/21/2017 14:31:42:  Epoch[ 8 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.63880234 * 1280; Err = 0.22656250 * 1280; time = 1.9340s; samplesPerSecond = 661.8
MPI Rank 0: 08/21/2017 14:31:44:  Epoch[ 8 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.65616913 * 1280; Err = 0.22812500 * 1280; time = 1.9468s; samplesPerSecond = 657.5
MPI Rank 0: 08/21/2017 14:31:46:  Epoch[ 8 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.69861145 * 1280; Err = 0.24062500 * 1280; time = 1.7236s; samplesPerSecond = 742.6
MPI Rank 0: 08/21/2017 14:31:48:  Epoch[ 8 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.71877213 * 1280; Err = 0.24687500 * 1280; time = 1.8516s; samplesPerSecond = 691.3
MPI Rank 0: 08/21/2017 14:31:50:  Epoch[ 8 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.72876434 * 1280; Err = 0.24296875 * 1280; time = 1.8752s; samplesPerSecond = 682.6
MPI Rank 0: 08/21/2017 14:31:51:  Epoch[ 8 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.67522736 * 1280; Err = 0.23203125 * 1280; time = 1.7266s; samplesPerSecond = 741.3
MPI Rank 0: 08/21/2017 14:31:53:  Epoch[ 8 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.66676636 * 1280; Err = 0.23593750 * 1280; time = 1.9332s; samplesPerSecond = 662.1
MPI Rank 0: 08/21/2017 14:31:55:  Epoch[ 8 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.65358582 * 1280; Err = 0.22890625 * 1280; time = 1.8704s; samplesPerSecond = 684.3
MPI Rank 0: 08/21/2017 14:31:56: Finished Epoch[ 8 of 12]: [Training] CE = 0.69185289 * 25000; Err = 0.24104000 * 25000; totalSamplesSeen = 175000; learningRatePerSample = 0.0040000002; epochTime=36.3806s
MPI Rank 0: 08/21/2017 14:32:01: Final Results: Minibatch[1-79]: CE = 0.94634126 * 10000; perplexity = 2.57626651; Err = 0.30440000 * 10000
MPI Rank 0: 08/21/2017 14:32:01: Finished Epoch[ 8 of 12]: [Validate] CE = 0.94634126 * 10000; Err = 0.30440000 * 10000
MPI Rank 0: 08/21/2017 14:32:01: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.8'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:32:01: Starting Epoch 9: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:32:01: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:32:02:  Epoch[ 9 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.64021331 * 128; Err = 0.28125000 * 128; time = 0.2818s; samplesPerSecond = 454.2
MPI Rank 0: 08/21/2017 14:32:03:  Epoch[ 9 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.66573632 * 1152; Err = 0.23003472 * 1152; time = 1.6566s; samplesPerSecond = 695.4
MPI Rank 0: 08/21/2017 14:32:05:  Epoch[ 9 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.62876544 * 1280; Err = 0.21171875 * 1280; time = 1.8953s; samplesPerSecond = 675.4
MPI Rank 0: 08/21/2017 14:32:07:  Epoch[ 9 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.66396599 * 1280; Err = 0.22500000 * 1280; time = 1.9398s; samplesPerSecond = 659.9
MPI Rank 0: 08/21/2017 14:32:09:  Epoch[ 9 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.61284256 * 1280; Err = 0.20859375 * 1280; time = 1.8798s; samplesPerSecond = 680.9
MPI Rank 0: 08/21/2017 14:32:11:  Epoch[ 9 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.71999512 * 1280; Err = 0.25156250 * 1280; time = 1.8536s; samplesPerSecond = 690.6
MPI Rank 0: 08/21/2017 14:32:13:  Epoch[ 9 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.62909126 * 1280; Err = 0.22031250 * 1280; time = 1.7734s; samplesPerSecond = 721.8
MPI Rank 0: 08/21/2017 14:32:15:  Epoch[ 9 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.71321716 * 1280; Err = 0.24921875 * 1280; time = 1.9368s; samplesPerSecond = 660.9
MPI Rank 0: 08/21/2017 14:32:16:  Epoch[ 9 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.68825455 * 1280; Err = 0.23359375 * 1280; time = 1.8091s; samplesPerSecond = 707.6
MPI Rank 0: 08/21/2017 14:32:18:  Epoch[ 9 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.62719460 * 1280; Err = 0.22031250 * 1280; time = 1.7430s; samplesPerSecond = 734.4
MPI Rank 0: 08/21/2017 14:32:20:  Epoch[ 9 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.64915352 * 1280; Err = 0.22812500 * 1280; time = 1.7636s; samplesPerSecond = 725.8
MPI Rank 0: 08/21/2017 14:32:22:  Epoch[ 9 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.59421768 * 1280; Err = 0.20156250 * 1280; time = 1.7509s; samplesPerSecond = 731.0
MPI Rank 0: 08/21/2017 14:32:24:  Epoch[ 9 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.66566620 * 1280; Err = 0.25703125 * 1280; time = 1.8392s; samplesPerSecond = 695.9
MPI Rank 0: 08/21/2017 14:32:25:  Epoch[ 9 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.62070007 * 1280; Err = 0.21406250 * 1280; time = 1.8480s; samplesPerSecond = 692.6
MPI Rank 0: 08/21/2017 14:32:27:  Epoch[ 9 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.63387680 * 1280; Err = 0.21875000 * 1280; time = 1.8524s; samplesPerSecond = 691.0
MPI Rank 0: 08/21/2017 14:32:29:  Epoch[ 9 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.59436951 * 1280; Err = 0.20000000 * 1280; time = 1.7154s; samplesPerSecond = 746.2
MPI Rank 0: 08/21/2017 14:32:31:  Epoch[ 9 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.59596939 * 1280; Err = 0.20937500 * 1280; time = 1.8681s; samplesPerSecond = 685.2
MPI Rank 0: 08/21/2017 14:32:33:  Epoch[ 9 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.60095749 * 1280; Err = 0.21250000 * 1280; time = 1.8329s; samplesPerSecond = 698.3
MPI Rank 0: 08/21/2017 14:32:34:  Epoch[ 9 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.60278778 * 1280; Err = 0.21406250 * 1280; time = 1.7843s; samplesPerSecond = 717.4
MPI Rank 0: 08/21/2017 14:32:36:  Epoch[ 9 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.61128540 * 1280; Err = 0.20937500 * 1280; time = 1.7706s; samplesPerSecond = 722.9
MPI Rank 0: 08/21/2017 14:32:37: Finished Epoch[ 9 of 12]: [Training] CE = 0.63852395 * 25000; Err = 0.22204000 * 25000; totalSamplesSeen = 200000; learningRatePerSample = 0.0040000002; epochTime=35.9179s
MPI Rank 0: 08/21/2017 14:32:43: Final Results: Minibatch[1-79]: CE = 0.81309944 * 10000; perplexity = 2.25488606; Err = 0.27600000 * 10000
MPI Rank 0: 08/21/2017 14:32:43: Finished Epoch[ 9 of 12]: [Validate] CE = 0.81309944 * 10000; Err = 0.27600000 * 10000
MPI Rank 0: 08/21/2017 14:32:43: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.9'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:32:43: Starting Epoch 10: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:32:43: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:32:44:  Epoch[10 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.49462539 * 128; Err = 0.12500000 * 128; time = 0.2844s; samplesPerSecond = 450.1
MPI Rank 0: 08/21/2017 14:32:45:  Epoch[10 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.58667233 * 1152; Err = 0.20920139 * 1152; time = 1.6663s; samplesPerSecond = 691.4
MPI Rank 0: 08/21/2017 14:32:47:  Epoch[10 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.61042423 * 1280; Err = 0.21015625 * 1280; time = 1.7679s; samplesPerSecond = 724.0
MPI Rank 0: 08/21/2017 14:32:49:  Epoch[10 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.58516474 * 1280; Err = 0.20156250 * 1280; time = 1.7646s; samplesPerSecond = 725.4
MPI Rank 0: 08/21/2017 14:32:51:  Epoch[10 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.59875298 * 1280; Err = 0.20781250 * 1280; time = 1.9232s; samplesPerSecond = 665.6
MPI Rank 0: 08/21/2017 14:32:53:  Epoch[10 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.63764610 * 1280; Err = 0.22265625 * 1280; time = 1.8303s; samplesPerSecond = 699.3
MPI Rank 0: 08/21/2017 14:32:54:  Epoch[10 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.59552593 * 1280; Err = 0.21093750 * 1280; time = 1.9339s; samplesPerSecond = 661.9
MPI Rank 0: 08/21/2017 14:32:56:  Epoch[10 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.59937859 * 1280; Err = 0.20468750 * 1280; time = 1.7824s; samplesPerSecond = 718.1
MPI Rank 0: 08/21/2017 14:32:58:  Epoch[10 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.58844910 * 1280; Err = 0.20156250 * 1280; time = 1.8676s; samplesPerSecond = 685.4
MPI Rank 0: 08/21/2017 14:33:00:  Epoch[10 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.60690041 * 1280; Err = 0.22421875 * 1280; time = 1.8402s; samplesPerSecond = 695.6
MPI Rank 0: 08/21/2017 14:33:02:  Epoch[10 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.64582214 * 1280; Err = 0.22187500 * 1280; time = 1.7825s; samplesPerSecond = 718.1
MPI Rank 0: 08/21/2017 14:33:04:  Epoch[10 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.57989616 * 1280; Err = 0.19531250 * 1280; time = 1.8189s; samplesPerSecond = 703.7
MPI Rank 0: 08/21/2017 14:33:05:  Epoch[10 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.60623474 * 1280; Err = 0.20390625 * 1280; time = 1.8238s; samplesPerSecond = 701.8
MPI Rank 0: 08/21/2017 14:33:07:  Epoch[10 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.60543823 * 1280; Err = 0.21875000 * 1280; time = 1.7739s; samplesPerSecond = 721.6
MPI Rank 0: 08/21/2017 14:33:09:  Epoch[10 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.57908783 * 1280; Err = 0.19687500 * 1280; time = 1.8365s; samplesPerSecond = 697.0
MPI Rank 0: 08/21/2017 14:33:11:  Epoch[10 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.61955109 * 1280; Err = 0.21875000 * 1280; time = 1.8728s; samplesPerSecond = 683.5
MPI Rank 0: 08/21/2017 14:33:13:  Epoch[10 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.57709198 * 1280; Err = 0.21171875 * 1280; time = 1.7872s; samplesPerSecond = 716.2
MPI Rank 0: 08/21/2017 14:33:15:  Epoch[10 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.62962265 * 1280; Err = 0.22187500 * 1280; time = 1.8957s; samplesPerSecond = 675.2
MPI Rank 0: 08/21/2017 14:33:16:  Epoch[10 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.58590775 * 1280; Err = 0.20234375 * 1280; time = 1.7830s; samplesPerSecond = 717.9
MPI Rank 0: 08/21/2017 14:33:18:  Epoch[10 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.59651184 * 1280; Err = 0.21015625 * 1280; time = 1.9629s; samplesPerSecond = 652.1
MPI Rank 0: 08/21/2017 14:33:19: Finished Epoch[10 of 12]: [Training] CE = 0.60054398 * 25000; Err = 0.20932000 * 25000; totalSamplesSeen = 225000; learningRatePerSample = 0.0040000002; epochTime=36.1181s
MPI Rank 0: 08/21/2017 14:33:25: Final Results: Minibatch[1-79]: CE = 0.82036347 * 10000; perplexity = 2.27132525; Err = 0.27660000 * 10000
MPI Rank 0: 08/21/2017 14:33:25: Finished Epoch[10 of 12]: [Validate] CE = 0.82036347 * 10000; Err = 0.27660000 * 10000
MPI Rank 0: 08/21/2017 14:33:25: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.10'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:33:25: Starting Epoch 11: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:33:25: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:33:25:  Epoch[11 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.63042974 * 128; Err = 0.22656250 * 128; time = 0.2523s; samplesPerSecond = 507.4
MPI Rank 0: 08/21/2017 14:33:27:  Epoch[11 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.58576531 * 1152; Err = 0.19618056 * 1152; time = 1.5432s; samplesPerSecond = 746.5
MPI Rank 0: 08/21/2017 14:33:29:  Epoch[11 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.58307652 * 1280; Err = 0.20156250 * 1280; time = 1.8120s; samplesPerSecond = 706.4
MPI Rank 0: 08/21/2017 14:33:31:  Epoch[11 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.60110807 * 1280; Err = 0.21562500 * 1280; time = 1.9049s; samplesPerSecond = 672.0
MPI Rank 0: 08/21/2017 14:33:32:  Epoch[11 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.55357418 * 1280; Err = 0.19843750 * 1280; time = 1.8625s; samplesPerSecond = 687.3
MPI Rank 0: 08/21/2017 14:33:34:  Epoch[11 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.59324207 * 1280; Err = 0.21171875 * 1280; time = 1.8708s; samplesPerSecond = 684.2
MPI Rank 0: 08/21/2017 14:33:36:  Epoch[11 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.56351662 * 1280; Err = 0.20078125 * 1280; time = 1.8079s; samplesPerSecond = 708.0
MPI Rank 0: 08/21/2017 14:33:38:  Epoch[11 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.58550606 * 1280; Err = 0.21796875 * 1280; time = 1.9226s; samplesPerSecond = 665.8
MPI Rank 0: 08/21/2017 14:33:40:  Epoch[11 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.57734489 * 1280; Err = 0.20468750 * 1280; time = 1.9604s; samplesPerSecond = 652.9
MPI Rank 0: 08/21/2017 14:33:42:  Epoch[11 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.62559624 * 1280; Err = 0.20390625 * 1280; time = 1.8518s; samplesPerSecond = 691.2
MPI Rank 0: 08/21/2017 14:33:44:  Epoch[11 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.58502388 * 1280; Err = 0.19375000 * 1280; time = 1.9705s; samplesPerSecond = 649.6
MPI Rank 0: 08/21/2017 14:33:46:  Epoch[11 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.56807899 * 1280; Err = 0.20156250 * 1280; time = 1.7322s; samplesPerSecond = 738.9
MPI Rank 0: 08/21/2017 14:33:47:  Epoch[11 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.56295471 * 1280; Err = 0.19453125 * 1280; time = 1.8469s; samplesPerSecond = 693.0
MPI Rank 0: 08/21/2017 14:33:49:  Epoch[11 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.58537140 * 1280; Err = 0.20234375 * 1280; time = 1.7853s; samplesPerSecond = 717.0
MPI Rank 0: 08/21/2017 14:33:51:  Epoch[11 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.53496094 * 1280; Err = 0.18359375 * 1280; time = 1.8991s; samplesPerSecond = 674.0
MPI Rank 0: 08/21/2017 14:33:53:  Epoch[11 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.52721176 * 1280; Err = 0.17890625 * 1280; time = 1.8442s; samplesPerSecond = 694.1
MPI Rank 0: 08/21/2017 14:33:55:  Epoch[11 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.57216187 * 1280; Err = 0.19453125 * 1280; time = 1.8495s; samplesPerSecond = 692.1
MPI Rank 0: 08/21/2017 14:33:57:  Epoch[11 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.54203262 * 1280; Err = 0.19765625 * 1280; time = 1.8113s; samplesPerSecond = 706.7
MPI Rank 0: 08/21/2017 14:33:58:  Epoch[11 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.61570129 * 1280; Err = 0.21562500 * 1280; time = 1.8097s; samplesPerSecond = 707.3
MPI Rank 0: 08/21/2017 14:34:00:  Epoch[11 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.55975723 * 1280; Err = 0.18046875 * 1280; time = 1.7679s; samplesPerSecond = 724.0
MPI Rank 0: 08/21/2017 14:34:01: Finished Epoch[11 of 12]: [Training] CE = 0.57516965 * 25000; Err = 0.19980000 * 25000; totalSamplesSeen = 250000; learningRatePerSample = 0.0040000002; epochTime=36.16s
MPI Rank 0: 08/21/2017 14:34:07: Final Results: Minibatch[1-79]: CE = 0.57025600 * 10000; perplexity = 1.76871978; Err = 0.19650000 * 10000
MPI Rank 0: 08/21/2017 14:34:07: Finished Epoch[11 of 12]: [Validate] CE = 0.57025600 * 10000; Err = 0.19650000 * 10000
MPI Rank 0: 08/21/2017 14:34:07: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.11'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:34:07: Starting Epoch 12: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:34:07: Starting minibatch loop, DataParallelASGD training (myRank = 0, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 0: 08/21/2017 14:34:07:  Epoch[12 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.63684660 * 128; Err = 0.24218750 * 128; time = 0.2547s; samplesPerSecond = 502.6
MPI Rank 0: 08/21/2017 14:34:09:  Epoch[12 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.49256960 * 1152; Err = 0.17274306 * 1152; time = 1.7325s; samplesPerSecond = 664.9
MPI Rank 0: 08/21/2017 14:34:11:  Epoch[12 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.54977980 * 1280; Err = 0.19375000 * 1280; time = 1.8193s; samplesPerSecond = 703.6
MPI Rank 0: 08/21/2017 14:34:12:  Epoch[12 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.54575624 * 1280; Err = 0.19531250 * 1280; time = 1.7498s; samplesPerSecond = 731.5
MPI Rank 0: 08/21/2017 14:34:14:  Epoch[12 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.56334248 * 1280; Err = 0.19921875 * 1280; time = 1.8622s; samplesPerSecond = 687.4
MPI Rank 0: 08/21/2017 14:34:16:  Epoch[12 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.52425461 * 1280; Err = 0.17890625 * 1280; time = 1.9421s; samplesPerSecond = 659.1
MPI Rank 0: 08/21/2017 14:34:18:  Epoch[12 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.53671360 * 1280; Err = 0.17968750 * 1280; time = 1.7745s; samplesPerSecond = 721.3
MPI Rank 0: 08/21/2017 14:34:20:  Epoch[12 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.48444672 * 1280; Err = 0.16093750 * 1280; time = 1.8085s; samplesPerSecond = 707.8
MPI Rank 0: 08/21/2017 14:34:22:  Epoch[12 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.54818077 * 1280; Err = 0.18203125 * 1280; time = 1.8593s; samplesPerSecond = 688.4
MPI Rank 0: 08/21/2017 14:34:24:  Epoch[12 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.54238281 * 1280; Err = 0.19218750 * 1280; time = 1.8195s; samplesPerSecond = 703.5
MPI Rank 0: 08/21/2017 14:34:25:  Epoch[12 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.53835640 * 1280; Err = 0.18828125 * 1280; time = 1.8065s; samplesPerSecond = 708.5
MPI Rank 0: 08/21/2017 14:34:27:  Epoch[12 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.53130035 * 1280; Err = 0.18203125 * 1280; time = 1.8226s; samplesPerSecond = 702.3
MPI Rank 0: 08/21/2017 14:34:29:  Epoch[12 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.54359970 * 1280; Err = 0.19062500 * 1280; time = 1.8537s; samplesPerSecond = 690.5
MPI Rank 0: 08/21/2017 14:34:31:  Epoch[12 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.51894150 * 1280; Err = 0.18203125 * 1280; time = 1.9196s; samplesPerSecond = 666.8
MPI Rank 0: 08/21/2017 14:34:33:  Epoch[12 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.55757141 * 1280; Err = 0.18828125 * 1280; time = 1.9271s; samplesPerSecond = 664.2
MPI Rank 0: 08/21/2017 14:34:35:  Epoch[12 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.56063385 * 1280; Err = 0.19531250 * 1280; time = 1.8429s; samplesPerSecond = 694.5
MPI Rank 0: 08/21/2017 14:34:37:  Epoch[12 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.55738602 * 1280; Err = 0.18437500 * 1280; time = 1.7774s; samplesPerSecond = 720.2
MPI Rank 0: 08/21/2017 14:34:38:  Epoch[12 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.49988785 * 1280; Err = 0.17812500 * 1280; time = 1.7884s; samplesPerSecond = 715.7
MPI Rank 0: 08/21/2017 14:34:40:  Epoch[12 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.51472855 * 1280; Err = 0.18515625 * 1280; time = 1.8266s; samplesPerSecond = 700.8
MPI Rank 0: 08/21/2017 14:34:42:  Epoch[12 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.49481812 * 1280; Err = 0.16875000 * 1280; time = 1.8563s; samplesPerSecond = 689.5
MPI Rank 0: 08/21/2017 14:34:43: Finished Epoch[12 of 12]: [Training] CE = 0.53212582 * 25000; Err = 0.18424000 * 25000; totalSamplesSeen = 275000; learningRatePerSample = 0.0040000002; epochTime=36.189s
MPI Rank 0: 08/21/2017 14:34:49: Final Results: Minibatch[1-79]: CE = 0.66494053 * 10000; perplexity = 1.94437489; Err = 0.21980000 * 10000
MPI Rank 0: 08/21/2017 14:34:49: Finished Epoch[12 of 12]: [Validate] CE = 0.66494053 * 10000; Err = 0.21980000 * 10000
MPI Rank 0: 08/21/2017 14:34:49: SGD: Saving checkpoint model '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model'
MPI Rank 0: ~MultiversoHelper
MPI Rank 0: [INFO] [2017-08-21 14:34:49] Multiverso Shutdown successfully
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:34:49: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 14:34:49: __COMPLETED__
MPI Rank 0: ~MPIWrapperMpi
MPI Rank 1: 08/21/2017 14:27:05: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 14:27:05: Build info: 
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: 		Built time: Aug 21 2017 08:19:23
MPI Rank 1: 08/21/2017 14:27:05: 		Last modified date: Fri Aug 18 16:43:56 2017
MPI Rank 1: 08/21/2017 14:27:05: 		Build type: debug
MPI Rank 1: 08/21/2017 14:27:05: 		Build target: GPU
MPI Rank 1: 08/21/2017 14:27:05: 		With 1bit-SGD: no
MPI Rank 1: 08/21/2017 14:27:05: 		With ASGD: yes
MPI Rank 1: 08/21/2017 14:27:05: 		Math lib: mkl
MPI Rank 1: 08/21/2017 14:27:05: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 1: 08/21/2017 14:27:05: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 08/21/2017 14:27:05: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 1: 08/21/2017 14:27:05: 		Build Branch: HEAD
MPI Rank 1: 08/21/2017 14:27:05: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 1: 08/21/2017 14:27:05: 		Built by Source/CNTK/buildinfo.h$$0 on 978ed30056f7
MPI Rank 1: 08/21/2017 14:27:05: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 08/21/2017 14:27:05: 		MPI distribution: Open MPI
MPI Rank 1: 08/21/2017 14:27:05: 		MPI version: 1.10.7
MPI Rank 1: 08/21/2017 14:27:05: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 14:27:05: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 14:27:05: GPU info:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2932 MB
MPI Rank 1: 08/21/2017 14:27:05: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: Configuration, Raw:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: makeMode = true
MPI Rank 1: RootDir = "."
MPI Rank 1: configName = "asgd"
MPI Rank 1: minibatch = 128
MPI Rank 1: epochSize = 5
MPI Rank 1: parallelizationMethod = "DataParallelASGD"
MPI Rank 1: asyncBuffer = "true"
MPI Rank 1: ConfigDir = "$RootDir$"
MPI Rank 1: DataDir = "$RootDir$"
MPI Rank 1: OutputDir = "$RootDir$/Output-$configName$"
MPI Rank 1: ModelDir = "$OutputDir$/Models"
MPI Rank 1: ndlMacros = "$ConfigDir$/Macros.ndl"
MPI Rank 1: precision = "float"
MPI Rank 1: DeviceId = 0
MPI Rank 1: imageLayout = "cudnn"
MPI Rank 1: initOnCPUOnly=true
MPI Rank 1: prefetch = "true"
MPI Rank 1: parallelTrain = "false"
MPI Rank 1: command = Train
MPI Rank 1: stderr = "$OutputDir$/Asgd_ResNet"
MPI Rank 1: traceLevel = 1
MPI Rank 1: Proj16to32Filename = "$ConfigDir$/16to32.txt"
MPI Rank 1: Proj32to64Filename = "$ConfigDir$/32to64.txt"
MPI Rank 1: Train = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$ModelDir$/ASGD_Resnet.model"
MPI Rank 1:      NDLNetworkBuilder = [
MPI Rank 1:         networkDescription = "$ConfigDir$/03_ResNet.ndl"
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 0
MPI Rank 1:         minibatchSize = $minibatch$
MPI Rank 1:         learningRatesPerSample = 0.004*80:0.0004*40:0.00004
MPI Rank 1:         momentumPerMB = 0
MPI Rank 1:         maxEpochs = $epochsize$
MPI Rank 1:         L2RegWeight = 0.0001
MPI Rank 1:         dropoutRate = 0
MPI Rank 1:         perfTraceLevel = 0
MPI Rank 1:         firstMBsToShowResult = 1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = $parallelizationMethod$
MPI Rank 1:             distributedMBReading = "true"
MPI Rank 1:             parallelizationStartEpoch = 1
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:                 useBufferedAsyncGradientAggregation = $asyncBuffer$
MPI Rank 1:             ]
MPI Rank 1:             ModelAveragingSGD = [
MPI Rank 1:                 blockSizePerWorker = 128
MPI Rank 1:             ]
MPI Rank 1:             DataParallelASGD = [
MPI Rank 1:                 syncPeriod = 128
MPI Rank 1:                 usePipeline = $asyncBuffer$
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "$DataDir$/train_map.txt"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "RandomSide"
MPI Rank 1:             sideRatio = 0.8
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "$DataDir$/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     cvReader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "$DataDir$/test_map.txt"
MPI Rank 1:         randomize = "none"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "Center"
MPI Rank 1:             sideRatio = 1
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "$DataDir$/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]    
MPI Rank 1: ]
MPI Rank 1: Test = [
MPI Rank 1:     action = "test"
MPI Rank 1:     modelPath = "$ModelDir$/03_ResNet"
MPI Rank 1:     minibatchSize = 256
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "$DataDir$/cifar-10-batches-py/test_map.txt"
MPI Rank 1:         randomize = "none"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "Center"
MPI Rank 1:             sideRatio = 1
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "$DataDir$/cifar-10-batches-py/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]    
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 1: RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 1: DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD
MPI Rank 1: OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: precision=float
MPI Rank 1: parallelTrain=true
MPI Rank 1: minibatch=256
MPI Rank 1: epochsize=12
MPI Rank 1: asyncBuffer="false"
MPI Rank 1: parallelizationMethod=DataParallelASGD
MPI Rank 1: stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Configuration After Variable Resolution:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: makeMode = true
MPI Rank 1: RootDir = "."
MPI Rank 1: configName = "asgd"
MPI Rank 1: minibatch = 128
MPI Rank 1: epochSize = 5
MPI Rank 1: parallelizationMethod = "DataParallelASGD"
MPI Rank 1: asyncBuffer = "true"
MPI Rank 1: ConfigDir = "."
MPI Rank 1: DataDir = "."
MPI Rank 1: OutputDir = "./Output-asgd"
MPI Rank 1: ModelDir = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models"
MPI Rank 1: ndlMacros = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/Macros.ndl"
MPI Rank 1: precision = "float"
MPI Rank 1: DeviceId = 0
MPI Rank 1: imageLayout = "cudnn"
MPI Rank 1: initOnCPUOnly=true
MPI Rank 1: prefetch = "true"
MPI Rank 1: parallelTrain = "false"
MPI Rank 1: command = Train
MPI Rank 1: stderr = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Asgd_ResNet"
MPI Rank 1: traceLevel = 1
MPI Rank 1: Proj16to32Filename = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/16to32.txt"
MPI Rank 1: Proj32to64Filename = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/32to64.txt"
MPI Rank 1: Train = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model"
MPI Rank 1:      NDLNetworkBuilder = [
MPI Rank 1:         networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet.ndl"
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 0
MPI Rank 1:         minibatchSize = 256
MPI Rank 1:         learningRatesPerSample = 0.004*80:0.0004*40:0.00004
MPI Rank 1:         momentumPerMB = 0
MPI Rank 1:         maxEpochs = 12
MPI Rank 1:         L2RegWeight = 0.0001
MPI Rank 1:         dropoutRate = 0
MPI Rank 1:         perfTraceLevel = 0
MPI Rank 1:         firstMBsToShowResult = 1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = DataParallelASGD
MPI Rank 1:             distributedMBReading = "true"
MPI Rank 1:             parallelizationStartEpoch = 1
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:                 useBufferedAsyncGradientAggregation = false
MPI Rank 1:             ]
MPI Rank 1:             ModelAveragingSGD = [
MPI Rank 1:                 blockSizePerWorker = 128
MPI Rank 1:             ]
MPI Rank 1:             DataParallelASGD = [
MPI Rank 1:                 syncPeriod = 128
MPI Rank 1:                 usePipeline = false
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/train_map.txt"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "RandomSide"
MPI Rank 1:             sideRatio = 0.8
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     cvReader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/test_map.txt"
MPI Rank 1:         randomize = "none"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "Center"
MPI Rank 1:             sideRatio = 1
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]    
MPI Rank 1: ]
MPI Rank 1: Test = [
MPI Rank 1:     action = "test"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/03_ResNet"
MPI Rank 1:     minibatchSize = 256
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/test_map.txt"
MPI Rank 1:         randomize = "none"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "Center"
MPI Rank 1:             sideRatio = 1
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]    
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 1: RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 1: DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD
MPI Rank 1: OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: precision=float
MPI Rank 1: parallelTrain=true
MPI Rank 1: minibatch=256
MPI Rank 1: epochsize=12
MPI Rank 1: asyncBuffer="false"
MPI Rank 1: parallelizationMethod=DataParallelASGD
MPI Rank 1: stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Configuration After Processing and Variable Resolution:
MPI Rank 1: 
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:asyncBuffer=false
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:command=Train
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:configName=asgd
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:currentDirectory=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:DataDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:DeviceId=0
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:epochSize=12
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:imageLayout=cudnn
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:initOnCPUOnly=true
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:makeMode=true
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:minibatch=256
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:ModelDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/Macros.ndl
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:numCPUThreads=1
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:OutputDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:parallelizationMethod=DataParallelASGD
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:parallelTrain=true
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:precision=float
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:prefetch=true
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:Proj16to32Filename=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/16to32.txt
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:Proj32to64Filename=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/32to64.txt
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:RootDir=.
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:RunDir=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:stderr=/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/ASGDMultiGPU
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:Test=[
MPI Rank 1:     action = "test"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/03_ResNet"
MPI Rank 1:     minibatchSize = 256
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/test_map.txt"
MPI Rank 1:         randomize = "none"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "Center"
MPI Rank 1:             sideRatio = 1
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/cifar-10-batches-py/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]    
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:timestamping=true
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:traceLevel=1
MPI Rank 1: configparameters: 03_ResNet-parallel.cntk:Train=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model"
MPI Rank 1:      NDLNetworkBuilder = [
MPI Rank 1:         networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/ParallelTraining/AsynchronousSGD/03_ResNet.ndl"
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 0
MPI Rank 1:         minibatchSize = 256
MPI Rank 1:         learningRatesPerSample = 0.004*80:0.0004*40:0.00004
MPI Rank 1:         momentumPerMB = 0
MPI Rank 1:         maxEpochs = 12
MPI Rank 1:         L2RegWeight = 0.0001
MPI Rank 1:         dropoutRate = 0
MPI Rank 1:         perfTraceLevel = 0
MPI Rank 1:         firstMBsToShowResult = 1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = DataParallelASGD
MPI Rank 1:             distributedMBReading = "true"
MPI Rank 1:             parallelizationStartEpoch = 1
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:                 useBufferedAsyncGradientAggregation = false
MPI Rank 1:             ]
MPI Rank 1:             ModelAveragingSGD = [
MPI Rank 1:                 blockSizePerWorker = 128
MPI Rank 1:             ]
MPI Rank 1:             DataParallelASGD = [
MPI Rank 1:                 syncPeriod = 128
MPI Rank 1:                 usePipeline = false
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/train_map.txt"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "RandomSide"
MPI Rank 1:             sideRatio = 0.8
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     cvReader = [
MPI Rank 1:         readerType = "ImageReader"
MPI Rank 1:         file = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/test_map.txt"
MPI Rank 1:         randomize = "none"
MPI Rank 1:         features = [
MPI Rank 1:             width = 32
MPI Rank 1:             height = 32
MPI Rank 1:             channels = 3
MPI Rank 1:             cropType = "Center"
MPI Rank 1:             sideRatio = 1
MPI Rank 1:             jitterType = "UniRatio"
MPI Rank 1:             interpolations = "linear"
MPI Rank 1:             meanFile = "/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/TestData/CIFAR-10_mean.xml"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             labelDim = 10
MPI Rank 1:         ]
MPI Rank 1:     ]    
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: Commands: Train
MPI Rank 1: 08/21/2017 14:27:05: precision = "float"
MPI Rank 1: 08/21/2017 14:27:05: Using 1 CPU threads.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: ##############################################################################
MPI Rank 1: 08/21/2017 14:27:05: #                                                                            #
MPI Rank 1: 08/21/2017 14:27:05: # Train command (train action)                                               #
MPI Rank 1: 08/21/2017 14:27:05: #                                                                            #
MPI Rank 1: 08/21/2017 14:27:05: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:05: 
MPI Rank 1: Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821142703.146078/ParallelTraining_AsynchronousSGD@debug_gpu/Models/ASGD_Resnet.model.1'.
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: conv1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 16, Kernel: 3 x 3 x 3, Map: 1 x 1 x 16, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn1_1.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn1_1.c2.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn1_2.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn1_2.c2.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn1_3.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn1_3.c2.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 32 x 32 x 16, Kernel: 3 x 3 x 16, Map: 1 x 1 x 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_1.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 16 x 16 x 32, Kernel: 3 x 3 x 16, Map: 1 x 1 x 32, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_1.c2.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_1.c_proj.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 16, Output: 16 x 16 x 32, Kernel: 1 x 1 x 16, Map: 1 x 1 x 32, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_2.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_2.c2.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_3.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn2_3.c2.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 16 x 16 x 32, Kernel: 3 x 3 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_1.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 8 x 8 x 64, Kernel: 3 x 3 x 32, Map: 1 x 1 x 64, Stride: 2 x 2 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_1.c2.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_1.c_proj.c: using cuDNN convolution engine for geometry: Input: 16 x 16 x 32, Output: 8 x 8 x 64, Kernel: 1 x 1 x 32, Map: 1 x 1 x 64, Stride: 2 x 2 x 32, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_2.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_2.c2.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_3.c1.c.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: rn3_3.c2.c.c: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 8 x 8 x 64, Kernel: 3 x 3 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
MPI Rank 1: Using CNTK batch normalization engine.
MPI Rank 1: pool: using cuDNN convolution engine for geometry: Input: 8 x 8 x 64, Output: 1 x 1 x 64, Kernel: 8 x 8 x 1, Map: 1, Stride: 1 x 1 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
MPI Rank 1: 08/21/2017 14:27:07: 
MPI Rank 1: Model has 205 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:07: Training criterion:   CE = CrossEntropyWithSoftmax
MPI Rank 1: 08/21/2017 14:27:07: Evaluation criterion: Err = ClassificationError
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:07: Training 269914 parameters in 63 out of 63 parameter tensors and 137 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'OutputNodes.W' (LearnableParameter operation) : [10 x 1 x 1 x 64]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'OutputNodes.b' (LearnableParameter operation) : [10]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'conv1.c.W' (LearnableParameter operation) : [16 x 27]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'conv1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'conv1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_1.c1.c.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_1.c1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_1.c1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_1.c2.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_1.c2.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_1.c2.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_2.c1.c.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_2.c1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_2.c1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_2.c2.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_2.c2.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_2.c2.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_3.c1.c.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_3.c1.c.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_3.c1.c.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_3.c2.W' (LearnableParameter operation) : [16 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_3.c2.c.b' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn1_3.c2.c.sc' (LearnableParameter operation) : [16 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c1.c.W' (LearnableParameter operation) : [32 x 144]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c1.c.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c1.c.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c2.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c2.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c2.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c_proj.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_1.c_proj.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_2.c1.c.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_2.c1.c.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_2.c1.c.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_2.c2.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_2.c2.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_2.c2.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_3.c1.c.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_3.c1.c.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_3.c1.c.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_3.c2.W' (LearnableParameter operation) : [32 x 288]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_3.c2.c.b' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn2_3.c2.c.sc' (LearnableParameter operation) : [32 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c1.c.W' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c1.c.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c1.c.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c2.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c2.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c2.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c_proj.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_1.c_proj.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_2.c1.c.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_2.c1.c.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_2.c1.c.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_2.c2.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_2.c2.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_2.c2.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_3.c1.c.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_3.c1.c.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_3.c1.c.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_3.c2.W' (LearnableParameter operation) : [64 x 576]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_3.c2.c.b' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 08/21/2017 14:27:07: 	Node 'rn3_3.c2.c.sc' (LearnableParameter operation) : [64 x 1]
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:07: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 08/21/2017 14:27:07: Warning: Checkpoint file is missing. Parameter-learning state (such as momentum) will be reset.
MPI Rank 1: [INFO] [2017-08-21 14:27:07] multiverso MPI-Net is initialized under MPI_THREAD_SERIALIZED mode.
MPI Rank 1: [INFO] [2017-08-21 14:27:07] Create a async server
MPI Rank 1: [INFO] [2017-08-21 14:27:07] Rank 1: Multiverso start successfully
MPI Rank 1: multiverso initial model loaded.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:07: Starting Epoch 2: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:07: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:27:08:  Epoch[ 2 of 12]-Minibatch[   1-   1]: CE = 1.84901845 * 128; Err = 0.67968750 * 128; time = 0.5787s; samplesPerSecond = 221.2
MPI Rank 1: 08/21/2017 14:27:10:  Epoch[ 2 of 12]-Minibatch[   2-  10]: CE = 1.84015969 * 1152; Err = 0.70486111 * 1152; time = 2.4537s; samplesPerSecond = 469.5
MPI Rank 1: 08/21/2017 14:27:12:  Epoch[ 2 of 12]-Minibatch[  11-  20]: CE = 1.74202938 * 1280; Err = 0.66171875 * 1280; time = 1.8593s; samplesPerSecond = 688.4
MPI Rank 1: 08/21/2017 14:27:14:  Epoch[ 2 of 12]-Minibatch[  21-  30]: CE = 1.81013870 * 1280; Err = 0.69296875 * 1280; time = 1.9567s; samplesPerSecond = 654.2
MPI Rank 1: 08/21/2017 14:27:16:  Epoch[ 2 of 12]-Minibatch[  31-  40]: CE = 1.74583511 * 1280; Err = 0.64921875 * 1280; time = 1.7507s; samplesPerSecond = 731.1
MPI Rank 1: 08/21/2017 14:27:18:  Epoch[ 2 of 12]-Minibatch[  41-  50]: CE = 1.69591064 * 1280; Err = 0.64921875 * 1280; time = 1.8450s; samplesPerSecond = 693.8
MPI Rank 1: 08/21/2017 14:27:20:  Epoch[ 2 of 12]-Minibatch[  51-  60]: CE = 1.74687271 * 1280; Err = 0.64531250 * 1280; time = 1.9729s; samplesPerSecond = 648.8
MPI Rank 1: 08/21/2017 14:27:21:  Epoch[ 2 of 12]-Minibatch[  61-  70]: CE = 1.65418777 * 1280; Err = 0.62968750 * 1280; time = 1.7428s; samplesPerSecond = 734.5
MPI Rank 1: 08/21/2017 14:27:23:  Epoch[ 2 of 12]-Minibatch[  71-  80]: CE = 1.74099121 * 1280; Err = 0.67343750 * 1280; time = 1.9420s; samplesPerSecond = 659.1
MPI Rank 1: 08/21/2017 14:27:25:  Epoch[ 2 of 12]-Minibatch[  81-  90]: CE = 1.58217926 * 1280; Err = 0.59140625 * 1280; time = 1.7991s; samplesPerSecond = 711.5
MPI Rank 1: 08/21/2017 14:27:27:  Epoch[ 2 of 12]-Minibatch[  91- 100]: CE = 1.65209961 * 1280; Err = 0.64062500 * 1280; time = 1.8405s; samplesPerSecond = 695.5
MPI Rank 1: 08/21/2017 14:27:29:  Epoch[ 2 of 12]-Minibatch[ 101- 110]: CE = 1.59138031 * 1280; Err = 0.58203125 * 1280; time = 1.9669s; samplesPerSecond = 650.8
MPI Rank 1: 08/21/2017 14:27:31:  Epoch[ 2 of 12]-Minibatch[ 111- 120]: CE = 1.70553589 * 1280; Err = 0.64609375 * 1280; time = 1.8583s; samplesPerSecond = 688.8
MPI Rank 1: 08/21/2017 14:27:32:  Epoch[ 2 of 12]-Minibatch[ 121- 130]: CE = 1.61837311 * 1280; Err = 0.59453125 * 1280; time = 1.7786s; samplesPerSecond = 719.7
MPI Rank 1: 08/21/2017 14:27:34:  Epoch[ 2 of 12]-Minibatch[ 131- 140]: CE = 1.53390198 * 1280; Err = 0.58125000 * 1280; time = 1.8750s; samplesPerSecond = 682.7
MPI Rank 1: 08/21/2017 14:27:36:  Epoch[ 2 of 12]-Minibatch[ 141- 150]: CE = 1.58672943 * 1280; Err = 0.60078125 * 1280; time = 1.8489s; samplesPerSecond = 692.3
MPI Rank 1: 08/21/2017 14:27:38:  Epoch[ 2 of 12]-Minibatch[ 151- 160]: CE = 1.62442017 * 1280; Err = 0.61250000 * 1280; time = 1.8214s; samplesPerSecond = 702.7
MPI Rank 1: 08/21/2017 14:27:40:  Epoch[ 2 of 12]-Minibatch[ 161- 170]: CE = 1.56217041 * 1280; Err = 0.58515625 * 1280; time = 1.8688s; samplesPerSecond = 684.9
MPI Rank 1: 08/21/2017 14:27:42:  Epoch[ 2 of 12]-Minibatch[ 171- 180]: CE = 1.53248901 * 1280; Err = 0.55937500 * 1280; time = 1.9006s; samplesPerSecond = 673.5
MPI Rank 1: 08/21/2017 14:27:44:  Epoch[ 2 of 12]-Minibatch[ 181- 190]: CE = 1.56769714 * 1280; Err = 0.58203125 * 1280; time = 1.8130s; samplesPerSecond = 706.0
MPI Rank 1: 08/21/2017 14:27:45: Finished Epoch[ 2 of 12]: [Training] CE = 1.65342703 * 25000; Err = 0.62356000 * 25000; totalSamplesSeen = 25000; learningRatePerSample = 0.0040000002; epochTime=37.6789s
MPI Rank 1: 08/21/2017 14:27:50: Final Results: Minibatch[1-79]: CE = 1.53174594 * 10000; perplexity = 4.62624694; Err = 0.57410000 * 10000
MPI Rank 1: 08/21/2017 14:27:50: Finished Epoch[ 2 of 12]: [Validate] CE = 1.53174594 * 10000; Err = 0.57410000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:50: Starting Epoch 3: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:27:50: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:27:51:  Epoch[ 3 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.61258864 * 128; Err = 0.57812500 * 128; time = 0.2566s; samplesPerSecond = 498.8
MPI Rank 1: 08/21/2017 14:27:52:  Epoch[ 3 of 12]-Minibatch[   2-  10, 10.53%]: CE = 1.50659670 * 1152; Err = 0.53906250 * 1152; time = 1.7578s; samplesPerSecond = 655.4
MPI Rank 1: 08/21/2017 14:27:54:  Epoch[ 3 of 12]-Minibatch[  11-  20, 21.05%]: CE = 1.47264805 * 1280; Err = 0.54921875 * 1280; time = 1.8983s; samplesPerSecond = 674.3
MPI Rank 1: 08/21/2017 14:27:56:  Epoch[ 3 of 12]-Minibatch[  21-  30, 31.58%]: CE = 1.53152256 * 1280; Err = 0.55312500 * 1280; time = 1.8746s; samplesPerSecond = 682.8
MPI Rank 1: 08/21/2017 14:27:58:  Epoch[ 3 of 12]-Minibatch[  31-  40, 42.11%]: CE = 1.46077118 * 1280; Err = 0.53359375 * 1280; time = 1.9714s; samplesPerSecond = 649.3
MPI Rank 1: 08/21/2017 14:28:00:  Epoch[ 3 of 12]-Minibatch[  41-  50, 52.63%]: CE = 1.46827431 * 1280; Err = 0.55078125 * 1280; time = 1.7865s; samplesPerSecond = 716.5
MPI Rank 1: 08/21/2017 14:28:02:  Epoch[ 3 of 12]-Minibatch[  51-  60, 63.16%]: CE = 1.47057037 * 1280; Err = 0.54453125 * 1280; time = 1.9079s; samplesPerSecond = 670.9
MPI Rank 1: 08/21/2017 14:28:03:  Epoch[ 3 of 12]-Minibatch[  61-  70, 73.68%]: CE = 1.42854462 * 1280; Err = 0.54765625 * 1280; time = 1.7437s; samplesPerSecond = 734.1
MPI Rank 1: 08/21/2017 14:28:05:  Epoch[ 3 of 12]-Minibatch[  71-  80, 84.21%]: CE = 1.40927887 * 1280; Err = 0.53281250 * 1280; time = 1.9390s; samplesPerSecond = 660.1
MPI Rank 1: 08/21/2017 14:28:07:  Epoch[ 3 of 12]-Minibatch[  81-  90, 94.74%]: CE = 1.41237488 * 1280; Err = 0.53359375 * 1280; time = 1.8820s; samplesPerSecond = 680.1
MPI Rank 1: 08/21/2017 14:28:09:  Epoch[ 3 of 12]-Minibatch[  91- 100, 105.26%]: CE = 1.40801849 * 1280; Err = 0.53125000 * 1280; time = 1.9413s; samplesPerSecond = 659.4
MPI Rank 1: 08/21/2017 14:28:11:  Epoch[ 3 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 1.44139404 * 1280; Err = 0.56406250 * 1280; time = 1.8813s; samplesPerSecond = 680.4
MPI Rank 1: 08/21/2017 14:28:13:  Epoch[ 3 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 1.29584961 * 1280; Err = 0.48281250 * 1280; time = 2.0033s; samplesPerSecond = 638.9
MPI Rank 1: 08/21/2017 14:28:15:  Epoch[ 3 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 1.35747681 * 1280; Err = 0.49765625 * 1280; time = 1.9460s; samplesPerSecond = 657.8
MPI Rank 1: 08/21/2017 14:28:17:  Epoch[ 3 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 1.32322235 * 1280; Err = 0.46953125 * 1280; time = 1.8647s; samplesPerSecond = 686.4
MPI Rank 1: 08/21/2017 14:28:19:  Epoch[ 3 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 1.36390381 * 1280; Err = 0.50078125 * 1280; time = 1.8667s; samplesPerSecond = 685.7
MPI Rank 1: 08/21/2017 14:28:21:  Epoch[ 3 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 1.31241302 * 1280; Err = 0.48437500 * 1280; time = 1.8527s; samplesPerSecond = 690.9
MPI Rank 1: 08/21/2017 14:28:23:  Epoch[ 3 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 1.31112213 * 1280; Err = 0.47890625 * 1280; time = 1.8719s; samplesPerSecond = 683.8
MPI Rank 1: 08/21/2017 14:28:24:  Epoch[ 3 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 1.30373383 * 1280; Err = 0.47421875 * 1280; time = 1.7310s; samplesPerSecond = 739.5
MPI Rank 1: 08/21/2017 14:28:26:  Epoch[ 3 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 1.33579102 * 1280; Err = 0.47187500 * 1280; time = 1.7925s; samplesPerSecond = 714.1
MPI Rank 1: 08/21/2017 14:28:27: Finished Epoch[ 3 of 12]: [Training] CE = 1.39560156 * 25000; Err = 0.51532000 * 25000; totalSamplesSeen = 50000; learningRatePerSample = 0.0040000002; epochTime=36.6873s
MPI Rank 1: 08/21/2017 14:28:32: Final Results: Minibatch[1-79]: CE = 1.28482749 * 10000; perplexity = 3.61404443; Err = 0.47030000 * 10000
MPI Rank 1: 08/21/2017 14:28:32: Finished Epoch[ 3 of 12]: [Validate] CE = 1.28482749 * 10000; Err = 0.47030000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:28:32: Starting Epoch 4: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:28:32: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:28:32:  Epoch[ 4 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.28293085 * 128; Err = 0.50000000 * 128; time = 0.2391s; samplesPerSecond = 535.4
MPI Rank 1: 08/21/2017 14:28:34:  Epoch[ 4 of 12]-Minibatch[   2-  10, 10.53%]: CE = 1.26748758 * 1152; Err = 0.45833333 * 1152; time = 1.7380s; samplesPerSecond = 662.8
MPI Rank 1: 08/21/2017 14:28:36:  Epoch[ 4 of 12]-Minibatch[  11-  20, 21.05%]: CE = 1.24268322 * 1280; Err = 0.45312500 * 1280; time = 1.6980s; samplesPerSecond = 753.8
MPI Rank 1: 08/21/2017 14:28:38:  Epoch[ 4 of 12]-Minibatch[  21-  30, 31.58%]: CE = 1.29051838 * 1280; Err = 0.48125000 * 1280; time = 1.9353s; samplesPerSecond = 661.4
MPI Rank 1: 08/21/2017 14:28:40:  Epoch[ 4 of 12]-Minibatch[  31-  40, 42.11%]: CE = 1.19653969 * 1280; Err = 0.42109375 * 1280; time = 1.9099s; samplesPerSecond = 670.2
MPI Rank 1: 08/21/2017 14:28:42:  Epoch[ 4 of 12]-Minibatch[  41-  50, 52.63%]: CE = 1.17924004 * 1280; Err = 0.44843750 * 1280; time = 1.8893s; samplesPerSecond = 677.5
MPI Rank 1: 08/21/2017 14:28:44:  Epoch[ 4 of 12]-Minibatch[  51-  60, 63.16%]: CE = 1.20521965 * 1280; Err = 0.44062500 * 1280; time = 1.9113s; samplesPerSecond = 669.7
MPI Rank 1: 08/21/2017 14:28:45:  Epoch[ 4 of 12]-Minibatch[  61-  70, 73.68%]: CE = 1.22487030 * 1280; Err = 0.47265625 * 1280; time = 1.8959s; samplesPerSecond = 675.2
MPI Rank 1: 08/21/2017 14:28:47:  Epoch[ 4 of 12]-Minibatch[  71-  80, 84.21%]: CE = 1.18741531 * 1280; Err = 0.44296875 * 1280; time = 1.8245s; samplesPerSecond = 701.6
MPI Rank 1: 08/21/2017 14:28:49:  Epoch[ 4 of 12]-Minibatch[  81-  90, 94.74%]: CE = 1.16963806 * 1280; Err = 0.41953125 * 1280; time = 1.8404s; samplesPerSecond = 695.5
MPI Rank 1: 08/21/2017 14:28:51:  Epoch[ 4 of 12]-Minibatch[  91- 100, 105.26%]: CE = 1.20440445 * 1280; Err = 0.40156250 * 1280; time = 1.8929s; samplesPerSecond = 676.2
MPI Rank 1: 08/21/2017 14:28:53:  Epoch[ 4 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 1.13780136 * 1280; Err = 0.41328125 * 1280; time = 1.7561s; samplesPerSecond = 728.9
MPI Rank 1: 08/21/2017 14:28:55:  Epoch[ 4 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 1.09510651 * 1280; Err = 0.39140625 * 1280; time = 1.8485s; samplesPerSecond = 692.5
MPI Rank 1: 08/21/2017 14:28:56:  Epoch[ 4 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 1.11580811 * 1280; Err = 0.38828125 * 1280; time = 1.7391s; samplesPerSecond = 736.0
MPI Rank 1: 08/21/2017 14:28:58:  Epoch[ 4 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 1.10529938 * 1280; Err = 0.41015625 * 1280; time = 1.8377s; samplesPerSecond = 696.5
MPI Rank 1: 08/21/2017 14:29:00:  Epoch[ 4 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 1.12741089 * 1280; Err = 0.40312500 * 1280; time = 1.8805s; samplesPerSecond = 680.7
MPI Rank 1: 08/21/2017 14:29:02:  Epoch[ 4 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 1.06243591 * 1280; Err = 0.37187500 * 1280; time = 1.8628s; samplesPerSecond = 687.1
MPI Rank 1: 08/21/2017 14:29:04:  Epoch[ 4 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 1.10544434 * 1280; Err = 0.39687500 * 1280; time = 1.8860s; samplesPerSecond = 678.7
MPI Rank 1: 08/21/2017 14:29:06:  Epoch[ 4 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 1.07949677 * 1280; Err = 0.38671875 * 1280; time = 1.8043s; samplesPerSecond = 709.4
MPI Rank 1: 08/21/2017 14:29:08:  Epoch[ 4 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 1.09758301 * 1280; Err = 0.39765625 * 1280; time = 1.8510s; samplesPerSecond = 691.5
MPI Rank 1: 08/21/2017 14:29:09: Finished Epoch[ 4 of 12]: [Training] CE = 1.16090250 * 25000; Err = 0.42028000 * 25000; totalSamplesSeen = 75000; learningRatePerSample = 0.0040000002; epochTime=36.3383s
MPI Rank 1: 08/21/2017 14:29:14: Final Results: Minibatch[1-79]: CE = 1.50480260 * 10000; perplexity = 4.50326461; Err = 0.50150000 * 10000
MPI Rank 1: 08/21/2017 14:29:14: Finished Epoch[ 4 of 12]: [Validate] CE = 1.50480260 * 10000; Err = 0.50150000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:29:14: Starting Epoch 5: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:29:14: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:29:14:  Epoch[ 5 of 12]-Minibatch[   1-   1, 1.05%]: CE = 1.13951635 * 128; Err = 0.43750000 * 128; time = 0.3417s; samplesPerSecond = 374.5
MPI Rank 1: 08/21/2017 14:29:16:  Epoch[ 5 of 12]-Minibatch[   2-  10, 10.53%]: CE = 1.06777705 * 1152; Err = 0.38020833 * 1152; time = 1.6886s; samplesPerSecond = 682.2
MPI Rank 1: 08/21/2017 14:29:18:  Epoch[ 5 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.96755161 * 1280; Err = 0.34687500 * 1280; time = 1.8372s; samplesPerSecond = 696.7
MPI Rank 1: 08/21/2017 14:29:20:  Epoch[ 5 of 12]-Minibatch[  21-  30, 31.58%]: CE = 1.06445980 * 1280; Err = 0.37890625 * 1280; time = 1.8930s; samplesPerSecond = 676.2
MPI Rank 1: 08/21/2017 14:29:22:  Epoch[ 5 of 12]-Minibatch[  31-  40, 42.11%]: CE = 1.02177525 * 1280; Err = 0.37265625 * 1280; time = 1.8536s; samplesPerSecond = 690.5
MPI Rank 1: 08/21/2017 14:29:24:  Epoch[ 5 of 12]-Minibatch[  41-  50, 52.63%]: CE = 1.02850151 * 1280; Err = 0.36015625 * 1280; time = 1.8735s; samplesPerSecond = 683.2
MPI Rank 1: 08/21/2017 14:29:26:  Epoch[ 5 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.98174667 * 1280; Err = 0.35546875 * 1280; time = 2.0521s; samplesPerSecond = 623.8
MPI Rank 1: 08/21/2017 14:29:27:  Epoch[ 5 of 12]-Minibatch[  61-  70, 73.68%]: CE = 1.00873833 * 1280; Err = 0.35781250 * 1280; time = 1.8317s; samplesPerSecond = 698.8
MPI Rank 1: 08/21/2017 14:29:29:  Epoch[ 5 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.94831085 * 1280; Err = 0.33984375 * 1280; time = 1.8925s; samplesPerSecond = 676.4
MPI Rank 1: 08/21/2017 14:29:31:  Epoch[ 5 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.99648285 * 1280; Err = 0.34921875 * 1280; time = 1.8180s; samplesPerSecond = 704.1
MPI Rank 1: 08/21/2017 14:29:33:  Epoch[ 5 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.96064758 * 1280; Err = 0.34531250 * 1280; time = 1.8450s; samplesPerSecond = 693.8
MPI Rank 1: 08/21/2017 14:29:35:  Epoch[ 5 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.99052048 * 1280; Err = 0.34921875 * 1280; time = 1.8358s; samplesPerSecond = 697.2
MPI Rank 1: 08/21/2017 14:29:37:  Epoch[ 5 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.97491608 * 1280; Err = 0.34062500 * 1280; time = 1.8570s; samplesPerSecond = 689.3
MPI Rank 1: 08/21/2017 14:29:39:  Epoch[ 5 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.96410980 * 1280; Err = 0.33046875 * 1280; time = 1.8660s; samplesPerSecond = 686.0
MPI Rank 1: 08/21/2017 14:29:41:  Epoch[ 5 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.92137451 * 1280; Err = 0.33203125 * 1280; time = 2.0493s; samplesPerSecond = 624.6
MPI Rank 1: 08/21/2017 14:29:42:  Epoch[ 5 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.94214783 * 1280; Err = 0.33203125 * 1280; time = 1.8155s; samplesPerSecond = 705.1
MPI Rank 1: 08/21/2017 14:29:44:  Epoch[ 5 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.97888947 * 1280; Err = 0.35234375 * 1280; time = 1.7908s; samplesPerSecond = 714.8
MPI Rank 1: 08/21/2017 14:29:46:  Epoch[ 5 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.94270935 * 1280; Err = 0.34687500 * 1280; time = 1.7912s; samplesPerSecond = 714.6
MPI Rank 1: 08/21/2017 14:29:48:  Epoch[ 5 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.84544830 * 1280; Err = 0.28750000 * 1280; time = 1.8562s; samplesPerSecond = 689.6
MPI Rank 1: 08/21/2017 14:29:50:  Epoch[ 5 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.91789093 * 1280; Err = 0.31171875 * 1280; time = 1.7435s; samplesPerSecond = 734.2
MPI Rank 1: 08/21/2017 14:29:51: Finished Epoch[ 5 of 12]: [Training] CE = 0.97227766 * 25000; Err = 0.34480000 * 25000; totalSamplesSeen = 100000; learningRatePerSample = 0.0040000002; epochTime=36.5097s
MPI Rank 1: 08/21/2017 14:29:56: Final Results: Minibatch[1-79]: CE = 0.97273187 * 10000; perplexity = 2.64516084; Err = 0.34230000 * 10000
MPI Rank 1: 08/21/2017 14:29:56: Finished Epoch[ 5 of 12]: [Validate] CE = 0.97273187 * 10000; Err = 0.34230000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:29:56: Starting Epoch 6: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:29:56: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:29:56:  Epoch[ 6 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.83483195 * 128; Err = 0.28125000 * 128; time = 0.2592s; samplesPerSecond = 493.8
MPI Rank 1: 08/21/2017 14:29:58:  Epoch[ 6 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.91623118 * 1152; Err = 0.32899306 * 1152; time = 1.7270s; samplesPerSecond = 667.1
MPI Rank 1: 08/21/2017 14:30:00:  Epoch[ 6 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.85995398 * 1280; Err = 0.29687500 * 1280; time = 1.7910s; samplesPerSecond = 714.7
MPI Rank 1: 08/21/2017 14:30:01:  Epoch[ 6 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.86926079 * 1280; Err = 0.30156250 * 1280; time = 1.8797s; samplesPerSecond = 681.0
MPI Rank 1: 08/21/2017 14:30:03:  Epoch[ 6 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.86363049 * 1280; Err = 0.31093750 * 1280; time = 1.7808s; samplesPerSecond = 718.8
MPI Rank 1: 08/21/2017 14:30:05:  Epoch[ 6 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.90767517 * 1280; Err = 0.31015625 * 1280; time = 1.7714s; samplesPerSecond = 722.6
MPI Rank 1: 08/21/2017 14:30:07:  Epoch[ 6 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.84254417 * 1280; Err = 0.30546875 * 1280; time = 1.9414s; samplesPerSecond = 659.3
MPI Rank 1: 08/21/2017 14:30:09:  Epoch[ 6 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.85831680 * 1280; Err = 0.30937500 * 1280; time = 1.7608s; samplesPerSecond = 726.9
MPI Rank 1: 08/21/2017 14:30:10:  Epoch[ 6 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.83549271 * 1280; Err = 0.30078125 * 1280; time = 1.7590s; samplesPerSecond = 727.7
MPI Rank 1: 08/21/2017 14:30:12:  Epoch[ 6 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.84122772 * 1280; Err = 0.29765625 * 1280; time = 1.8500s; samplesPerSecond = 691.9
MPI Rank 1: 08/21/2017 14:30:14:  Epoch[ 6 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.88853989 * 1280; Err = 0.29843750 * 1280; time = 1.8077s; samplesPerSecond = 708.1
MPI Rank 1: 08/21/2017 14:30:16:  Epoch[ 6 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.84571915 * 1280; Err = 0.30156250 * 1280; time = 1.9301s; samplesPerSecond = 663.2
MPI Rank 1: 08/21/2017 14:30:18:  Epoch[ 6 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.85706482 * 1280; Err = 0.29453125 * 1280; time = 1.9548s; samplesPerSecond = 654.8
MPI Rank 1: 08/21/2017 14:30:20:  Epoch[ 6 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.85880737 * 1280; Err = 0.31640625 * 1280; time = 1.9274s; samplesPerSecond = 664.1
MPI Rank 1: 08/21/2017 14:30:22:  Epoch[ 6 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.88505249 * 1280; Err = 0.30156250 * 1280; time = 1.7618s; samplesPerSecond = 726.5
MPI Rank 1: 08/21/2017 14:30:24:  Epoch[ 6 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.83832474 * 1280; Err = 0.29765625 * 1280; time = 1.9216s; samplesPerSecond = 666.1
MPI Rank 1: 08/21/2017 14:30:25:  Epoch[ 6 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.80554810 * 1280; Err = 0.28984375 * 1280; time = 1.7971s; samplesPerSecond = 712.2
MPI Rank 1: 08/21/2017 14:30:27:  Epoch[ 6 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.77334747 * 1280; Err = 0.26328125 * 1280; time = 1.8306s; samplesPerSecond = 699.2
MPI Rank 1: 08/21/2017 14:30:29:  Epoch[ 6 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.77878265 * 1280; Err = 0.27968750 * 1280; time = 1.8085s; samplesPerSecond = 707.8
MPI Rank 1: 08/21/2017 14:30:31:  Epoch[ 6 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.81309509 * 1280; Err = 0.27734375 * 1280; time = 1.7808s; samplesPerSecond = 718.8
MPI Rank 1: 08/21/2017 14:30:32: Finished Epoch[ 6 of 12]: [Training] CE = 0.84879992 * 25000; Err = 0.29868000 * 25000; totalSamplesSeen = 125000; learningRatePerSample = 0.0040000002; epochTime=36.1425s
MPI Rank 1: 08/21/2017 14:30:37: Final Results: Minibatch[1-79]: CE = 1.28856244 * 10000; perplexity = 3.62756797; Err = 0.42810000 * 10000
MPI Rank 1: 08/21/2017 14:30:37: Finished Epoch[ 6 of 12]: [Validate] CE = 1.28856244 * 10000; Err = 0.42810000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:30:38: Starting Epoch 7: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:30:38: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:30:38:  Epoch[ 7 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.73311037 * 128; Err = 0.28125000 * 128; time = 0.2588s; samplesPerSecond = 494.6
MPI Rank 1: 08/21/2017 14:30:40:  Epoch[ 7 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.75604794 * 1152; Err = 0.27517361 * 1152; time = 1.7587s; samplesPerSecond = 655.0
MPI Rank 1: 08/21/2017 14:30:42:  Epoch[ 7 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.79465404 * 1280; Err = 0.28203125 * 1280; time = 1.8723s; samplesPerSecond = 683.6
MPI Rank 1: 08/21/2017 14:30:43:  Epoch[ 7 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.81096697 * 1280; Err = 0.29296875 * 1280; time = 1.8694s; samplesPerSecond = 684.7
MPI Rank 1: 08/21/2017 14:30:45:  Epoch[ 7 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.73001728 * 1280; Err = 0.26250000 * 1280; time = 1.8905s; samplesPerSecond = 677.1
MPI Rank 1: 08/21/2017 14:30:47:  Epoch[ 7 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.75939522 * 1280; Err = 0.25468750 * 1280; time = 1.8469s; samplesPerSecond = 693.0
MPI Rank 1: 08/21/2017 14:30:49:  Epoch[ 7 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.73237953 * 1280; Err = 0.25390625 * 1280; time = 1.8471s; samplesPerSecond = 693.0
MPI Rank 1: 08/21/2017 14:30:51:  Epoch[ 7 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.80306549 * 1280; Err = 0.27656250 * 1280; time = 1.8916s; samplesPerSecond = 676.7
MPI Rank 1: 08/21/2017 14:30:53:  Epoch[ 7 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.73198547 * 1280; Err = 0.26093750 * 1280; time = 1.7451s; samplesPerSecond = 733.5
MPI Rank 1: 08/21/2017 14:30:54:  Epoch[ 7 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.79072304 * 1280; Err = 0.27656250 * 1280; time = 1.8311s; samplesPerSecond = 699.0
MPI Rank 1: 08/21/2017 14:30:56:  Epoch[ 7 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.82580185 * 1280; Err = 0.27890625 * 1280; time = 1.9074s; samplesPerSecond = 671.1
MPI Rank 1: 08/21/2017 14:30:58:  Epoch[ 7 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.71954117 * 1280; Err = 0.24140625 * 1280; time = 1.9158s; samplesPerSecond = 668.1
MPI Rank 1: 08/21/2017 14:31:00:  Epoch[ 7 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.75283737 * 1280; Err = 0.27031250 * 1280; time = 1.9547s; samplesPerSecond = 654.8
MPI Rank 1: 08/21/2017 14:31:02:  Epoch[ 7 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.70276871 * 1280; Err = 0.24531250 * 1280; time = 1.8457s; samplesPerSecond = 693.5
MPI Rank 1: 08/21/2017 14:31:04:  Epoch[ 7 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.70652924 * 1280; Err = 0.25078125 * 1280; time = 1.8895s; samplesPerSecond = 677.4
MPI Rank 1: 08/21/2017 14:31:06:  Epoch[ 7 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.80904922 * 1280; Err = 0.27421875 * 1280; time = 1.8607s; samplesPerSecond = 687.9
MPI Rank 1: 08/21/2017 14:31:08:  Epoch[ 7 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.75662079 * 1280; Err = 0.27421875 * 1280; time = 1.8594s; samplesPerSecond = 688.4
MPI Rank 1: 08/21/2017 14:31:10:  Epoch[ 7 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.73388596 * 1280; Err = 0.25234375 * 1280; time = 1.9581s; samplesPerSecond = 653.7
MPI Rank 1: 08/21/2017 14:31:11:  Epoch[ 7 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.76177826 * 1280; Err = 0.26171875 * 1280; time = 1.8183s; samplesPerSecond = 704.0
MPI Rank 1: 08/21/2017 14:31:13:  Epoch[ 7 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.65871887 * 1280; Err = 0.22812500 * 1280; time = 1.9656s; samplesPerSecond = 651.2
MPI Rank 1: 08/21/2017 14:31:14: Finished Epoch[ 7 of 12]: [Training] CE = 0.75292609 * 25000; Err = 0.26324000 * 25000; totalSamplesSeen = 150000; learningRatePerSample = 0.0040000002; epochTime=36.7042s
MPI Rank 1: 08/21/2017 14:31:20: Final Results: Minibatch[1-79]: CE = 0.91667455 * 10000; perplexity = 2.50095974; Err = 0.30190000 * 10000
MPI Rank 1: 08/21/2017 14:31:20: Finished Epoch[ 7 of 12]: [Validate] CE = 0.91667455 * 10000; Err = 0.30190000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:31:20: Starting Epoch 8: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:31:20: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:31:20:  Epoch[ 8 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.78815877 * 128; Err = 0.26562500 * 128; time = 0.3110s; samplesPerSecond = 411.5
MPI Rank 1: 08/21/2017 14:31:22:  Epoch[ 8 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.74105195 * 1152; Err = 0.25694444 * 1152; time = 1.6395s; samplesPerSecond = 702.7
MPI Rank 1: 08/21/2017 14:31:24:  Epoch[ 8 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.69221191 * 1280; Err = 0.24296875 * 1280; time = 1.8741s; samplesPerSecond = 683.0
MPI Rank 1: 08/21/2017 14:31:25:  Epoch[ 8 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.66098270 * 1280; Err = 0.22265625 * 1280; time = 1.8495s; samplesPerSecond = 692.1
MPI Rank 1: 08/21/2017 14:31:27:  Epoch[ 8 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.73641567 * 1280; Err = 0.24687500 * 1280; time = 1.7856s; samplesPerSecond = 716.8
MPI Rank 1: 08/21/2017 14:31:29:  Epoch[ 8 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.69754601 * 1280; Err = 0.23203125 * 1280; time = 1.8939s; samplesPerSecond = 675.8
MPI Rank 1: 08/21/2017 14:31:31:  Epoch[ 8 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.72721901 * 1280; Err = 0.25468750 * 1280; time = 1.7394s; samplesPerSecond = 735.9
MPI Rank 1: 08/21/2017 14:31:33:  Epoch[ 8 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.69682922 * 1280; Err = 0.24687500 * 1280; time = 2.0354s; samplesPerSecond = 628.9
MPI Rank 1: 08/21/2017 14:31:35:  Epoch[ 8 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.72049141 * 1280; Err = 0.25156250 * 1280; time = 1.8387s; samplesPerSecond = 696.2
MPI Rank 1: 08/21/2017 14:31:37:  Epoch[ 8 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.68220215 * 1280; Err = 0.23906250 * 1280; time = 1.8918s; samplesPerSecond = 676.6
MPI Rank 1: 08/21/2017 14:31:38:  Epoch[ 8 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.66346092 * 1280; Err = 0.23203125 * 1280; time = 1.8312s; samplesPerSecond = 699.0
MPI Rank 1: 08/21/2017 14:31:40:  Epoch[ 8 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.69596558 * 1280; Err = 0.23828125 * 1280; time = 1.7967s; samplesPerSecond = 712.4
MPI Rank 1: 08/21/2017 14:31:42:  Epoch[ 8 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.64716492 * 1280; Err = 0.23359375 * 1280; time = 1.8629s; samplesPerSecond = 687.1
MPI Rank 1: 08/21/2017 14:31:44:  Epoch[ 8 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.75232086 * 1280; Err = 0.26640625 * 1280; time = 1.7795s; samplesPerSecond = 719.3
MPI Rank 1: 08/21/2017 14:31:46:  Epoch[ 8 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.67243881 * 1280; Err = 0.22890625 * 1280; time = 1.8248s; samplesPerSecond = 701.4
MPI Rank 1: 08/21/2017 14:31:48:  Epoch[ 8 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.68080978 * 1280; Err = 0.24843750 * 1280; time = 1.9065s; samplesPerSecond = 671.4
MPI Rank 1: 08/21/2017 14:31:49:  Epoch[ 8 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.64825745 * 1280; Err = 0.23046875 * 1280; time = 1.8103s; samplesPerSecond = 707.1
MPI Rank 1: 08/21/2017 14:31:51:  Epoch[ 8 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.69157257 * 1280; Err = 0.24921875 * 1280; time = 1.9879s; samplesPerSecond = 643.9
MPI Rank 1: 08/21/2017 14:31:53:  Epoch[ 8 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.71388092 * 1280; Err = 0.25312500 * 1280; time = 1.7910s; samplesPerSecond = 714.7
MPI Rank 1: 08/21/2017 14:31:55:  Epoch[ 8 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.69646454 * 1280; Err = 0.24609375 * 1280; time = 1.7166s; samplesPerSecond = 745.7
MPI Rank 1: 08/21/2017 14:31:56: Finished Epoch[ 8 of 12]: [Training] CE = 0.69393437 * 25000; Err = 0.24256000 * 25000; totalSamplesSeen = 175000; learningRatePerSample = 0.0040000002; epochTime=36.2845s
MPI Rank 1: 08/21/2017 14:32:01: Final Results: Minibatch[1-79]: CE = 0.76524953 * 10000; perplexity = 2.14953069; Err = 0.26380000 * 10000
MPI Rank 1: 08/21/2017 14:32:01: Finished Epoch[ 8 of 12]: [Validate] CE = 0.76524953 * 10000; Err = 0.26380000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:32:01: Starting Epoch 9: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:32:01: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:32:02:  Epoch[ 9 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.63786536 * 128; Err = 0.20312500 * 128; time = 0.2443s; samplesPerSecond = 523.9
MPI Rank 1: 08/21/2017 14:32:03:  Epoch[ 9 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.64767580 * 1152; Err = 0.22743056 * 1152; time = 1.7602s; samplesPerSecond = 654.5
MPI Rank 1: 08/21/2017 14:32:05:  Epoch[ 9 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.63855610 * 1280; Err = 0.22500000 * 1280; time = 1.8295s; samplesPerSecond = 699.7
MPI Rank 1: 08/21/2017 14:32:07:  Epoch[ 9 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.64905758 * 1280; Err = 0.22734375 * 1280; time = 1.8705s; samplesPerSecond = 684.3
MPI Rank 1: 08/21/2017 14:32:09:  Epoch[ 9 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.62863884 * 1280; Err = 0.21953125 * 1280; time = 1.8795s; samplesPerSecond = 681.0
MPI Rank 1: 08/21/2017 14:32:11:  Epoch[ 9 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.70354176 * 1280; Err = 0.23359375 * 1280; time = 1.8563s; samplesPerSecond = 689.5
MPI Rank 1: 08/21/2017 14:32:13:  Epoch[ 9 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.68799133 * 1280; Err = 0.22968750 * 1280; time = 1.8196s; samplesPerSecond = 703.4
MPI Rank 1: 08/21/2017 14:32:15:  Epoch[ 9 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.63434982 * 1280; Err = 0.21406250 * 1280; time = 1.8866s; samplesPerSecond = 678.5
MPI Rank 1: 08/21/2017 14:32:16:  Epoch[ 9 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.66886177 * 1280; Err = 0.23203125 * 1280; time = 1.8057s; samplesPerSecond = 708.9
MPI Rank 1: 08/21/2017 14:32:18:  Epoch[ 9 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.69480247 * 1280; Err = 0.24218750 * 1280; time = 1.9344s; samplesPerSecond = 661.7
MPI Rank 1: 08/21/2017 14:32:20:  Epoch[ 9 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.64221077 * 1280; Err = 0.21875000 * 1280; time = 1.9481s; samplesPerSecond = 657.0
MPI Rank 1: 08/21/2017 14:32:22:  Epoch[ 9 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.64508743 * 1280; Err = 0.22734375 * 1280; time = 1.8718s; samplesPerSecond = 683.8
MPI Rank 1: 08/21/2017 14:32:24:  Epoch[ 9 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.67537308 * 1280; Err = 0.23437500 * 1280; time = 1.8461s; samplesPerSecond = 693.4
MPI Rank 1: 08/21/2017 14:32:26:  Epoch[ 9 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.64166489 * 1280; Err = 0.21875000 * 1280; time = 1.8166s; samplesPerSecond = 704.6
MPI Rank 1: 08/21/2017 14:32:28:  Epoch[ 9 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.65946426 * 1280; Err = 0.21093750 * 1280; time = 1.7964s; samplesPerSecond = 712.5
MPI Rank 1: 08/21/2017 14:32:29:  Epoch[ 9 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.66382294 * 1280; Err = 0.22968750 * 1280; time = 1.8212s; samplesPerSecond = 702.8
MPI Rank 1: 08/21/2017 14:32:31:  Epoch[ 9 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.64251938 * 1280; Err = 0.23046875 * 1280; time = 1.7917s; samplesPerSecond = 714.4
MPI Rank 1: 08/21/2017 14:32:33:  Epoch[ 9 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.59756470 * 1280; Err = 0.19531250 * 1280; time = 1.9469s; samplesPerSecond = 657.5
MPI Rank 1: 08/21/2017 14:32:35:  Epoch[ 9 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.61344452 * 1280; Err = 0.21171875 * 1280; time = 1.9431s; samplesPerSecond = 658.7
MPI Rank 1: 08/21/2017 14:32:37:  Epoch[ 9 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.62550125 * 1280; Err = 0.21640625 * 1280; time = 1.8181s; samplesPerSecond = 704.0
MPI Rank 1: 08/21/2017 14:32:38: Finished Epoch[ 9 of 12]: [Training] CE = 0.64864879 * 25000; Err = 0.22284000 * 25000; totalSamplesSeen = 200000; learningRatePerSample = 0.0040000002; epochTime=36.402s
MPI Rank 1: 08/21/2017 14:32:43: Final Results: Minibatch[1-79]: CE = 1.03656757 * 10000; perplexity = 2.81952257; Err = 0.33230000 * 10000
MPI Rank 1: 08/21/2017 14:32:43: Finished Epoch[ 9 of 12]: [Validate] CE = 1.03656757 * 10000; Err = 0.33230000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:32:43: Starting Epoch 10: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:32:43: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:32:44:  Epoch[10 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.65962267 * 128; Err = 0.20312500 * 128; time = 0.2525s; samplesPerSecond = 506.9
MPI Rank 1: 08/21/2017 14:32:45:  Epoch[10 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.57095337 * 1152; Err = 0.20138889 * 1152; time = 1.6681s; samplesPerSecond = 690.6
MPI Rank 1: 08/21/2017 14:32:47:  Epoch[10 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.62070098 * 1280; Err = 0.21171875 * 1280; time = 1.9323s; samplesPerSecond = 662.4
MPI Rank 1: 08/21/2017 14:32:49:  Epoch[10 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.62196426 * 1280; Err = 0.22109375 * 1280; time = 1.8587s; samplesPerSecond = 688.7
MPI Rank 1: 08/21/2017 14:32:51:  Epoch[10 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.57893562 * 1280; Err = 0.19531250 * 1280; time = 1.8045s; samplesPerSecond = 709.3
MPI Rank 1: 08/21/2017 14:32:53:  Epoch[10 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.59036865 * 1280; Err = 0.20546875 * 1280; time = 1.8183s; samplesPerSecond = 703.9
MPI Rank 1: 08/21/2017 14:32:54:  Epoch[10 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.61844273 * 1280; Err = 0.20312500 * 1280; time = 1.7690s; samplesPerSecond = 723.6
MPI Rank 1: 08/21/2017 14:32:56:  Epoch[10 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.62901573 * 1280; Err = 0.21718750 * 1280; time = 1.9285s; samplesPerSecond = 663.7
MPI Rank 1: 08/21/2017 14:32:58:  Epoch[10 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.62105980 * 1280; Err = 0.21875000 * 1280; time = 1.8736s; samplesPerSecond = 683.2
MPI Rank 1: 08/21/2017 14:33:00:  Epoch[10 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.65771027 * 1280; Err = 0.23281250 * 1280; time = 1.8743s; samplesPerSecond = 682.9
MPI Rank 1: 08/21/2017 14:33:02:  Epoch[10 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.58075066 * 1280; Err = 0.19375000 * 1280; time = 1.8603s; samplesPerSecond = 688.1
MPI Rank 1: 08/21/2017 14:33:04:  Epoch[10 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.57841530 * 1280; Err = 0.19062500 * 1280; time = 1.8727s; samplesPerSecond = 683.5
MPI Rank 1: 08/21/2017 14:33:06:  Epoch[10 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.58650818 * 1280; Err = 0.19921875 * 1280; time = 1.8886s; samplesPerSecond = 677.7
MPI Rank 1: 08/21/2017 14:33:08:  Epoch[10 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.62536926 * 1280; Err = 0.22187500 * 1280; time = 1.8939s; samplesPerSecond = 675.9
MPI Rank 1: 08/21/2017 14:33:09:  Epoch[10 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.69223099 * 1280; Err = 0.23750000 * 1280; time = 1.8498s; samplesPerSecond = 692.0
MPI Rank 1: 08/21/2017 14:33:11:  Epoch[10 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.55688477 * 1280; Err = 0.19296875 * 1280; time = 1.8828s; samplesPerSecond = 679.9
MPI Rank 1: 08/21/2017 14:33:13:  Epoch[10 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.57947845 * 1280; Err = 0.20468750 * 1280; time = 1.8914s; samplesPerSecond = 676.8
MPI Rank 1: 08/21/2017 14:33:15:  Epoch[10 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.58739090 * 1280; Err = 0.20781250 * 1280; time = 1.7926s; samplesPerSecond = 714.0
MPI Rank 1: 08/21/2017 14:33:17:  Epoch[10 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.60509796 * 1280; Err = 0.19921875 * 1280; time = 1.9041s; samplesPerSecond = 672.2
MPI Rank 1: 08/21/2017 14:33:19:  Epoch[10 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.62820206 * 1280; Err = 0.21015625 * 1280; time = 1.8507s; samplesPerSecond = 691.6
MPI Rank 1: 08/21/2017 14:33:20: Finished Epoch[10 of 12]: [Training] CE = 0.60650195 * 25000; Err = 0.20832000 * 25000; totalSamplesSeen = 225000; learningRatePerSample = 0.0040000002; epochTime=36.486s
MPI Rank 1: 08/21/2017 14:33:25: Final Results: Minibatch[1-79]: CE = 0.76601027 * 10000; perplexity = 2.15116653; Err = 0.26380000 * 10000
MPI Rank 1: 08/21/2017 14:33:25: Finished Epoch[10 of 12]: [Validate] CE = 0.76601027 * 10000; Err = 0.26380000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:33:25: Starting Epoch 11: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:33:25: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:33:25:  Epoch[11 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.39698574 * 128; Err = 0.15625000 * 128; time = 0.2527s; samplesPerSecond = 506.5
MPI Rank 1: 08/21/2017 14:33:27:  Epoch[11 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.54693850 * 1152; Err = 0.19010417 * 1152; time = 1.7618s; samplesPerSecond = 653.9
MPI Rank 1: 08/21/2017 14:33:29:  Epoch[11 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.62839718 * 1280; Err = 0.20937500 * 1280; time = 1.7868s; samplesPerSecond = 716.4
MPI Rank 1: 08/21/2017 14:33:31:  Epoch[11 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.57550688 * 1280; Err = 0.19921875 * 1280; time = 1.8923s; samplesPerSecond = 676.4
MPI Rank 1: 08/21/2017 14:33:33:  Epoch[11 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.58131371 * 1280; Err = 0.20468750 * 1280; time = 1.7471s; samplesPerSecond = 732.7
MPI Rank 1: 08/21/2017 14:33:34:  Epoch[11 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.56879597 * 1280; Err = 0.19218750 * 1280; time = 1.7660s; samplesPerSecond = 724.8
MPI Rank 1: 08/21/2017 14:33:36:  Epoch[11 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.53306427 * 1280; Err = 0.18359375 * 1280; time = 1.8852s; samplesPerSecond = 679.0
MPI Rank 1: 08/21/2017 14:33:38:  Epoch[11 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.54367867 * 1280; Err = 0.18359375 * 1280; time = 1.8132s; samplesPerSecond = 705.9
MPI Rank 1: 08/21/2017 14:33:40:  Epoch[11 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.57816200 * 1280; Err = 0.20703125 * 1280; time = 1.8375s; samplesPerSecond = 696.6
MPI Rank 1: 08/21/2017 14:33:42:  Epoch[11 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.59662971 * 1280; Err = 0.20312500 * 1280; time = 1.7624s; samplesPerSecond = 726.3
MPI Rank 1: 08/21/2017 14:33:43:  Epoch[11 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.57426071 * 1280; Err = 0.19687500 * 1280; time = 1.7981s; samplesPerSecond = 711.9
MPI Rank 1: 08/21/2017 14:33:45:  Epoch[11 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.58327522 * 1280; Err = 0.20156250 * 1280; time = 1.9928s; samplesPerSecond = 642.3
MPI Rank 1: 08/21/2017 14:33:47:  Epoch[11 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.55806313 * 1280; Err = 0.20000000 * 1280; time = 1.8550s; samplesPerSecond = 690.0
MPI Rank 1: 08/21/2017 14:33:49:  Epoch[11 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.60198441 * 1280; Err = 0.20156250 * 1280; time = 2.0470s; samplesPerSecond = 625.3
MPI Rank 1: 08/21/2017 14:33:51:  Epoch[11 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.53634033 * 1280; Err = 0.18281250 * 1280; time = 1.8981s; samplesPerSecond = 674.4
MPI Rank 1: 08/21/2017 14:33:53:  Epoch[11 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.57768784 * 1280; Err = 0.20000000 * 1280; time = 1.8461s; samplesPerSecond = 693.3
MPI Rank 1: 08/21/2017 14:33:55:  Epoch[11 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.58402557 * 1280; Err = 0.20078125 * 1280; time = 1.8685s; samplesPerSecond = 685.0
MPI Rank 1: 08/21/2017 14:33:57:  Epoch[11 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.53758011 * 1280; Err = 0.18203125 * 1280; time = 1.8424s; samplesPerSecond = 694.8
MPI Rank 1: 08/21/2017 14:33:59:  Epoch[11 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.58285294 * 1280; Err = 0.19296875 * 1280; time = 1.8714s; samplesPerSecond = 684.0
MPI Rank 1: 08/21/2017 14:34:00:  Epoch[11 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.53854065 * 1280; Err = 0.18906250 * 1280; time = 1.8832s; samplesPerSecond = 679.7
MPI Rank 1: 08/21/2017 14:34:01: Finished Epoch[11 of 12]: [Training] CE = 0.56816242 * 25000; Err = 0.19540000 * 25000; totalSamplesSeen = 250000; learningRatePerSample = 0.0040000002; epochTime=36.3686s
MPI Rank 1: 08/21/2017 14:34:07: Final Results: Minibatch[1-79]: CE = 0.57358590 * 10000; perplexity = 1.77461926; Err = 0.19520000 * 10000
MPI Rank 1: 08/21/2017 14:34:07: Finished Epoch[11 of 12]: [Validate] CE = 0.57358590 * 10000; Err = 0.19520000 * 10000
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:34:07: Starting Epoch 12: learning rate per sample = 0.004  effective momentum = 0.000000  momentum as time constant = 0.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:34:07: Starting minibatch loop, DataParallelASGD training (myRank = 1, numNodes = 2, SamplesSyncToServer = 128), Distributed Evaluation is DISABLED, distributed reading is ENABLED.
MPI Rank 1: 08/21/2017 14:34:07:  Epoch[12 of 12]-Minibatch[   1-   1, 1.05%]: CE = 0.49133766 * 128; Err = 0.17187500 * 128; time = 0.3041s; samplesPerSecond = 420.9
MPI Rank 1: 08/21/2017 14:34:09:  Epoch[12 of 12]-Minibatch[   2-  10, 10.53%]: CE = 0.59750436 * 1152; Err = 0.20225694 * 1152; time = 1.6588s; samplesPerSecond = 694.5
MPI Rank 1: 08/21/2017 14:34:11:  Epoch[12 of 12]-Minibatch[  11-  20, 21.05%]: CE = 0.57482858 * 1280; Err = 0.20156250 * 1280; time = 1.9491s; samplesPerSecond = 656.7
MPI Rank 1: 08/21/2017 14:34:13:  Epoch[12 of 12]-Minibatch[  21-  30, 31.58%]: CE = 0.50507698 * 1280; Err = 0.17578125 * 1280; time = 1.9219s; samplesPerSecond = 666.0
MPI Rank 1: 08/21/2017 14:34:15:  Epoch[12 of 12]-Minibatch[  31-  40, 42.11%]: CE = 0.57409191 * 1280; Err = 0.19609375 * 1280; time = 1.8041s; samplesPerSecond = 709.5
MPI Rank 1: 08/21/2017 14:34:16:  Epoch[12 of 12]-Minibatch[  41-  50, 52.63%]: CE = 0.51805992 * 1280; Err = 0.17500000 * 1280; time = 1.8552s; samplesPerSecond = 690.0
MPI Rank 1: 08/21/2017 14:34:18:  Epoch[12 of 12]-Minibatch[  51-  60, 63.16%]: CE = 0.50801582 * 1280; Err = 0.17421875 * 1280; time = 1.8714s; samplesPerSecond = 684.0
MPI Rank 1: 08/21/2017 14:34:20:  Epoch[12 of 12]-Minibatch[  61-  70, 73.68%]: CE = 0.51675186 * 1280; Err = 0.18046875 * 1280; time = 1.8390s; samplesPerSecond = 696.0
MPI Rank 1: 08/21/2017 14:34:22:  Epoch[12 of 12]-Minibatch[  71-  80, 84.21%]: CE = 0.50183449 * 1280; Err = 0.16484375 * 1280; time = 1.8956s; samplesPerSecond = 675.2
MPI Rank 1: 08/21/2017 14:34:24:  Epoch[12 of 12]-Minibatch[  81-  90, 94.74%]: CE = 0.55718002 * 1280; Err = 0.19140625 * 1280; time = 1.9207s; samplesPerSecond = 666.4
MPI Rank 1: 08/21/2017 14:34:26:  Epoch[12 of 12]-Minibatch[  91- 100, 105.26%]: CE = 0.53021202 * 1280; Err = 0.16484375 * 1280; time = 1.8783s; samplesPerSecond = 681.5
MPI Rank 1: 08/21/2017 14:34:28:  Epoch[12 of 12]-Minibatch[ 101- 110, 115.79%]: CE = 0.51848602 * 1280; Err = 0.18906250 * 1280; time = 1.8223s; samplesPerSecond = 702.4
MPI Rank 1: 08/21/2017 14:34:29:  Epoch[12 of 12]-Minibatch[ 111- 120, 126.32%]: CE = 0.54608231 * 1280; Err = 0.18593750 * 1280; time = 1.7666s; samplesPerSecond = 724.6
MPI Rank 1: 08/21/2017 14:34:31:  Epoch[12 of 12]-Minibatch[ 121- 130, 136.84%]: CE = 0.57973709 * 1280; Err = 0.20000000 * 1280; time = 1.8072s; samplesPerSecond = 708.3
MPI Rank 1: 08/21/2017 14:34:33:  Epoch[12 of 12]-Minibatch[ 131- 140, 147.37%]: CE = 0.56760254 * 1280; Err = 0.19921875 * 1280; time = 1.7862s; samplesPerSecond = 716.6
MPI Rank 1: 08/21/2017 14:34:35:  Epoch[12 of 12]-Minibatch[ 141- 150, 157.89%]: CE = 0.53803406 * 1280; Err = 0.17812500 * 1280; time = 1.8578s; samplesPerSecond = 689.0
MPI Rank 1: 08/21/2017 14:34:37:  Epoch[12 of 12]-Minibatch[ 151- 160, 168.42%]: CE = 0.52945938 * 1280; Err = 0.19062500 * 1280; time = 1.8908s; samplesPerSecond = 677.0
MPI Rank 1: 08/21/2017 14:34:39:  Epoch[12 of 12]-Minibatch[ 161- 170, 178.95%]: CE = 0.53748398 * 1280; Err = 0.18515625 * 1280; time = 1.8781s; samplesPerSecond = 681.5
MPI Rank 1: 08/21/2017 14:34:41:  Epoch[12 of 12]-Minibatch[ 171- 180, 189.47%]: CE = 0.54678421 * 1280; Err = 0.18906250 * 1280; time = 1.9271s; samplesPerSecond = 664.2
MPI Rank 1: 08/21/2017 14:34:42:  Epoch[12 of 12]-Minibatch[ 181- 190, 200.00%]: CE = 0.54080429 * 1280; Err = 0.18750000 * 1280; time = 1.7768s; samplesPerSecond = 720.4
MPI Rank 1: 08/21/2017 14:34:43: Finished Epoch[12 of 12]: [Training] CE = 0.53947680 * 25000; Err = 0.18508000 * 25000; totalSamplesSeen = 275000; learningRatePerSample = 0.0040000002; epochTime=36.3658s
MPI Rank 1: 08/21/2017 14:34:49: Final Results: Minibatch[1-79]: CE = 0.71245377 * 10000; perplexity = 2.03898833; Err = 0.23630000 * 10000
MPI Rank 1: 08/21/2017 14:34:49: Finished Epoch[12 of 12]: [Validate] CE = 0.71245377 * 10000; Err = 0.23630000 * 10000
MPI Rank 1: ~MultiversoHelper
MPI Rank 1: [INFO] [2017-08-21 14:34:49] Multiverso Shutdown successfully
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:34:49: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 14:34:49: __COMPLETED__
MPI Rank 1: ~MPIWrapperMpi