CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 264106564 kB
-------------------------------------------------------------------
=== Running mpiexec -n 4 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/ OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu DeviceId=0 timestamping=true numCPUThreads=3 stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (1) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (3) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (2) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (0) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
08/21/2017 08:28:13: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank0
08/21/2017 08:28:14: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank1
08/21/2017 08:28:14: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank2
08/21/2017 08:28:15: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank3
MPI Rank 0: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13
MPI Rank 0: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 08/21/2017 08:28:13: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:28:13: Build info: 
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:13: 		Built time: Aug 21 2017 08:19:24
MPI Rank 0: 08/21/2017 08:28:13: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 0: 08/21/2017 08:28:13: 		Build type: debug
MPI Rank 0: 08/21/2017 08:28:13: 		Build target: GPU
MPI Rank 0: 08/21/2017 08:28:13: 		With 1bit-SGD: yes
MPI Rank 0: 08/21/2017 08:28:13: 		With ASGD: yes
MPI Rank 0: 08/21/2017 08:28:13: 		Math lib: mkl
MPI Rank 0: 08/21/2017 08:28:13: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 0: 08/21/2017 08:28:13: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 08/21/2017 08:28:13: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 0: 08/21/2017 08:28:13: 		Build Branch: HEAD
MPI Rank 0: 08/21/2017 08:28:13: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 0: 08/21/2017 08:28:13: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 0: 08/21/2017 08:28:13: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 0: 08/21/2017 08:28:13: 		MPI distribution: Open MPI
MPI Rank 0: 08/21/2017 08:28:13: 		MPI version: 1.10.7
MPI Rank 0: 08/21/2017 08:28:13: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:28:13: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:28:13: GPU info:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:13: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 3018 MB
MPI Rank 0: 08/21/2017 08:28:13: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:28:13: Using 3 CPU threads.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:13: ##############################################################################
MPI Rank 0: 08/21/2017 08:28:13: #                                                                            #
MPI Rank 0: 08/21/2017 08:28:13: # train command (train action)                                               #
MPI Rank 0: 08/21/2017 08:28:13: #                                                                            #
MPI Rank 0: 08/21/2017 08:28:13: ##############################################################################
MPI Rank 0: 
MPI Rank 0: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 0: 08/21/2017 08:28:13: 
MPI Rank 0: Creating virgin network.
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 08/21/2017 08:28:14: 
MPI Rank 0: Model has 21 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:14: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing: Out of 36 matrices, 23 are shared as 7, and 13 are not shared.
MPI Rank 0: 
MPI Rank 0: Here are the ones that share memory:
MPI Rank 0: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 0: 	  WD1_D : [64 x *]
MPI Rank 0: 	  WQ1 : [64 x 288] (gradient)
MPI Rank 0: 	  WQ1_Q : [64 x *]
MPI Rank 0: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 0: 	{ WD0_D : [288 x *]
MPI Rank 0: 	  WD0_D : [288 x *] (gradient)
MPI Rank 0: 	  WD1_D_Tanh : [64 x *]
MPI Rank 0: 	  WQ0_Q : [288 x *]
MPI Rank 0: 	  WQ0_Q_Tanh : [288 x *] (gradient) }
MPI Rank 0: 	{ SIM : [51 x *] (gradient)
MPI Rank 0: 	  WD0 : [288 x 49292] (gradient)
MPI Rank 0: 	  WD1_D : [64 x *] (gradient) }
MPI Rank 0: 	{ SIM : [51 x *]
MPI Rank 0: 	  WD1 : [64 x 288] (gradient) }
MPI Rank 0: 	{ WD0_D_Tanh : [288 x *]
MPI Rank 0: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 0: 	{ WQ0 : [288 x 49292] (gradient)
MPI Rank 0: 	  WQ0_Q_Tanh : [288 x *] }
MPI Rank 0: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 0: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 0: 	  WD1_D_Tanh : [64 x *] (gradient)
MPI Rank 0: 	  WQ0_Q : [288 x *] (gradient) }
MPI Rank 0: 
MPI Rank 0: Here are the ones that don't share memory:
MPI Rank 0: 	{WQ0 : [288 x 49292]}
MPI Rank 0: 	{WQ1 : [64 x 288]}
MPI Rank 0: 	{WD1 : [64 x 288]}
MPI Rank 0: 	{WD0 : [288 x 49292]}
MPI Rank 0: 	{Query : [49292 x *]}
MPI Rank 0: 	{Keyword : [49292 x *]}
MPI Rank 0: 	{S : [1 x 1]}
MPI Rank 0: 	{N : [1 x 1]}
MPI Rank 0: 	{G : [1 x 1]}
MPI Rank 0: 	{DSSMLabel : [51 x 1 x *]}
MPI Rank 0: 	{ce : [1]}
MPI Rank 0: 	{WQ1_Q_Tanh : [64 x *]}
MPI Rank 0: 	{ce : [1] (gradient)}
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:14: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:14: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 08/21/2017 08:28:14: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 08/21/2017 08:28:14: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 08/21/2017 08:28:14: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 
MPI Rank 0: Parallel training (4 workers) using ModelAveraging
MPI Rank 0: 08/21/2017 08:28:14: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:17: Starting Epoch 1: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.11 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:28:24:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.34696808 * 10240; time = 6.7946s; samplesPerSecond = 1507.1
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:28:30:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.34277344 * 10240; time = 6.5722s; samplesPerSecond = 1558.1
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:28:33: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601706 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-05; epochTime=16.7472s
MPI Rank 0: 08/21/2017 08:28:34: Final Results: Minibatch[1-26]: ce = 2.49916009 * 102399; perplexity = 12.17226604
MPI Rank 0: 08/21/2017 08:28:34: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916009 * 102399
MPI Rank 0: 08/21/2017 08:28:35: SGD: Saving checkpoint model '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net.1'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:36: Starting Epoch 2: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.11 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.03 seconds
MPI Rank 0: 08/21/2017 08:28:43:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.30270958 * 10240; time = 6.5740s; samplesPerSecond = 1557.7
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:28:49:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.09883766 * 10240; time = 6.6189s; samplesPerSecond = 1547.1
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577526 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-05; epochTime=16.4843s
MPI Rank 0: 08/21/2017 08:28:53: Final Results: Minibatch[1-26]: ce = 1.97005577 * 102399; perplexity = 7.17107641
MPI Rank 0: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005577 * 102399
MPI Rank 0: 08/21/2017 08:28:55: SGD: Saving checkpoint model '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net.2'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:56: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:28:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:29:03:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.89778175 * 10240; time = 6.7985s; samplesPerSecond = 1506.2
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 08/21/2017 08:29:09:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.86335983 * 10240; time = 6.6202s; samplesPerSecond = 1546.8
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.01 seconds
MPI Rank 0: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.8249s
MPI Rank 0: 08/21/2017 08:29:13: Final Results: Minibatch[1-26]: ce = 1.80751073 * 102399; perplexity = 6.09525582
MPI Rank 0: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751073 * 102399
MPI Rank 0: 08/21/2017 08:29:14: SGD: Saving checkpoint model '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:15: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:15: __COMPLETED__
MPI Rank 1: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13
MPI Rank 1: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:28:14: Build info: 
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:14: 		Built time: Aug 21 2017 08:19:24
MPI Rank 1: 08/21/2017 08:28:14: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 1: 08/21/2017 08:28:14: 		Build type: debug
MPI Rank 1: 08/21/2017 08:28:14: 		Build target: GPU
MPI Rank 1: 08/21/2017 08:28:14: 		With 1bit-SGD: yes
MPI Rank 1: 08/21/2017 08:28:14: 		With ASGD: yes
MPI Rank 1: 08/21/2017 08:28:14: 		Math lib: mkl
MPI Rank 1: 08/21/2017 08:28:14: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 1: 08/21/2017 08:28:14: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 08/21/2017 08:28:14: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 1: 08/21/2017 08:28:14: 		Build Branch: HEAD
MPI Rank 1: 08/21/2017 08:28:14: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 1: 08/21/2017 08:28:14: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 1: 08/21/2017 08:28:14: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 1: 08/21/2017 08:28:14: 		MPI distribution: Open MPI
MPI Rank 1: 08/21/2017 08:28:14: 		MPI version: 1.10.7
MPI Rank 1: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:28:14: GPU info:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:14: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2721 MB
MPI Rank 1: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:28:14: Using 3 CPU threads.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:14: ##############################################################################
MPI Rank 1: 08/21/2017 08:28:14: #                                                                            #
MPI Rank 1: 08/21/2017 08:28:14: # train command (train action)                                               #
MPI Rank 1: 08/21/2017 08:28:14: #                                                                            #
MPI Rank 1: 08/21/2017 08:28:14: ##############################################################################
MPI Rank 1: 
MPI Rank 1: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 1: 08/21/2017 08:28:14: 
MPI Rank 1: Creating virgin network.
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 08/21/2017 08:28:14: 
MPI Rank 1: Model has 21 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:14: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing: Out of 36 matrices, 23 are shared as 7, and 13 are not shared.
MPI Rank 1: 
MPI Rank 1: Here are the ones that share memory:
MPI Rank 1: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 1: 	  WD1_D : [64 x *]
MPI Rank 1: 	  WQ1 : [64 x 288] (gradient)
MPI Rank 1: 	  WQ1_Q : [64 x *]
MPI Rank 1: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 1: 	{ WD0_D : [288 x *]
MPI Rank 1: 	  WD0_D : [288 x *] (gradient)
MPI Rank 1: 	  WD1_D_Tanh : [64 x *]
MPI Rank 1: 	  WQ0_Q : [288 x *]
MPI Rank 1: 	  WQ0_Q_Tanh : [288 x *] (gradient) }
MPI Rank 1: 	{ SIM : [51 x *] (gradient)
MPI Rank 1: 	  WD0 : [288 x 49292] (gradient)
MPI Rank 1: 	  WD1_D : [64 x *] (gradient) }
MPI Rank 1: 	{ SIM : [51 x *]
MPI Rank 1: 	  WD1 : [64 x 288] (gradient) }
MPI Rank 1: 	{ WD0_D_Tanh : [288 x *]
MPI Rank 1: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 1: 	{ WQ0 : [288 x 49292] (gradient)
MPI Rank 1: 	  WQ0_Q_Tanh : [288 x *] }
MPI Rank 1: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 1: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 1: 	  WD1_D_Tanh : [64 x *] (gradient)
MPI Rank 1: 	  WQ0_Q : [288 x *] (gradient) }
MPI Rank 1: 
MPI Rank 1: Here are the ones that don't share memory:
MPI Rank 1: 	{WQ0 : [288 x 49292]}
MPI Rank 1: 	{S : [1 x 1]}
MPI Rank 1: 	{WQ1 : [64 x 288]}
MPI Rank 1: 	{WD0 : [288 x 49292]}
MPI Rank 1: 	{WD1 : [64 x 288]}
MPI Rank 1: 	{Keyword : [49292 x *]}
MPI Rank 1: 	{Query : [49292 x *]}
MPI Rank 1: 	{N : [1 x 1]}
MPI Rank 1: 	{G : [1 x 1]}
MPI Rank 1: 	{DSSMLabel : [51 x 1 x *]}
MPI Rank 1: 	{ce : [1]}
MPI Rank 1: 	{ce : [1] (gradient)}
MPI Rank 1: 	{WQ1_Q_Tanh : [64 x *]}
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:14: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:14: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 08/21/2017 08:28:14: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 08/21/2017 08:28:14: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 08/21/2017 08:28:14: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 
MPI Rank 1: Parallel training (4 workers) using ModelAveraging
MPI Rank 1: 08/21/2017 08:28:14: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:17: Starting Epoch 1: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.36-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.36 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.18 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.39 seconds , average latency = 0.13 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.39 seconds , average latency = 0.10 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.08 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.04 seconds
MPI Rank 1: 08/21/2017 08:28:24:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.32159615 * 10240; time = 6.7958s; samplesPerSecond = 1506.8
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.48 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.53 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.64 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.64 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.64 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.64 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.67 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.67 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.72 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.78 seconds , average latency = 0.04 seconds
MPI Rank 1: 08/21/2017 08:28:30:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.33525505 * 10240; time = 6.5722s; samplesPerSecond = 1558.1
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.83 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.83 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.89 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 1.00 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 1.00 seconds , average latency = 0.04 seconds
MPI Rank 1: 08/21/2017 08:28:33: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601706 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-05; epochTime=16.7472s
MPI Rank 1: 08/21/2017 08:28:34: Final Results: Minibatch[1-26]: ce = 2.49916009 * 102399; perplexity = 12.17226604
MPI Rank 1: 08/21/2017 08:28:34: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916009 * 102399
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:36: Starting Epoch 2: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.19-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.19 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.04 seconds
MPI Rank 1: 08/21/2017 08:28:43:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.32732925 * 10240; time = 6.5740s; samplesPerSecond = 1557.7
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 1: 08/21/2017 08:28:49:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.11035995 * 10240; time = 6.6189s; samplesPerSecond = 1547.1
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.52 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.52 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.52 seconds , average latency = 0.02 seconds
MPI Rank 1: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577526 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-05; epochTime=16.4843s
MPI Rank 1: 08/21/2017 08:28:53: Final Results: Minibatch[1-26]: ce = 1.97005577 * 102399; perplexity = 7.17107641
MPI Rank 1: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005577 * 102399
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:56: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:28:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.02 seconds
MPI Rank 1: 08/21/2017 08:29:03:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.92909813 * 10240; time = 6.7988s; samplesPerSecond = 1506.2
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 08/21/2017 08:29:09:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.86598778 * 10240; time = 6.6202s; samplesPerSecond = 1546.8
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.8249s
MPI Rank 1: 08/21/2017 08:29:13: Final Results: Minibatch[1-26]: ce = 1.80751073 * 102399; perplexity = 6.09525582
MPI Rank 1: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751073 * 102399
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:15: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:15: __COMPLETED__
MPI Rank 2: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13
MPI Rank 2: 
MPI Rank 2: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:28:14: Build info: 
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:14: 		Built time: Aug 21 2017 08:19:24
MPI Rank 2: 08/21/2017 08:28:14: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 2: 08/21/2017 08:28:14: 		Build type: debug
MPI Rank 2: 08/21/2017 08:28:14: 		Build target: GPU
MPI Rank 2: 08/21/2017 08:28:14: 		With 1bit-SGD: yes
MPI Rank 2: 08/21/2017 08:28:14: 		With ASGD: yes
MPI Rank 2: 08/21/2017 08:28:14: 		Math lib: mkl
MPI Rank 2: 08/21/2017 08:28:14: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 2: 08/21/2017 08:28:14: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 2: 08/21/2017 08:28:14: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 2: 08/21/2017 08:28:14: 		Build Branch: HEAD
MPI Rank 2: 08/21/2017 08:28:14: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 2: 08/21/2017 08:28:14: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 2: 08/21/2017 08:28:14: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 2: 08/21/2017 08:28:14: 		MPI distribution: Open MPI
MPI Rank 2: 08/21/2017 08:28:14: 		MPI version: 1.10.7
MPI Rank 2: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:28:14: GPU info:
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:14: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2424 MB
MPI Rank 2: 08/21/2017 08:28:14: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:28:14: Using 3 CPU threads.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:14: ##############################################################################
MPI Rank 2: 08/21/2017 08:28:14: #                                                                            #
MPI Rank 2: 08/21/2017 08:28:14: # train command (train action)                                               #
MPI Rank 2: 08/21/2017 08:28:14: #                                                                            #
MPI Rank 2: 08/21/2017 08:28:14: ##############################################################################
MPI Rank 2: 
MPI Rank 2: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 2: 08/21/2017 08:28:14: 
MPI Rank 2: Creating virgin network.
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 08/21/2017 08:28:15: 
MPI Rank 2: Model has 21 nodes. Using GPU 0.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:15: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 
MPI Rank 2: Memory Sharing: Out of 36 matrices, 23 are shared as 7, and 13 are not shared.
MPI Rank 2: 
MPI Rank 2: Here are the ones that share memory:
MPI Rank 2: 	{ WD0_D_Tanh : [288 x *]
MPI Rank 2: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 2: 	{ WD0_D : [288 x *]
MPI Rank 2: 	  WD0_D : [288 x *] (gradient)
MPI Rank 2: 	  WD1_D_Tanh : [64 x *]
MPI Rank 2: 	  WQ0_Q : [288 x *]
MPI Rank 2: 	  WQ0_Q_Tanh : [288 x *] (gradient) }
MPI Rank 2: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 2: 	  WD1_D : [64 x *]
MPI Rank 2: 	  WQ1 : [64 x 288] (gradient)
MPI Rank 2: 	  WQ1_Q : [64 x *]
MPI Rank 2: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 2: 	{ SIM : [51 x *] (gradient)
MPI Rank 2: 	  WD0 : [288 x 49292] (gradient)
MPI Rank 2: 	  WD1_D : [64 x *] (gradient) }
MPI Rank 2: 	{ WQ0 : [288 x 49292] (gradient)
MPI Rank 2: 	  WQ0_Q_Tanh : [288 x *] }
MPI Rank 2: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 2: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 2: 	  WD1_D_Tanh : [64 x *] (gradient)
MPI Rank 2: 	  WQ0_Q : [288 x *] (gradient) }
MPI Rank 2: 	{ SIM : [51 x *]
MPI Rank 2: 	  WD1 : [64 x 288] (gradient) }
MPI Rank 2: 
MPI Rank 2: Here are the ones that don't share memory:
MPI Rank 2: 	{WQ0 : [288 x 49292]}
MPI Rank 2: 	{WQ1 : [64 x 288]}
MPI Rank 2: 	{WD0 : [288 x 49292]}
MPI Rank 2: 	{WD1 : [64 x 288]}
MPI Rank 2: 	{Keyword : [49292 x *]}
MPI Rank 2: 	{Query : [49292 x *]}
MPI Rank 2: 	{S : [1 x 1]}
MPI Rank 2: 	{N : [1 x 1]}
MPI Rank 2: 	{G : [1 x 1]}
MPI Rank 2: 	{DSSMLabel : [51 x 1 x *]}
MPI Rank 2: 	{ce : [1]}
MPI Rank 2: 	{ce : [1] (gradient)}
MPI Rank 2: 	{WQ1_Q_Tanh : [64 x *]}
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:15: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:15: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 08/21/2017 08:28:15: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 08/21/2017 08:28:15: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 08/21/2017 08:28:15: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 
MPI Rank 2: Parallel training (4 workers) using ModelAveraging
MPI Rank 2: 08/21/2017 08:28:15: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:17: Starting Epoch 1: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 08/21/2017 08:28:24:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.32837563 * 10240; time = 6.7934s; samplesPerSecond = 1507.3
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.01 seconds
MPI Rank 2: 08/21/2017 08:28:30:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.35655479 * 10240; time = 6.5722s; samplesPerSecond = 1558.1
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 2: 08/21/2017 08:28:33: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601706 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-05; epochTime=16.7472s
MPI Rank 2: 08/21/2017 08:28:34: Final Results: Minibatch[1-26]: ce = 2.49916009 * 102399; perplexity = 12.17226604
MPI Rank 2: 08/21/2017 08:28:34: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916009 * 102399
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:36: Starting Epoch 2: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 2: 08/21/2017 08:28:43:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.32893581 * 10240; time = 6.5740s; samplesPerSecond = 1557.6
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 08/21/2017 08:28:49:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.11646938 * 10240; time = 6.6189s; samplesPerSecond = 1547.1
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.00 seconds
MPI Rank 2: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577526 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-05; epochTime=16.4842s
MPI Rank 2: 08/21/2017 08:28:53: Final Results: Minibatch[1-26]: ce = 1.97005577 * 102399; perplexity = 7.17107641
MPI Rank 2: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005577 * 102399
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:56: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:28:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.22 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.11 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.07 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.05 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 2: 08/21/2017 08:29:03:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.95308418 * 10240; time = 6.7988s; samplesPerSecond = 1506.2
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 08/21/2017 08:29:09:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.87902641 * 10240; time = 6.6202s; samplesPerSecond = 1546.8
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.8249s
MPI Rank 2: 08/21/2017 08:29:13: Final Results: Minibatch[1-26]: ce = 1.80751073 * 102399; perplexity = 6.09525582
MPI Rank 2: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751073 * 102399
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:15: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:15: __COMPLETED__
MPI Rank 3: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:28:13
MPI Rank 3: 
MPI Rank 3: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 08/21/2017 08:28:15: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:28:15: Build info: 
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:15: 		Built time: Aug 21 2017 08:19:24
MPI Rank 3: 08/21/2017 08:28:15: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 3: 08/21/2017 08:28:15: 		Build type: debug
MPI Rank 3: 08/21/2017 08:28:15: 		Build target: GPU
MPI Rank 3: 08/21/2017 08:28:15: 		With 1bit-SGD: yes
MPI Rank 3: 08/21/2017 08:28:15: 		With ASGD: yes
MPI Rank 3: 08/21/2017 08:28:15: 		Math lib: mkl
MPI Rank 3: 08/21/2017 08:28:15: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 3: 08/21/2017 08:28:15: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 3: 08/21/2017 08:28:15: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 3: 08/21/2017 08:28:15: 		Build Branch: HEAD
MPI Rank 3: 08/21/2017 08:28:15: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 3: 08/21/2017 08:28:15: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 3: 08/21/2017 08:28:15: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 3: 08/21/2017 08:28:15: 		MPI distribution: Open MPI
MPI Rank 3: 08/21/2017 08:28:15: 		MPI version: 1.10.7
MPI Rank 3: 08/21/2017 08:28:15: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:28:15: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:28:15: GPU info:
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:15: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2125 MB
MPI Rank 3: 08/21/2017 08:28:15: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:28:15: Using 3 CPU threads.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:15: ##############################################################################
MPI Rank 3: 08/21/2017 08:28:15: #                                                                            #
MPI Rank 3: 08/21/2017 08:28:15: # train command (train action)                                               #
MPI Rank 3: 08/21/2017 08:28:15: #                                                                            #
MPI Rank 3: 08/21/2017 08:28:15: ##############################################################################
MPI Rank 3: 
MPI Rank 3: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 3: 08/21/2017 08:28:15: 
MPI Rank 3: Creating virgin network.
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 08/21/2017 08:28:15: 
MPI Rank 3: Model has 21 nodes. Using GPU 0.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:15: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: 
MPI Rank 3: Memory Sharing: Out of 36 matrices, 23 are shared as 7, and 13 are not shared.
MPI Rank 3: 
MPI Rank 3: Here are the ones that share memory:
MPI Rank 3: 	{ WD0_D_Tanh : [288 x *]
MPI Rank 3: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 3: 	{ SIM : [51 x *] (gradient)
MPI Rank 3: 	  WD0 : [288 x 49292] (gradient)
MPI Rank 3: 	  WD1_D : [64 x *] (gradient) }
MPI Rank 3: 	{ WD0_D : [288 x *]
MPI Rank 3: 	  WD0_D : [288 x *] (gradient)
MPI Rank 3: 	  WD1_D_Tanh : [64 x *]
MPI Rank 3: 	  WQ0_Q : [288 x *]
MPI Rank 3: 	  WQ0_Q_Tanh : [288 x *] (gradient) }
MPI Rank 3: 	{ WQ0 : [288 x 49292] (gradient)
MPI Rank 3: 	  WQ0_Q_Tanh : [288 x *] }
MPI Rank 3: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 3: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 3: 	  WD1_D_Tanh : [64 x *] (gradient)
MPI Rank 3: 	  WQ0_Q : [288 x *] (gradient) }
MPI Rank 3: 	{ SIM : [51 x *]
MPI Rank 3: 	  WD1 : [64 x 288] (gradient) }
MPI Rank 3: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 3: 	  WD1_D : [64 x *]
MPI Rank 3: 	  WQ1 : [64 x 288] (gradient)
MPI Rank 3: 	  WQ1_Q : [64 x *]
MPI Rank 3: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 3: 
MPI Rank 3: Here are the ones that don't share memory:
MPI Rank 3: 	{ce : [1]}
MPI Rank 3: 	{WQ1_Q_Tanh : [64 x *]}
MPI Rank 3: 	{ce : [1] (gradient)}
MPI Rank 3: 	{WQ1 : [64 x 288]}
MPI Rank 3: 	{WD0 : [288 x 49292]}
MPI Rank 3: 	{WD1 : [64 x 288]}
MPI Rank 3: 	{Query : [49292 x *]}
MPI Rank 3: 	{Keyword : [49292 x *]}
MPI Rank 3: 	{S : [1 x 1]}
MPI Rank 3: 	{N : [1 x 1]}
MPI Rank 3: 	{G : [1 x 1]}
MPI Rank 3: 	{DSSMLabel : [51 x 1 x *]}
MPI Rank 3: 	{WQ0 : [288 x 49292]}
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:15: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:15: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 08/21/2017 08:28:15: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 08/21/2017 08:28:15: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 08/21/2017 08:28:15: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 
MPI Rank 3: Parallel training (4 workers) using ModelAveraging
MPI Rank 3: 08/21/2017 08:28:15: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:17: Starting Epoch 1: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.08 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.02 seconds
MPI Rank 3: 08/21/2017 08:28:24:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.32287750 * 10240; time = 6.7905s; samplesPerSecond = 1508.0
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.44 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.49 seconds , average latency = 0.02 seconds
MPI Rank 3: 08/21/2017 08:28:30:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.35470428 * 10240; time = 6.5722s; samplesPerSecond = 1558.1
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.55 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.55 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.60 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.74 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.82 seconds , average latency = 0.03 seconds
MPI Rank 3: 08/21/2017 08:28:33: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601706 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-05; epochTime=16.7472s
MPI Rank 3: 08/21/2017 08:28:34: Final Results: Minibatch[1-26]: ce = 2.49916009 * 102399; perplexity = 12.17226604
MPI Rank 3: 08/21/2017 08:28:34: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916009 * 102399
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:36: Starting Epoch 2: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.08 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.12 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.11 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 0.49 seconds , average latency = 0.12 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 0.65 seconds , average latency = 0.13 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 0.87 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.19-seconds latency this time; accumulated time on sync point = 1.06 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 1.23 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 1.39 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 1.61 seconds , average latency = 0.16 seconds
MPI Rank 3: 08/21/2017 08:28:43:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.29653873 * 10240; time = 6.5740s; samplesPerSecond = 1557.7
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 1.83 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 1.99 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 2.21 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 2.37 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 2.48 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 2.64 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 2.75 seconds , average latency = 0.16 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 2.92 seconds , average latency = 0.16 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 3.02 seconds , average latency = 0.16 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 3.13 seconds , average latency = 0.16 seconds
MPI Rank 3: 08/21/2017 08:28:49:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.11679478 * 10240; time = 6.6189s; samplesPerSecond = 1547.1
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 3.24 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 3.35 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 3.57 seconds , average latency = 0.16 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 3.68 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 3.84 seconds , average latency = 0.15 seconds
MPI Rank 3: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577526 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-05; epochTime=16.4843s
MPI Rank 3: 08/21/2017 08:28:53: Final Results: Minibatch[1-26]: ce = 1.97005577 * 102399; perplexity = 7.17107641
MPI Rank 3: 08/21/2017 08:28:53: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005577 * 102399
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:56: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:28:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.25-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.25 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.19-seconds latency this time; accumulated time on sync point = 0.44 seconds , average latency = 0.22 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 0.60 seconds , average latency = 0.20 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.71 seconds , average latency = 0.18 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.82 seconds , average latency = 0.16 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.93 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 1.04 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 1.14 seconds , average latency = 0.14 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 1.36 seconds , average latency = 0.15 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.19-seconds latency this time; accumulated time on sync point = 1.55 seconds , average latency = 0.16 seconds
MPI Rank 3: 08/21/2017 08:29:03:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.90347176 * 10240; time = 6.7987s; samplesPerSecond = 1506.2
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 1.77 seconds , average latency = 0.16 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 1.99 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 2.21 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 2.43 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 2.59 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 2.75 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 2.92 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 3.08 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 3.24 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 3.41 seconds , average latency = 0.17 seconds
MPI Rank 3: 08/21/2017 08:29:09:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.88304176 * 10240; time = 6.6202s; samplesPerSecond = 1546.8
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 3.57 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 3.73 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 3.84 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 4.01 seconds , average latency = 0.17 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.16-seconds latency this time; accumulated time on sync point = 4.17 seconds , average latency = 0.17 seconds
MPI Rank 3: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.8249s
MPI Rank 3: 08/21/2017 08:29:13: Final Results: Minibatch[1-26]: ce = 1.80751073 * 102399; perplexity = 6.09525582
MPI Rank 3: 08/21/2017 08:29:13: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751073 * 102399
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:15: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:15: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running mpiexec -n 4 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/ OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu DeviceId=0 timestamping=true numCPUThreads=3 stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
Changed current directory to /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (2) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (1) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (0) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 4 out of 4 MPI nodes on a single host (4 requested); we (3) are in (participating)
ping [mpihelper]: 4 nodes pinging each other
08/21/2017 08:29:16: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank0
08/21/2017 08:29:16: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank1
08/21/2017 08:29:17: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank2
08/21/2017 08:29:17: Redirecting stderr to file /tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr_train.logrank3
MPI Rank 0: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16
MPI Rank 0: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:29:16: Build info: 
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:16: 		Built time: Aug 21 2017 08:19:24
MPI Rank 0: 08/21/2017 08:29:16: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 0: 08/21/2017 08:29:16: 		Build type: debug
MPI Rank 0: 08/21/2017 08:29:16: 		Build target: GPU
MPI Rank 0: 08/21/2017 08:29:16: 		With 1bit-SGD: yes
MPI Rank 0: 08/21/2017 08:29:16: 		With ASGD: yes
MPI Rank 0: 08/21/2017 08:29:16: 		Math lib: mkl
MPI Rank 0: 08/21/2017 08:29:16: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 0: 08/21/2017 08:29:16: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 08/21/2017 08:29:16: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 0: 08/21/2017 08:29:16: 		Build Branch: HEAD
MPI Rank 0: 08/21/2017 08:29:16: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 0: 08/21/2017 08:29:16: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 0: 08/21/2017 08:29:16: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 0: 08/21/2017 08:29:16: 		MPI distribution: Open MPI
MPI Rank 0: 08/21/2017 08:29:16: 		MPI version: 1.10.7
MPI Rank 0: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:29:16: GPU info:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:16: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 3018 MB
MPI Rank 0: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 0: 08/21/2017 08:29:16: Using 3 CPU threads.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:16: ##############################################################################
MPI Rank 0: 08/21/2017 08:29:16: #                                                                            #
MPI Rank 0: 08/21/2017 08:29:16: # train command (train action)                                               #
MPI Rank 0: 08/21/2017 08:29:16: #                                                                            #
MPI Rank 0: 08/21/2017 08:29:16: ##############################################################################
MPI Rank 0: 
MPI Rank 0: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 0: 08/21/2017 08:29:16: 
MPI Rank 0: Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 08/21/2017 08:29:18: 
MPI Rank 0: Model has 21 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:18: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:18: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:18: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 08/21/2017 08:29:18: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 08/21/2017 08:29:18: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 08/21/2017 08:29:18: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 
MPI Rank 0: Parallel training (4 workers) using ModelAveraging
MPI Rank 0: 08/21/2017 08:29:18: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:21: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:21: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 08/21/2017 08:29:27:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.87577057 * 10240; time = 6.7097s; samplesPerSecond = 1526.1
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 08/21/2017 08:29:34:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.79361115 * 10240; time = 6.5505s; samplesPerSecond = 1563.3
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 08/21/2017 08:29:37: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974288 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.6308s
MPI Rank 0: 08/21/2017 08:29:38: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241652
MPI Rank 0: 08/21/2017 08:29:38: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 0: 08/21/2017 08:29:39: SGD: Saving checkpoint model '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net'
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:40: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 08/21/2017 08:29:40: __COMPLETED__
MPI Rank 1: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16
MPI Rank 1: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:29:16: Build info: 
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:16: 		Built time: Aug 21 2017 08:19:24
MPI Rank 1: 08/21/2017 08:29:16: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 1: 08/21/2017 08:29:16: 		Build type: debug
MPI Rank 1: 08/21/2017 08:29:16: 		Build target: GPU
MPI Rank 1: 08/21/2017 08:29:16: 		With 1bit-SGD: yes
MPI Rank 1: 08/21/2017 08:29:16: 		With ASGD: yes
MPI Rank 1: 08/21/2017 08:29:16: 		Math lib: mkl
MPI Rank 1: 08/21/2017 08:29:16: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 1: 08/21/2017 08:29:16: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 08/21/2017 08:29:16: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 1: 08/21/2017 08:29:16: 		Build Branch: HEAD
MPI Rank 1: 08/21/2017 08:29:16: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 1: 08/21/2017 08:29:16: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 1: 08/21/2017 08:29:16: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 1: 08/21/2017 08:29:16: 		MPI distribution: Open MPI
MPI Rank 1: 08/21/2017 08:29:16: 		MPI version: 1.10.7
MPI Rank 1: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:29:16: GPU info:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:16: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2940 MB
MPI Rank 1: 08/21/2017 08:29:16: -------------------------------------------------------------------
MPI Rank 1: 08/21/2017 08:29:16: Using 3 CPU threads.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:16: ##############################################################################
MPI Rank 1: 08/21/2017 08:29:16: #                                                                            #
MPI Rank 1: 08/21/2017 08:29:16: # train command (train action)                                               #
MPI Rank 1: 08/21/2017 08:29:16: #                                                                            #
MPI Rank 1: 08/21/2017 08:29:16: ##############################################################################
MPI Rank 1: 
MPI Rank 1: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 1: 08/21/2017 08:29:16: 
MPI Rank 1: Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 08/21/2017 08:29:18: 
MPI Rank 1: Model has 21 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:18: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:18: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:18: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 08/21/2017 08:29:18: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 08/21/2017 08:29:18: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 08/21/2017 08:29:18: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 
MPI Rank 1: Parallel training (4 workers) using ModelAveraging
MPI Rank 1: 08/21/2017 08:29:18: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:21: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:21: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.12-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.12 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.02 seconds
MPI Rank 1: 08/21/2017 08:29:27:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.93745022 * 10240; time = 6.7090s; samplesPerSecond = 1526.3
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 08/21/2017 08:29:34:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.89571209 * 10240; time = 6.5504s; samplesPerSecond = 1563.3
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 08/21/2017 08:29:37: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974288 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.6309s
MPI Rank 1: 08/21/2017 08:29:38: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241652
MPI Rank 1: 08/21/2017 08:29:38: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:40: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 08/21/2017 08:29:40: __COMPLETED__
MPI Rank 2: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16
MPI Rank 2: 
MPI Rank 2: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:29:17: Build info: 
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:17: 		Built time: Aug 21 2017 08:19:24
MPI Rank 2: 08/21/2017 08:29:17: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 2: 08/21/2017 08:29:17: 		Build type: debug
MPI Rank 2: 08/21/2017 08:29:17: 		Build target: GPU
MPI Rank 2: 08/21/2017 08:29:17: 		With 1bit-SGD: yes
MPI Rank 2: 08/21/2017 08:29:17: 		With ASGD: yes
MPI Rank 2: 08/21/2017 08:29:17: 		Math lib: mkl
MPI Rank 2: 08/21/2017 08:29:17: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 2: 08/21/2017 08:29:17: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 2: 08/21/2017 08:29:17: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 2: 08/21/2017 08:29:17: 		Build Branch: HEAD
MPI Rank 2: 08/21/2017 08:29:17: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 2: 08/21/2017 08:29:17: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 2: 08/21/2017 08:29:17: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 2: 08/21/2017 08:29:17: 		MPI distribution: Open MPI
MPI Rank 2: 08/21/2017 08:29:17: 		MPI version: 1.10.7
MPI Rank 2: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:29:17: GPU info:
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:17: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2862 MB
MPI Rank 2: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 2: 08/21/2017 08:29:17: Using 3 CPU threads.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:17: ##############################################################################
MPI Rank 2: 08/21/2017 08:29:17: #                                                                            #
MPI Rank 2: 08/21/2017 08:29:17: # train command (train action)                                               #
MPI Rank 2: 08/21/2017 08:29:17: #                                                                            #
MPI Rank 2: 08/21/2017 08:29:17: ##############################################################################
MPI Rank 2: 
MPI Rank 2: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 2: 08/21/2017 08:29:17: 
MPI Rank 2: Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 08/21/2017 08:29:19: 
MPI Rank 2: Model has 21 nodes. Using GPU 0.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:19: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:19: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:19: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 08/21/2017 08:29:19: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 08/21/2017 08:29:19: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 08/21/2017 08:29:19: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 
MPI Rank 2: Parallel training (4 workers) using ModelAveraging
MPI Rank 2: 08/21/2017 08:29:19: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:21: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:21: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.37-seconds latency this time; accumulated time on sync point = 0.37 seconds , average latency = 0.37 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.37 seconds , average latency = 0.18 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.39 seconds , average latency = 0.13 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.10 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.08 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.07 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.06 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.05 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.04 seconds
MPI Rank 2: 08/21/2017 08:29:27:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.96188030 * 10240; time = 6.7282s; samplesPerSecond = 1521.9
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 08/21/2017 08:29:34:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.90950069 * 10240; time = 6.5505s; samplesPerSecond = 1563.2
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 2: 08/21/2017 08:29:37: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974288 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.6308s
MPI Rank 2: 08/21/2017 08:29:38: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241652
MPI Rank 2: 08/21/2017 08:29:38: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:40: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 08/21/2017 08:29:40: __COMPLETED__
MPI Rank 3: CNTK 2.1+ (HEAD 572609, Aug 21 2017 08:21:13) on 2a27ade3fb9d at 2017/08/21 08:29:16
MPI Rank 3: 
MPI Rank 3: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/debug/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk  currentDirectory=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  RunDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DataDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SparseDSSM/  OutputDir=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=3  stderr=/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:29:17: Build info: 
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:17: 		Built time: Aug 21 2017 08:19:24
MPI Rank 3: 08/21/2017 08:29:17: 		Last modified date: Thu Aug  3 09:47:37 2017
MPI Rank 3: 08/21/2017 08:29:17: 		Build type: debug
MPI Rank 3: 08/21/2017 08:29:17: 		Build target: GPU
MPI Rank 3: 08/21/2017 08:29:17: 		With 1bit-SGD: yes
MPI Rank 3: 08/21/2017 08:29:17: 		With ASGD: yes
MPI Rank 3: 08/21/2017 08:29:17: 		Math lib: mkl
MPI Rank 3: 08/21/2017 08:29:17: 		CUDA_PATH: /usr/local/cuda-8.0
MPI Rank 3: 08/21/2017 08:29:17: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 3: 08/21/2017 08:29:17: 		CUDNN_PATH: /usr/local/cudnn-6.0
MPI Rank 3: 08/21/2017 08:29:17: 		Build Branch: HEAD
MPI Rank 3: 08/21/2017 08:29:17: 		Build SHA1: 57260963c605c12d3796e37783433518ab8ba039
MPI Rank 3: 08/21/2017 08:29:17: 		Built by Source/CNTK/buildinfo.h$$0 on e5cc4a4c4ac6
MPI Rank 3: 08/21/2017 08:29:17: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux_2
MPI Rank 3: 08/21/2017 08:29:17: 		MPI distribution: Open MPI
MPI Rank 3: 08/21/2017 08:29:17: 		MPI version: 1.10.7
MPI Rank 3: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:29:17: GPU info:
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:17: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; total memory = 3020 MB; free memory = 2728 MB
MPI Rank 3: 08/21/2017 08:29:17: -------------------------------------------------------------------
MPI Rank 3: 08/21/2017 08:29:17: Using 3 CPU threads.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:17: ##############################################################################
MPI Rank 3: 08/21/2017 08:29:17: #                                                                            #
MPI Rank 3: 08/21/2017 08:29:17: # train command (train action)                                               #
MPI Rank 3: 08/21/2017 08:29:17: #                                                                            #
MPI Rank 3: 08/21/2017 08:29:17: ##############################################################################
MPI Rank 3: 
MPI Rank 3: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 3: 08/21/2017 08:29:17: 
MPI Rank 3: Starting from checkpoint. Loading network from '/tmp/cntk-test-20170821082624.423236/Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 08/21/2017 08:29:19: 
MPI Rank 3: Model has 21 nodes. Using GPU 0.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:19: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:19: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:19: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 08/21/2017 08:29:19: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 08/21/2017 08:29:19: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 08/21/2017 08:29:19: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 
MPI Rank 3: Parallel training (4 workers) using ModelAveraging
MPI Rank 3: 08/21/2017 08:29:19: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:21: Starting Epoch 3: learning rate per sample = 0.0001  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:21: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.24-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.24 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.12 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.08 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.06 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.05 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.04 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.04 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.03 seconds
MPI Rank 3: 08/21/2017 08:29:27:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.91174278 * 10240; time = 6.7237s; samplesPerSecond = 1523.0
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.02 seconds
MPI Rank 3: 08/21/2017 08:29:34:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.91370468 * 10240; time = 6.5504s; samplesPerSecond = 1563.3
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 3: 08/21/2017 08:29:37: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974288 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-05; epochTime=16.6309s
MPI Rank 3: 08/21/2017 08:29:38: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241652
MPI Rank 3: 08/21/2017 08:29:38: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:40: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 08/21/2017 08:29:40: __COMPLETED__